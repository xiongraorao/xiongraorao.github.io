<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux僵尸进程]]></title>
    <url>%2F2018%2F07%2F11%2Flinux%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[linux僵尸进程原因： 父进程调用fork创建子进程后，子进程运行直至其终止，它立即从内存中移除，但进程描述符仍然保留在内存中（进程描述符占有极少的内存空间）。子进程的状态变成EXIT_ZOMBIE，并且向父进程发送SIGCHLD 信号，父进程此时应该调用 wait() 系统调用来获取子进程的退出状态以及其它的信息。在 wait 调用之后，僵尸进程就完全从内存中移除。因此一个僵尸存在于其终止到父进程调用 wait 等函数这个时间的间隙，一般很快就消失，但如果编程不合理，父进程从不调用 wait 等系统调用来收集僵尸进程，那么这些进程会一直存在内存中。 检测僵尸进程123456$ top top - 09:58:31 up 3 min, 2 users, load average: 0.76, 0.45, 0.19Tasks: 212 total, 1 running, 210 sleeping, 0 stopped, 1 zombie%Cpu(s): 6.4 us, 3.1 sy, 0.6 ni, 78.6 id, 11.2 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem: 4037576 total, 1664952 used, 2372624 free, 82416 buffersKiB Swap: 1998844 total, 0 used, 1998844 free. 916128 cached Mem 可以看到，我们系统中有一个僵尸进程（1 zombie）。 杀死僵尸进程1234$ ps aux | grep -w 'Z'#或者只查看特定的栏目：$ ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]'$ sudo kill -9 ppid]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见排序算法]]></title>
    <url>%2F2018%2F07%2F11%2F%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[简介 分类排序算法通常指的是内部排序算法，即数据记录在内存中进行排序。 比较排序 时间复杂度为O(nlogn) ~ O(n^2), 有冒泡排序、选择排序、 插入排序、希尔排序、归并排序、堆排序、快速排序等 非比较排序 时间复杂度可以达到O(n), 主要有：计数排序，基数排序，桶排序等。 算法复杂度 相关概念 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。不稳定：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。时间复杂度：对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。空间复杂度：是指算法在计算机内执行时所需存储空间的度量，它也是数据规模n的函数。 冒泡排序算法描述：从左到右，不断的交换逆序的相邻元素，在一轮的交换过后，可以让未排序的元素上浮到右侧。在一轮循环中，如果没有发生交换，就说明数组已经是有序的，此时可以直接退出。 1234567891011121314151617181920212223242526272829/** * 冒泡排序 */public static void bubbleSort(int[] arr) &#123; boolean hasSorted = false; for (int i = 0; i &lt; arr.length - 1 &amp;&amp; !hasSorted; i++) &#123; hasSorted = true; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j + 1] &lt; arr[j]) &#123; hasSorted = false; swap(arr, j, j + 1); &#125; &#125; &#125;&#125;private static void swap(int[] arr, int a, int b) &#123; if (arr == null || arr.length == 0) &#123; return; &#125; if (a &lt; 0 || a &gt; arr.length || b &lt; 0 || b &gt; arr.length) &#123; return; &#125; int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp;&#125; 选择排序算法描述：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 123456789101112131415/** * 选择排序 */ public static void selectSort(int[] arr) &#123; int N = arr.length; for (int i = 0; i &lt; N - 1; i++) &#123; int minIndex = i; for (int j = i + 1; j &lt; N; j++) &#123; if (arr[j] &lt; arr[minIndex]) &#123; minIndex = j; &#125; &#125; swap(arr, minIndex, i); &#125; &#125; 插入排序算法描述：通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后；重复步骤2~5。 12345678910111213141516171819202122232425262728/** * 插入排序 */ public static void insertSort(int[] arr) &#123; int N = arr.length; for (int i = 1; i &lt; N; i++) &#123; int current = arr[i]; int j = i - 1; for (; j &gt;= 0 &amp;&amp; arr[j] &gt; current; j--) &#123; arr[j + 1] = arr[j]; &#125; arr[j + 1] = current; &#125; &#125; /** * 插入排序2 * * 直接相邻数据交换，不需要中间变量 */ public static void insertSort2(int[] arr) &#123; int N = arr.length; for (int i = 1; i &lt; N; i++) &#123; for (int j = i; j &gt; 0 &amp;&amp; arr[j - 1] &gt; arr[j]; j--) &#123; swap(arr, j - 1, j); &#125; &#125; &#125; 希尔排序算法描述：简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；按增量序列个数k，对序列进行k 趟排序；每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 对于大规模的数组，插入排序很慢，因为它只能交换相邻的元素，每次只能将逆序数量减少 1。希尔排序的出现就是为了改进插入排序的这种局限性，它通过交换不相邻的元素，每次可以将逆序数量减少大于 1。希尔排序使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 算法的核心在于间隔序列的设定 1234567891011121314151617181920/** * 希尔排序 */public static void shellSort(int[] arr) &#123; int N = arr.length; int h = 1; // 动态定义间隔 while (h &lt; N / 3) &#123; h = h * 3 + 1; // h = 1, 4, 13, 40 ... &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; N; i++) &#123; for (int j = i; j &gt;= h &amp;&amp; arr[j - h] &gt; arr[j]; j -= h) &#123; swap(arr, j - h, j); &#125; &#125; h = h / 3; &#125;&#125; 归并排序算法描述：归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 归并排序 */ public static void mergeSort(int[] arr) &#123; mergeSort(arr, 0, arr.length - 1); &#125; private static int[] mergeSort(int[] arr, int low, int high) &#123; int mid = (low + high) / 2; if (low &lt; high) &#123; mergeSort(arr, low, mid); mergeSort(arr, mid + 1, high); merge(arr, low, mid, high); &#125; return arr; &#125; /** * 合并两个有序数组 */ private static void merge(int[] a, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low; int j = mid + 1; int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (a[i] &lt; a[j]) &#123; temp[k++] = a[i++]; &#125; else &#123; temp[k++] = a[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = a[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = a[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int x = 0; x &lt; temp.length; x++) &#123; a[x + low] = temp[x]; &#125; &#125; 快速排序算法描述：归并排序将数组分为两个子数组分别排序，并将有序的子数组归并使得整个数组排序；快速排序通过一个切分元素将数组分为两个子数组，左子数组小于等于切分元素，右子数组大于等于切分元素，将这两个子数组排序也就将整个数组排序了。 1234567891011121314151617181920212223242526272829303132/** * 快速排序 */ public static void quickSort(int[] arr) &#123; quickSort(arr, 0, arr.length - 1); &#125; private static void quickSort(int[] arr, int left, int right) &#123; if (right &lt;= left) &#123; return; &#125; int index = partition(arr, left, right); quickSort(arr, left, index - 1); quickSort(arr, index + 1, right); &#125; private static int partition(int[] arr, int left, int right) &#123; int pivot = arr[left]; // 以第一个数为基准 while (left &lt; right) &#123; // 先从后向前比较 while (arr[right] &gt; pivot &amp;&amp; right &gt; left) &#123; right--; &#125; arr[left] = arr[right]; while (arr[left] &lt;= pivot &amp;&amp; right &gt; left) &#123; left++; &#125; arr[right] = arr[left]; &#125; arr[right] = pivot; return right; &#125; 堆排序算法简介：堆排序指利用堆这种数据结构所设计的一种排序算法。堆是一种近似完全二叉树的结构，并满足性质：以最大堆为例，其中父节点的值总是大于它的孩子节点。 堆可以用数组来表示，因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。这里不使用数组索引为 0 的位置，是为了更清晰地描述节点的位置关系。 流程： 由输入的无序数组构造一个最大堆，作为初始的无序区 把堆顶元素（最大值）和堆尾元素互换,交换之后需要进行下沉操作维持堆的有序状态 12345678910111213141516171819202122232425262728/** * 堆排序 */public static void heapSort(int[] arr) &#123; int N = arr.length - 1; for (int k = N / 2; k &gt;= 1; k--) &#123; sink(arr, k, N); &#125; while (N &gt; 1) &#123; swap(arr, 1, N--); sink(arr, 1, N); &#125;&#125;private static void sink(int[] arr, int k, int N) &#123; while (2 * k &lt;= N) &#123; int j = 2 * k; if (j &lt; N &amp;&amp; arr[j] &lt; arr[j + 1]) &#123; j++; &#125; if (!(arr[k] &lt; arr[j])) &#123; break; &#125; swap(arr, k, j); k = j; &#125;&#125; 计数排序算法描述：计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序适合分布集中的排序，如统计年龄的排序等 123456789101112131415161718192021222324252627282930/** * 计数排序 */ public static void countSort(int[] arr) &#123; int maxValue = arr[0]; for (int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; maxValue) &#123; maxValue = arr[i]; &#125; &#125; countSort(arr, maxValue); &#125; private static void countSort(int[] arr, int maxValue) &#123; int[] bucket = new int[maxValue + 1]; int sortedIndex = 0; int len = arr.length; int bucketLen = maxValue + 1; for (int i = 0; i &lt; len; i++) &#123; bucket[arr[i]]++; &#125; for (int j = 0; j &lt; bucketLen; j++) &#123; while (bucket[j] &gt; 0) &#123; arr[sortedIndex++] = j; bucket[j]--; &#125; &#125; &#125; 桶排序算法原理：桶排序是计数排序的升级版，利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。 设置一个定量的数组当作空桶；遍历输入数据，并且把数据一个一个放到对应的桶里去；对每个不是空的桶进行排序；从不是空的桶里把排好序的数据拼接起来。 代码实现： 123456789101112131415161718192021222324252627282930313233/** * 桶排序 */ public static void bucketSort(int[] arr, int bucketSize) &#123; int i; int minValue = arr[0]; int maxValue = arr[0]; for (i = 0; i &lt; arr.length; i++) &#123; if (arr[i] &lt; minValue) &#123; minValue = arr[i]; &#125; else if (arr[i] &gt; maxValue) &#123; maxValue = arr[i]; &#125; &#125; // 初始化桶 int bucketCount = (int) (Math.floor((maxValue - minValue) / bucketSize) + 1); List&lt;List&lt;Integer&gt;&gt; buckets = new ArrayList&lt;&gt;(); for (i = 0; i &lt; arr.length; i++) &#123; int index = (int) Math.floor((arr[i] - minValue) / bucketSize); List&lt;Integer&gt; temp = buckets.get(index); if (temp == null) &#123; buckets.add(index, Arrays.asList(arr[i])); &#125; else &#123; temp.add(arr[i]); &#125; &#125; for (i = 0; i &lt; buckets.size(); i++) &#123; //对每个桶进行排序。。。 &#125; &#125; 基数排序算法描述： 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。 取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点） 12345678910111213141516171819202122232425// LSD Radix Sortvar counter = [];function radixSort(arr, maxDigit) &#123; var mod = 10; var dev = 1; for (var i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) &#123; for(var j = 0; j &lt; arr.length; j++) &#123; var bucket = parseInt((arr[j] % mod) / dev); if(counter[bucket]==null) &#123; counter[bucket] = []; &#125; counter[bucket].push(arr[j]); &#125; var pos = 0; for(var j = 0; j &lt; counter.length; j++) &#123; var value = null; if(counter[j]!=null) &#123; while ((value = counter[j].shift()) != null) &#123; arr[pos++] = value; &#125; &#125; &#125; &#125; return arr;&#125; 参考链接： 常用排序算法总结(一) 常用排序算法总结(二) 十大经典排序算法（动图演示） 各种排序算法总结和比较]]></content>
      <categories>
        <category>笔记</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chrome解决http自动跳转https的问题]]></title>
    <url>%2F2018%2F07%2F03%2Fchrome%E8%A7%A3%E5%86%B3http%E8%87%AA%E5%8A%A8%E8%B7%B3%E8%BD%AChttps%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.地址栏输入： chrome://net-internals/#hsts 2.找到底部Delete domain security policies一栏，输入想处理的域名，点击delete。 3.搞定了，再次访问http域名不再自动跳转https了]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvm磁盘合并]]></title>
    <url>%2F2018%2F07%2F03%2Flvm%E7%A3%81%E7%9B%98%E5%90%88%E5%B9%B6%2F</url>
    <content type="text"><![CDATA[显示逻辑卷组sudo vgdisplay 显示逻辑卷sudo lvdisplay 显示磁盘sudo fdisk -l 创建物理卷sudo pvcreate /dev/sdb 显示物理卷信息sudo pvdisplay 物理卷/dev/sdb加入卷组vg-rootsudo vgextend vg-root /dev/sdb 增大逻辑卷root 1Tsudo lvextend -L +1T /dev/ubuntu-vg/rootsudo lvextend -l +100%FREE /de/ubuntu-vg/root 调整文件系统大小sudo resize2fs /dev/ubuntu-vg/root 查看结果df -h issue: remove bad disk]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑苹果仿冒声卡驱动AppleALC]]></title>
    <url>%2F2018%2F07%2F02%2F%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%BB%BF%E5%86%92%E5%A3%B0%E5%8D%A1%E9%A9%B1%E5%8A%A8AppleALC%2F</url>
    <content type="text"><![CDATA[参考教程： 黑苹果定制声卡驱动（ALC892为例) 使用AppleALC声卡仿冒驱动AppleHDA的正确姿势 傻瓜式仿冒声卡驱动第二季（仿冒ALC892) [教程] AppleALC使用和修改教程 资源链接： vit9696/AppleALC acidanthera/Lilu HDA 工具 zlib 转换器 注意事项： 该教程可以通过AppleALC修改驱动，然后通过Clover 的方式注入Layout，也可以直接在原生AppleHDA上面修改。 AppleHDA-10.14.kext.zip clover注意要设置一个参数：FixHPET,否则无法加载AppleHDA 附：ALC269VC 的confidData的数据格式 123456789id_modified:4001271C40 01271D01 01271EA0 01271F90 01471C10 01471D01 01471E17 01471F90 01470C02 01571C20 01571D10 01571E21 01571F00 01871C30 01871D10 01871E81 01871F00oneline:01271C40 01271D01 01271EA0 01271F90 01471C10 01471D01 01471E17 01471F90 01470C02 01571C20 01571D10 01571E21 01571F00 01871C30 01871D10 01871E81 01871F00 每组数字构成：Address+Node+71+[c/d/e/f]+描述数字描述数字每组一共有8个分别表示：1 优先级耳机优先级一定要低于内置扬声器，外置麦克风一定要低于内置麦克风2 lineout 为f，其余03 接口颜色4 接口为 0，表示当接口被检测到时使用。如果是笔记本的话内建的麦克风和扬声器要设成1，即当耳机插入时，内建扬声器静音，耳机0 接口被检测到就是用耳机。5 接口功能信息6 链接装置类型7 接口类型0为插入接口的，如外置麦克风、耳机等。(如果codec_dump出来有 [N/A] 的就是无用的port，数字为4。)9为给笔记本內建，像内置扬声器、内置麦克风等8 接口位置 常见问题 睡眠后无法耳机没有声音 解决方法: 解决耳机切换问题 CodeCommander.kext 上面不管用的情况，直接重新加载AppleHDA就可以了 12sudo kextunload /System/Library/Extensions/AppleHDA.kextsudo kextload /System/Library/Extensions/AppleHDA.kext]]></content>
      <categories>
        <category>笔记</category>
        <category>mac</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>黑苹果</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh反向代理新姿势]]></title>
    <url>%2F2018%2F07%2F02%2Fssh%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%96%B0%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[基础知识ssh 的端口转发应用链接方向： 从应用的client到应用的server端ssh链接方向：ssh client –&gt; ssh server 本地转发(local forwarding) SSH链接方向和本地链接方向一致 ssh -L &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt; 本地转发会在本地机器上监听一个端口，所有访问这个端口的数据都会通过SSH隧道传输到远程主机的对应端口上, 最后将数据返回到客户端，完成整个转发过程 由于本地转发绑定的地址是lookback接口，因此绑定的local port只能在本机访问，不能让其他的client访问，如果想实现其他的client也可以访问的话，需要在ssh host 的 sshd_config 文件中添加一个参数 “GatewayPorts yes”，或者直接使用 -g 命令 远程转发(local forwarding) SSH链接方向和本地方向不一致，就是远程转发 ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt; 远程转发会在远程主机上面监听一个端口，所有访问远程主机的端口的数据都会被转发到本地对应的端口上,ssh反向代理(隧道)技术就是这样实现的 例如实现远程服务器A的1234端口映射到本机的22端口，实现远程服务器访问本地的22端口 ssh -R 1234:localhost:22 username@ServerA 动态转发(dynamic forwarding) 指定一个本地机器 “动态的’’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发. ssh -D &lt;local port&gt; &lt;SSH Server&gt; ssh 端口转发参数ssh的三个强大的端口转发命令： 转发到远端：ssh -C -f -N -g -L 本地端口:目标IP:目标端口 用户名@目标IP 转发到本地：ssh -C -f -N -g –R 本地端口:目标IP:目标端口 用户名@目标IP ssh -C -f -N -g -D listen_port user@Tunnel_Host -C：压缩数据传输。 -f ：后台认证用户/密码，通常和-N连用，不用登录到远程主机。 -N ：不执行脚本或命令，通常与-f连用。 -g ：在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。 -L 本地端口:目标IP:目标端口 将本地机(客户机)的某个端口转发到远端指定机器的指定端口. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 同时远程主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有 root 才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport -R本地端口:目标IP:目标端口 将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口. 工作原理是这样的, 远程主机上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转向出去, 同时本地主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有用 root 登录远程主机才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport -p ：被登录的ssd服务器的sshd服务端口。 -D port 指定一个本地机器 “动态的’’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发. 实现内网端口转发问题： 内网有服务器器A, 无公网IP，现有公网服务器B，如何实现在外网情况下链接服务器B的某个端口访问到A的服务 host 类型 ip port A 内网 192.168.1.3 1234 B 外网 www.123.com 5678 通过ssh的反向代理可以实现B服务器的5678 端口绑定在A服务器的1234端口上 12# 登录到A服务器ssh -C -f -N -g -R 5678:127.0.0.1:1234 username@www.123.com 实现内网VPN服务问题： 内网有服务器器A, 无公网IP，现有公网服务器B，如何实现在外网情况下访问到内网的所有服务 host 类型 ip port A 内网 192.168.1.3 192.168.1.0/24:* B 外网 www.123.com 5678 解决方案： shadowsocks + ssh远程转发 A机器安装shadowsock 服务端 shadowsocksR一键安装 A机器做远程转发 ssh -C -f -N -g -R 5678:127.0.0.1:shadowsocks_server_port username@www.123.com VPN访问 安装shadowsocks客户端，链接后配置socks5代理，就可以链接到内网的任何服务了 autossh–强大而稳定的解决方案ssh隧道非常容易断掉，在做远程转发的时候，有时候往往无法链接服务器，因此需要一个稳定的SSH链接，autossh就能实现SSH的断线自动重启 1234567891011121314# 配置好客户端到远程服务的ssh免密码连接autossh -f -M 55888 -NR *:10013:localhost:22 hadoop@oceanai.com.cnusage: autossh [-V] [-M monitor_port[:echo_port]] [-f] [SSH_OPTIONS] -M specifies monitor port. Overrides the environment variable AUTOSSH_PORT. 0 turns monitoring loop off. Alternatively, a port for an echo service on the remote machine may be specified. (Normally port 7.) -f run in background (autossh handles this, and does not pass it to ssh.) -V print autossh version and exit. 设置crontab任务，实现代理的自检查和重启功能，基本不会断连接 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354crontab -e */1 * * * * bash /home/hadoop/autossh/monitor-auto-ssh.sh* * * * * sleep 30; bash /home/hadoop/autossh/monitor-auto-ssh.shvim /home/hadoop/autossh/monitor-auto-ssh.sh---- #! /bin/shPROCESS_NAME=&apos;55566&apos;PROCESS_PATH=&apos;/home/hadoop/autossh&apos;START_PROCESS=&quot;autossh -f -M 55567 -NR 55566:localhost:22 hadoop@www.123.com&quot;VPN_PROCESS=&quot;autossh -f -M 55577 -NR 10012:localhost:13838 hadoop@www.123.com&quot;VPN_PROCESS_NAME=&quot;10012&quot;#PORT_TRANS=&quot;ssh -C -f -N -g -R 8888:127.0.0.1:8888 hadoop@www.123.com&quot;#PORT_TRANS_NAME=&quot;8888:127.0.0.1:8888&quot;proc_num() #查询进程数量 &#123; num=`ps -ef | grep $&#123;PROCESS_NAME&#125; | grep -v grep | wc -l` return $num &#125; proc_num2()&#123; num=`ps -ef | grep $&#123;VPN_PROCESS_NAME&#125; | grep -v grep | wc -l` return $num&#125; proc_num number=$?proc_num2number2=$?if [ $number -eq 0 ] #如果进程数量为0 then #重新启动服务 echo &quot;Restarting $&#123;PROCESS_NAME&#125; ...&quot; echo $(date &apos;+%Y-%m-%d %T&apos;) &gt;&gt; $&#123;PROCESS_PATH&#125;/restart.log ($&#123;START_PROCESS&#125;) &amp; echo &quot;over&quot;elif [ $number2 -eq 2 ]then echo &quot;ssh proxy has been started!&quot;fi if [ $number2 -eq 0 ] #如果进程数量为0 then #重新启动服务 echo &quot;Restarting $&#123;VPN_PROCESS_NAME&#125; ...&quot; echo $(date &apos;+%Y-%m-%d %T&apos;) &gt;&gt; $&#123;PROCESS_PATH&#125;/restart.log ($&#123;VPN_PROCESS&#125;) &amp; echo &quot;over&quot;elif [ $number -eq 2 ]then echo &quot;shadow proxy has been started!&quot;fi]]></content>
      <categories>
        <category>笔记</category>
        <category>网络</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ShadowsocksR一键安装脚本]]></title>
    <url>%2F2018%2F06%2F25%2FShadowsocksR%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[ShadowsocksR一键安装脚本默认配置：服务器端口：自己设定（如不设定，默认从 9000-19999 之间随机生成）密码：自己设定（如不设定，默认为 teddysun.com）加密方式：自己设定（如不设定，默认为 aes-256-cfb）协议（Protocol）：自己设定（如不设定，默认为 origin）混淆（obfs）：自己设定（如不设定，默认为 plain） 客户端下载：github shadowsock 安装步骤123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log 卸载步骤./shadowsocksR.sh uninstall 多用户配置123456789101112131415161718192021&#123;"server":"0.0.0.0","server_ipv6": "[::]","local_address":"127.0.0.1","local_port":1080,"port_password":&#123; "8989":"password1", "8990":"password2", "8991":"password3"&#125;,"timeout":300,"method":"aes-256-cfb","protocol": "origin","protocol_param": "","obfs": "plain","obfs_param": "","redirect": "","dns_ipv6": false,"fast_open": false,"workers": 1&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groovy学习笔记]]></title>
    <url>%2F2018%2F06%2F22%2Fgroovy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[概述Groovy是一种基于Java平台的面向对象语言。 Groovy 1.0于2007年1月2日发布，其中Groovy 2.4是当前的主要版本。 Groovy通过Apache License v 2.0发布。 Groovy的特点Groovy中有以下特点: 同时支持静态和动态类型。 支持运算符重载。 本地语法列表和关联数组。 对正则表达式的本地支持。 种标记语言，如XML和HTML原生支持。 Groovy对于Java开发人员来说很简单，因为Java和Groovy的语法非常相似。 您可以使用现有的Java库。 Groovy扩展了java.lang.Object。 用法groovy 大部分的语法和java相同，并且支持静态类型。 123def x = 5x = "jack"println x 数值和表达式 支持的数据类型：byte short int long float double char boolean String 同java 对应的类封装类型 其中整数是Intgerger类的实例，有小数部分的数据是BigDecimal类的实例 特殊运算符： 范围运算符： 12def range = 0..5println range // 输出： [0,1,2,3,4,5] groovy 支持运算符的重载 动态类型： def variable_name动态类型在运行时确定，不在编译的时候确定，类似java的多态 字符串和正则表达式字符串字面值单引号：所见即所得双引号：解释性字符串三引号：解释性字符串 多行文本用这个 1234567def age=25'My age is $&#123;age&#125;' //My age is $&#123;age&#125;"My age is $&#123;age&#125;" //My age is 25"""//My age is $&#123;age&#125;""" //My age is 25"""My age is \$&#123;age&#125;""" //My age is $&#123;age&#125; 字符串索引1234567def greeting='Hello World'greeting[4] //ogreeting[-1] //dgreeting[1..2] //elgreeting[1..&lt;3] //el, 等价于greeting[1..2]greeting[4..2] //ollgreeting[4,1,6] //oew groovy 中的字符串是有序序列，单个字符可以通过位置访问，支持负索引。 字符串操作参考链接：groovy字符串 12345678def greeting='Hello world''Hello'+'world' //Helloworld'Hello'*3 //HelloHelloHellogreeting-'o world' //Hellgreeting.size() //11greeting.length() //11greeting.count('o') //2greeting.contains('ell') //true 索引类似java String 的 charAt()方法获取指定位置的字符 字符串方法def message=’Hello’message.center(11) //返回长度为11，左右两边均使用空格填充的字符串message.center(3)message.center(11,’#’)message.eachMatch(‘.’) 正则表达式~’regex’定义正则表达式 def regex=~’cheese’ if(‘cheesecake’=~’cheese’) //左边String对象和右边的正则匹配，返回布尔值 ==~ 精确匹配 ‘cheesecake’==~’cheese’ \\在正则中表示一个反斜杠字符类似于java中正则的使用，用单引号括起也可以用js的方法，直接使用，不用引号 1 def matcher=”\$abc.”=~\\$(.)\.2 def matcher=”\$abc.”=~/\$(.)./ 方法12345678910111213141516def methodName() &#123; //Method code &#125;// 不用显式指定参数名字def methodName(parameter1, parameter2, parameter3) &#123; // Method code goes here &#125;// 默认参数def someMethod(para1,para2=0,para3=0)&#123; // Method code goes here &#125;// 返回值return 可选，省略了，代码的最后一条语句的值就是方法的返回值 groovy 定义方法时不用显示指定参数类型 groovy 列表、映射、范围列表在java list基础上进行了一些扩展 [11，12，13，14] - 整数值列表[‘Angular’，’Groovy’，’Java’] - 字符串列表[1，2，[3，4]，5] - 嵌套列表[‘Groovy’，21，2.11] - 异构的对象引用列表[] - 一个空列表 12345678def list = ['hello', 12, 1.5]println list[0..1]list &lt;&lt; 'world' println list[0..-1]//输出如下：[hello, 12][hello, 12, 1.5, world] &lt;&lt; 把新元素追加到列表末尾 调用#leftShift 连接两个列表 调用#plus 从列表删除元素 调用#minusnumber[1]=[33,44] 调用#putAt 映射类似 java 的Map 123456789101112131415161718192021// 1. 访问 调用getAtdef names=[‘ken’:’Barclay,’John’:’Savage’] def divisors=[4:[2],6:[3,2],12:[6,4,3,2]] names[‘Ken’] //第一种访问写法 names.Ken //第二种访问写法 divisors[6]// 2. 赋值 调用putAtdivisors[6]=[6,3,2,1]// 3. 空映射[:] 空映射// 4. 映射方法def map=['ken':2745,'john':2746,'sally':2742]map.get('david',9999) //9999map.get('sally') //2742map.keySet() //[david,ken,sally,john]mp['ken'] //2745mp.values.asList() 范围1..10 - 包含范围的示例1 .. &lt;10 - 独占范围的示例, 排除最后一个数值‘a’..’x’ - 范围也可以由字符组成10..1 - 范围也可以按降序排列‘x’..’a’ - 范围也可以由字符组成并按降序排列。 类如果不声明public/private等访问权限的话，Groovy中类及其变量默认都是public的。 在使用默认修饰符的时候，自动生成隐藏的getter和setter方法，不过也可以直接访问 其余和java差不多 闭包闭包，英文叫Closure，是Groovy中非常重要的一个数据类型或者说一种概念了。闭包，是一种数据类型，它代表了一段可执行的代码。 12345def aClosure = &#123;//闭包是一段代码，所以需要用花括号括起来.. String param1, int param2 -&gt; //这个箭头很关键。箭头前面是参数定义，箭头后面是代码 println"this is code" //这是代码，最后一句是返回值， //也可以使用return，和Groovy中普通函数一样 &#125; closure 的定义格式为： 1234def xxx = &#123;paramters -&gt; code&#125; //或者 def xxx = &#123;无参数，纯code&#125; 闭包的访问： 1234aClosure.call("this is string",100) //或者 aClosure("this is string", 100) 闭包的默认参数，it, 类似 this 12345def fun2 = &#123; it-&gt; "dsdsd"&#125;println( fun2.call()) 闭包默认参数的覆盖 123456def fun3 = &#123; -&gt; "dsdsd"&#125;println( fun3.call())fun3.call("d") //执行这个方法的时候就会报错 闭包和函数的区别接口特征(trait)特征是语言的构造，允许 行为的组成 接口的运行时实现 与静态类型检查/编译的兼容性 traint 可以被看做是承载默认实现和状态的接口 traint 的实现 12345678910111213141516171819class Example &#123; static void main(String[] args) &#123; Student st = new Student(); st.StudentID = 1; st.Marks1 = 10; println(st.DisplayMarks()); &#125; &#125; trait Marks &#123; int Marks1; void DisplayMarks() &#123; println("Display Marks"); &#125; &#125; class Student implements Marks &#123; int StudentID&#125; traint 用于行为的构成： 特征可以用于以受控的方式实现多重继承，避免钻石问题。在下面的代码示例中，我们定义了两个特征 - Marks和Total。我们的Student类实现了两个特征。由于学生类扩展了这两个特征，它能够访问这两种方法 - DisplayMarks和DisplayTotal。 12345678910111213141516171819202122232425class Example &#123; static void main(String[] args) &#123; Student st = new Student(); st.StudentID = 1; println(st.DisplayMarks()); println(st.DisplayTotal()); &#125; &#125; trait Marks &#123; void DisplayMarks() &#123; println("Marks1"); &#125; &#125; trait Total &#123; void DisplayTotal() &#123; println("Total"); &#125; &#125; class Student implements Marks,Total &#123; int StudentID &#125; 扩展特征 特征可能扩展另一个特征，在这种情况下，必须使用extends关键字。在下面的代码示例中，我们使用Marks trait扩展了Total trait。 1234567891011121314151617181920212223class Example &#123; static void main(String[] args) &#123; Student st = new Student(); st.StudentID = 1; println(st.DisplayMarks()); &#125; &#125; trait Marks &#123; void DisplayMarks() &#123; println("Marks1"); &#125; &#125; trait Total extends Marks &#123; void DisplayMarks() &#123; println("Total"); &#125; &#125; class Student implements Total &#123; int StudentID &#125; 总的来说，特征可以实现接口，可以被类实现，可以继承其他的特征，相比java, groovy的这一个特性相当于实现了多继承 xmlMarkupBuilder用于构造整个XML文档。通过首先创建XML文档类的对象来创建XML文档 xml 构建 12345678910111213141516171819202122232425262728293031import groovy.xml.MarkupBuilder class Example &#123; static void main(String[] args) &#123; def mB = new MarkupBuilder() // Compose the builder mB.collection(shelf : 'New Arrivals') &#123; movie(title : 'Enemy Behind') type('War, Thriller') format('DVD') year('2003') rating('PG') stars(10) description('Talk about a US-Japan war') &#125; &#125; &#125;// 得到如下结果&lt;collection shelf = 'New Arrivals'&gt; &lt;movie title = 'Enemy Behind' /&gt; &lt;type&gt;War, Thriller&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;2003&lt;/year&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Talk about a US-Japan war&lt;/description&gt; &lt;/movie&gt; &lt;/collection&gt; xml 解析 123456789101112131415161718192021222324252627282930313233343536import groovy.xml.MarkupBuilder import groovy.util.*class Example &#123; static void main(String[] args) &#123; def parser = new XmlParser() def doc = parser.parse("D:Movies.xml"); doc.movie.each&#123; bk-&gt; print("Movie Name:") println "$&#123;bk['@title']&#125;" print("Movie Type:") println "$&#123;bk.type[0].text()&#125;" print("Movie Format:") println "$&#123;bk.format[0].text()&#125;" print("Movie year:") println "$&#123;bk.year[0].text()&#125;" print("Movie rating:") println "$&#123;bk.rating[0].text()&#125;" print("Movie stars:") println "$&#123;bk.stars[0].text()&#125;" print("Movie description:") println "$&#123;bk.description[0].text()&#125;" println("*******************************") &#125; &#125;&#125; JSON 功能 对象 JsonSlurper | JsonSlurper是一个将JSON文本或阅读器内容解析为Groovy数据的类结构，例如地图，列表和原始类型，如整数，双精度，布尔和字符串。JsonOutput | 此方法负责将Groovy对象序列化为JSON字符串。 json 解析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849http.request( GET, TEXT ) &#123; headers.Accept = 'application/json' headers.'User-Agent' = USER_AGENT response.success = &#123; res, rd -&gt; def jsonText = rd.text //Setting the parser type to JsonParserLax def parser = new JsonSlurper().setType(JsonParserType.LAX) def jsonResp = parser.parseText(jsonText) &#125;&#125;// 解析文本数据class Example &#123; static void main(String[] args) &#123; def jsonSlurper = new JsonSlurper() def object = jsonSlurper.parseText('&#123; "name": "John", "ID" : "1"&#125;') println(object.name); println(object.ID); &#125; &#125;// 解析整数列表class Example &#123; static void main(String[] args) &#123; def jsonSlurper = new JsonSlurper() Object lst = jsonSlurper.parseText('&#123; "List": [2, 3, 4, 5] &#125;') lst.each &#123; println it &#125; &#125; &#125;// 解析基本数据类型列表class Example &#123; static void main(String[] args) &#123; def jsonSlurper = new JsonSlurper() def obj = jsonSlurper.parseText ''' &#123;"Integer": 12, "fraction": 12.55, "double": 12e13&#125;''' println(obj.Integer); println(obj.fraction); println(obj.double); &#125; &#125; json 输出 1234567891011121314151617181920212223242526import groovy.json.JsonOutput class Example &#123; static void main(String[] args) &#123; def output = JsonOutput.toJson([name: 'John', ID: 1]) println(output); &#125;&#125;// 输出&#123;"name":"John","ID":1&#125;// 作用于普通 groovy 对象class Example &#123; static void main(String[] args) &#123; def output = JsonOutput.toJson([ new Student(name: 'John',ID:1), new Student(name: 'Mark',ID:2)]) println(output); &#125; &#125; class Student &#123; String name int ID; &#125; DSLSGroovy允许在顶层语句的方法调用的参数周围省略括号。这被称为“命令链”功能。这个扩展的工作原理是允许一个人链接这种无括号的方法调用，在参数周围不需要括号，也不需要链接调用之间的点。 DSL或域特定语言旨在简化以Groovy编写的代码，使得它对于普通用户变得容易理解。以下示例显示了具有域特定语言的确切含义。 参考资料： Groovy 使用完全解析 Groovy基础——接口的实现方式 Groovy教程]]></content>
      <categories>
        <category>编程</category>
        <category>groovy</category>
      </categories>
      <tags>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据传输的加密]]></title>
    <url>%2F2018%2F06%2F22%2F%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[简介加密算法首先分为两种：单向加密、双向加密 单向加密是不可逆的，只能加密，不能解密，钥匙即本身。通常用来传输类似用户名和密码，直接将加密后的数据提交到后台，因为后台不需要知道用户名和密码，可以直接将收到的加密后的数据存储到数据库。 双向加密通常分为对称加密和非对称加密。对称加密指的是，加密和解密使用的是同一把秘钥。非对称加密指的是，加密和解密双方事先生成一对秘钥，使用其中的一把作为公钥用来加密信息，并且只能使用对应的私钥进行解密信息。这样可以避免钥匙的传输风险了。 常用算法 几种对称性加密算法：AES,DES,3DES DES是一种分组数据加密技术（先将数据分成固定长度的小数据块，之后进行加密），速度较快，适用于大量数据加密，而3DES是一种基于DES的加密算法，使用3个不同密匙对同一个分组数据块进行3次加密，如此以使得密文强度更高。 相较于DES和3DES算法而言，AES算法有着更高的速度和资源使用效率，安全级别也较之更高了，被称为下一代加密标准。 几种非对称性加密算法：RSA,DSA,ECC RSA和DSA的安全性及其它各方面性能都差不多，而ECC较之则有着很多的性能优越，包括处理速度，带宽要求，存储空间等等。 RSA 通常采用1024位，ECC 160 位, AES 128 位 几种线性散列算法（签名算法，单向加密，不可逆加密）：MD5,SHA1,SHA-2,HMAC 这几种算法只生成一串不可逆的密文，经常用其效验数据传输过程中是否经过修改，因为相同的生成算法对于同一明文只会生成唯一的密文，若相同算法生成的密文不同，则证明传输数据进行过了修改。通常在数据传说过程前，使用MD5和SHA1算法均需要发送和接收数据双方在数据传送之前就知道密匙生成算法，而HMAC与之不同的是需要生成一个密匙，发送方用此密匙对数据进行摘要处理（生成密文），接收方再利用此密匙对接收到的数据进行摘要处理，再判断生成的密文是否相同。 MD5即Message-Digest Algorithm 5（信息-摘要算法 5），用于确保信息传输完整一致，目前广泛用于错误检查，例如种子下载的碎片完整性。输入不定长的数据，输出为128位的hash值。 SHA-1: SHA-1在许多安全协议中广为使用，包括TLS和SSL、PGP、SSH、S/MIME和IPsec，曾被视为是MD5（更早之前被广为使用的散列函数）的后继者。但SHA-1的安全性如今被密码学家严重质疑。 SHA-2: SHA-224、SHA-256、SHA-384，和SHA-512并称为SHA-2。输出的hash的位数不一样。 参考文档： 各种加密算法比较 HTTP和HTTPS的区别]]></content>
      <tags>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 远程构建]]></title>
    <url>%2F2018%2F06%2F20%2Fdocker-%E8%BF%9C%E7%A8%8B%E6%9E%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[docker 远程连接docker server和client是分开的，因此支持远程连接 dockerd 设置方法1： 修改 /etc/default/docker 文件 DOCKER_OPTS=&quot;-H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375&quot; 方法2： 修改 /etc/systemd/system/docker.service 文件 ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:2375 重启docker服务 systemctl daemon-reload &amp;&amp; systemctl restart docker TSL 认证如果主机在公网环境，则需要使用TSL认证 参考资料： Docker Daemon连接方式详解]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑苹果安装记录]]></title>
    <url>%2F2018%2F06%2F20%2F%E9%BB%91%E8%8B%B9%E6%9E%9C%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[笔记本配置： 项目 详情 型号 | 神舟战神Z6-i78154S2CPU | Intel-core i7-4720HQ核心显卡 | Intel Graphics HD 4600独显 | NVIDIA GTX 960M 这是我的Config文件 软件准备： transMac 烧录镜像 DiskGenius 硬盘分区工具 BIOS + MBR 转 GPT + EFI 使用U盘 PE 系统，将硬盘MBR分区表备份出来 使用DG 软件将MBR 转为 GPT 分区 挂载ESP分区,很关键，不然无法启动系统 bcdboot c:\windows /s X: /f uefi /l zh-cn 其中X为你指派的ESP分区盘符。（修复UEfi也可借助工具） 查看ESP分区是否已经写入了efi等启动文件 参考链接：免重装系统 手把手教你MBR转GPT分区表 已经驱动的硬件： 显卡 声卡 键盘 背光亮度 麦克风 摄像头 无解： 无线网卡，准备换一个博通的 蓝牙 修复黑苹果和windows系统时间不同步的问题：bios 时钟设置UTC时间，mac OS 自动识别到UTC+8的时间，但是windows无法变成UTC+8, 因此需要在windows上面执行如下指令： Reg add HKLM\SYSTEM\CurrentControlSet\Control\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 修复黑苹果睡眠重启问题：参考链接 参考链接： 修改屏幕亮度的快捷键]]></content>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cloudera和CDH5的安装]]></title>
    <url>%2F2018%2F06%2F15%2FCloudera%E5%92%8CCDH5%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1.准备工作1.安装Oracel JDK（所有节点）查看cloudera官网上堆系统的要求安装jdk版本，查看链接CDH5.11.X要求JDK1.7u55 or higher 、JDK1.8u31 or higher，要求集群所有机器的JDK版本一致 2.安装Mysql （主节点）集群中至少有一台机器安装mysql，建议安装在主节点机器上。安装mysql参考链接 mysql配置 1234567# 配置mysql数据库远程连接$ mysql -uroot -p123456mysql&gt;grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;mysql&gt;flush privileges;$ sudo vi /etc/mysql/my.confbind-address=127.0.0.1 注释掉$ sudo service mysql restart 生成CDH5所需数据库 123456789101112131415161718create database amon default character set utf8;grant all on amon.* to 'amon'@'%' identified by 'amon';create database rman default character set utf8;grant all on rman.* to 'rman'@'%' identified by 'rman';create database metastore default character set utf8;grant all on metastore.* to 'hive'@'%' identified by 'hive';create database sentry default character set utf8;grant all on sentry.* to 'sentry'@'%' identified by 'sentry';create database nav default character set utf8;grant all on nav.* to 'nav'@'%' identified by 'nav';create database navms default character set utf8;grant all on navms.* to 'navms'@'%' identified by 'navms';create database hue default character set utf8 default collate utf8_general_ci;grant all on hue.* to 'hue'@'%' identified by 'hue';select * from information_schema.schemata;create database oozie;grant all privileges on oozie.* to 'oozie'@'localhost' identified by 'oozie';grant all privileges on oozie.* to 'oozie'@'%' identified by 'oozie'; 3.网络配置 （所有节点）12345678910111213# 1.修改hostnamesudo vi /etc/hostsname ==&gt; cloud01,cloud02,cloud03# 2. 修改ip映射sudo vi /etc/hosts ==&gt; example: 192.168.1.1 cloud01[,other name]192.168.1.3 cloud02[,other name]192.168.1.3 cloud03[,other name]# 3. 关闭防火墙sudo apt-get install ufw -ysudo ufw stopsudo ufw status //查看防火墙状态 3.设置SSH无密码访问123456789101112131415161718192021222324252627# 1.生成密钥对，集群所有机器上执行命令ssh-keygen -t rsa //默认生成两个文件 ~/.ssh/id_rsa ~/.ssh/id_rsa.pub# 2.选择集群一台机器，例如cloud01,假设集群有5台机器root@cloud01:~# for ip in `seq 1 5`;do scp root@cloud0$ip:~/.ssh/id_rsa.pub ~/.ssh/rsa_temp &amp;&amp; cat ~/.ssh/rsa_temp &gt;&gt; ~/.ssh/authorized_keys;done //此时会在~/.ssh/目录下生成authorizied_keys文件root@cloud01:~# for ip in `seq 2 5`;do scp ~/.ssh/authorized_keys root@cloud0$ip:~/.ssh/;done //复制authorizedkeys到其他的主机中root@cloud01:~# rm ~/.ssh/rsa_temp# 3.SSH服务器配置root@cloud01:~# vi /etc/ssh/sshd_configPermitRootLogin yes //修改默认的without password# 4.重启SSH服务sudo service sshd restart# 5.免密码登录失败原因1、权限问题.ssh目录，以及/home/当前用户 需要700权限，参考以下操作调整sudo chmod 700 ~/.sshsudo chmod 700 /home/当前用户.ssh目录下的authorized_keys文件需要600或644权限，参考以下操作调整sudo chmod 600 ~/.ssh/authorized_keys 4.配置NTP时间同步服务（所有节点） 时间服务器配置（主节点） 123456789101112131415161718192021222324252627# 所有节点安装ntp服务sudo apt-get install ntp#查看服务是否启动service --status-all[+]表示启动#选择cloud01作为时间同步服务器ssh cloud01sudo vi /etc/ntp.conf=====1. 修改serverserver [IP or hostname] [prefer]在 server 后端可以接 IP 或主机名，个人比较喜欢使用 IP 来设定， perfer 表示『优先使用』的服务器。server 2.cn.pool.ntp.org preferserver 0.asia.pool.ntp.org preferserver 3.asia.pool.ntp.org prefer2. 修改本地server#让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端server 127.127.1.0fudge 127.127.1.0 stratum 53. restrict管理时间服务器权限#不允许来自公网上ipv4和ipv6客户端的访问restrict -4 default kod notrap nomodify nopeer noqueryrestrict -6 default kod notrap nomodify nopeer noquery#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap===== 请求对时客户端配置（其他节点） 123456#安装ntp服务sudo apt-get install ntpsudo vi /etc/ntp.conf#去掉之前默认的serverserver 192.168.1.1（时间服务器的ip）fudge 192.168.1.1 stratum 5 对时操作 12345678910111. 使用ntp服务对时$ sudo service ntp stop$ sudo ntpdate 时间服务器ip$ sudo service ntp start2.查看时间状态$ timedatectl status$ sudo ntpq -p3.更换时区$ sudo tzselect 5.修改source.list123456# 1.增加两个源deb [arch=amd64] http://archive.cloudera.com/cm5/ubuntu/trusty/amd64/cm trusty-cm5 contribdeb-src http://archive.cloudera.com/cm5/ubuntu/trusty/amd64/cm trusty-cm5 contrib# 2.更新sudo apt-get update 2.安装CDH1.下载CDH安装包（主节点）Ubuntu14.04下载链接（CM5.11）cloudera-manager下载链接CDH5下载链接123456789101112131415# 1.解压安装包sudo mkdir /opt/cloudera-managersudo tar xzf cloudera-manager*.tar.gz -C /opt/cloudera-manager# 假设$CMF_DEFAULTS=/opt/cloudera-manager/cm-5.11.1# 2.初始化数据库sudo $CMF_DEFAULTS/share/cmf/schema/scm_prepare_database.sh mysql cm -hMasterNode -uroot -p123456 --scm-host MasterNode scm scm scm# 3.修改angent配置sudo vi $CMF_DEFAULTS/etc/cloudera-scm-agent/config.ini server_host = MasterNode# 4.复制cloudera-manager到其他主机root@cloud01:~# for $ip in `seq 2 5`;do scp -r $CMF_DEFAULTS/ root@cloud0$ip:/opt/ 2.为CDH创建用户（所有节点）1root@cloud01:~# useradd --system --home=$CMF_DEFAULTS/run/cloudera-scm-server --no-create-home --shell=/bin/false --comment "Cloudera SCM User" cloudera-scm 3.创建相关文件夹（主节点）12$ sudo mkdir /var/lib/cloudera-scm-server$ sudo chown cloudera-scm:cloudera-scm /var/lib/cloudera-scm-server 4.准备Parcels，用于安装CDH51234567891011# 1.主节点放置CDH5 Parcel 库文件$ sudo mkdir -p /opt/cloudera/parcel-repo$ sudo chown cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo$ sudo mv /path/to/CDH5.parcel /opt/cloudera/parcel-repo/ $ sudo mv /path/to/CDH5.parcel.sha1 /opt/cloudera/parcel-repo/CDH5.parcel.sha$ sudo mv /path/to/manifest.json /opt/cloudera/parcel-repo/# 2.所有节点创建parcels目录$ sudo mkdir -p /opt/cloudera/parcels$ sudo chown cloudera-scm:cloudera-scm /opt/cloudera/parcels 5.启动cloudera scm 服务1234567891011121314151617# 1. 主节点启动server服务$ root@cloud01:~# /$CMF_DEFAULTS/etc/init.d/cloudera-scm-server start//server启动日志/var/log/cloudera-scm-server/cloudera-scm-server.log# 2. 所有节点启动agent服务$ root@cloud01:~# /$CMF_DEFAULTS/etc/init.d/cloudera-scm-agent start//agent启动日志/var/log/cloudera-scm-agent/cloudera-scm-agent.log# 3.设置机器重启自动运行服务$ cp $CMF_DEFAULTS/etc/init.d/cloudera-scm-server /etc/init.d/cloudera-scm-server$ update-rc.d cloudera-scm-server defaults$ cp $CMF_DEFAULTS/etc/init.d/cloudera-scm-agent /etc/init.d/cloudera-scm-agent$ update-rc.d cloudera-scm-agent defaults# 4.取消自动重启$ sudo update-rc.d -f cloudera-scm-agent remove tips:这一步如果没有完成好，会导致后面的cloudera-manager agent安装出错，推荐顺序启动/opt目录下的agent服务设置步骤3，但不要使用service 命令启动安装完成后，可以去掉自动重启（执行步骤4） 6.CDH5网页配置 打开http://clouder-server-host:7180 默认密码是admin 选择免费版本，不需要安装JDK root用户登录，提前将集群机器的root密码设置一样，并且打通root用户的ssh登录 7.安装kafka服务1.下载kafka parcel，在线或者离线都可以，然后在集群所有机器中分发激活Kafka Parcel 2.集群添加kafka服务若提示，或者错误日志中提示Java Heap空间太小：Missing required value: Destination Broker ListMissing required value: Source Broker List 可按如下方法配置后重试即可：a. 填写Source Brokers List填写Kafka Broker所在节点构成的列表（用逗号分隔），如下（本文在所有节点部署了Kafka Broker）：master:9092,slave1:9092,slave2:9092,slave3:9092,slave4:9092 b. 填写Destination Brokers List若添加了Kafka MirrorMaker，则可填写其所在节点构成的列表；若未添加Kafka MirrorMaker，可填写任意服务器即可，如下：master:9092,slave1:9092,slave2:9092,slave3:9092,slave4:9092或：example.com:9092 c. 修改Java Heap Size填写上面列表后，点击继续，出错后，Kafka服务未启动。返回集群配置，打卡Kafka服务配置页，查找“Java Heap Size of Broker”项，将对大小从50MB修改为256MB。d. 配置Topic Whitelist配置Topic Whitelist项为正则表达式：(?!x)x，保存更改。然后添加角色实例，重新配置即可。参考链接：adding a Kafka service failed 3.CDH5安装常见问题1. 主机检查警告123456789101112131415161718第一个警告： Cloudera 建议将 /proc/sys/vm/swappiness 设置为 10。当前设置为 60。使用 sysctl 命令在运行时更改该设置并编辑 /etc/sysctl.conf 以在重启后保存该设置。 echo 10 &gt; /proc/sys/vm/swappiness这样操作重启机器还是还原，要永久改变vim /etc/sysctl.confvm.swappiness=10 第二个警告，提示执行命令： echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled执行完毕，重启后，警告依然，暂时不处理 2.mysql数据库生成报错123456789# 1.主要是系统的java环境中没有连接数据库的包，因此需要手动把包拷贝到系统目录$ sudo cp mysql-connector-*.jar /usr/share/java/mysql-connector-java.jar# 2.设置mysql远程登录和访问权限问题mysql&gt;grant all privileges on . to ‘root’@’%’ identified by ‘youpassword’ with grant option;mysql&gt;flush privileges;$ sudo vi /etc/mysql/my.confcomment bind-address = 127.0.0.1$ sudo service mysql restart 3.kafka安装问题参考官方教程，分配Kafka parcel包，第一次安装会遇到问题，解决方案如下：http://www.aboutyun.com/thread-19903-1-1.html 4.参考链接http://www.cnblogs.com/codedevelop/p/6762555.html 5.agent启动报错ProtocolError: &lt;ProtocolError for 127.0.0.1/RPC2: 401 Unauthorized&gt;resolution:Steps to find and kill the process:1) Find the port which is used by supervisor: ps aux |grep supervisor2) kill the portsudo kill -9]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>cloudera</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins使用]]></title>
    <url>%2F2018%2F06%2F12%2Fjenkins%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[jenkins 是一个自动化集成工具，可以实现对程序员完全透明化，只需要专注于自己的业务代码即可 安装准备工作：硬件条件：256 MB of RAM + 1 GB of drive space软件条件：JRE 8 docker docker 方式安装 install docker 安装jenkins 启动 docker container123456789docker run \ -u root \ --rm \ -d \ -p 8080:8080 \ -p 50000:50000 \ -v jenkins-data:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkinsci/blueocean download war file java -jar jenkins.war brows http://localhost:8080 and wait until the Unlock Jenkins page appears. apt 方式安装1234wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'sudo apt-get updatesudo apt-get install jenkins 使用jenkins 本身是一个持续集成部署的工具，可以和很多工具平台联动。 credentialscredentials 主要是用来存储一些用户密码、token 这些敏感信息 配置： Credentials &gt; Create permission detail… pipeline（流水线）环境配置： jenkins version &gt;= 2.x pipeline plugin in jenkins 定义一个流水线：通过编写Jenkinsfile 来完成流水线作业。 Jenkinsfile 采用 groovy 语法 jenkins 支持两种类型的流水线： 一种是 Declarative Pipeline, 另一种是 scripted pipeline, 个人推荐使用第二种，简洁 使用例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243# declarative pipelinepipeline &#123; agent any environment &#123; CC = 'clang' &#125; stages &#123; stage('Build') &#123; steps &#123; echo 'Building..' &#125; &#125; stage('Test') &#123; steps &#123; echo 'Testing..' &#125; &#125; stage('Deploy') &#123; steps &#123; echo 'Deploying....' &#125; &#125; &#125;&#125;# scripted pipelinenode &#123; withEnv(['CC=lang']) &#123; &#125; stage('Build') &#123; echo 'Building....' &#125; stage('Test') &#123; echo 'Building....' &#125; stage('Deploy') &#123; echo 'Deploying....' &#125;&#125; agent/node: instructs Jenkins to allocate an executor (on any available agent/node in the Jenkins environment) and workspace for the entire Pipeline. 环境变量：http://localhost:8080/pipeline-syntax/globals#env 常用的环境变量：BUILD_IDJOB_NAMEJENKINS_URL pipeline generateorclick http://localhost:8080/pipeline-syntax/ 可以看到很多帮助文档，其中Snippet Generator 用来生成scripted pipeline, Declarative Directive Generator 生成 declarative pipeline handle credentials通过环境变量注入的方式, 前提是已经做好了credentials, 这里只是提供了一个读取的方法 12345678910111213141516# secret textenvironment &#123; AWS_ACCESS_KEY_ID = credentials('jenkins-aws-secret-key-id') AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')&#125;# username and passwordenvironment &#123; BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')&#125;## actually environment variablesBITBUCKET_COMMON_CREDS - contains a username and a password separated by a colon in the format username:password.BITBUCKET_COMMON_CREDS_USR - an additional variable containing the username component only.BITBUCKET_COMMON_CREDS_PSW - an additional variable containing the password component only. 其他的证书获取的方法可以参考 generator handle parameters1234567891011121314151617181920pipeline &#123; agent any parameters &#123; string(name: 'Greeting', defaultValue: 'Hello', description: 'How should I greet the world?') &#125; stages &#123; stage('Example') &#123; steps &#123; echo "$&#123;params.Greeting&#125; World!" &#125; &#125; &#125;&#125;# scripted pipelineproperties([parameters([string(defaultValue: 'Hello', description: 'How should I greet the world?', name: 'Greeting')])])node &#123; echo "$&#123;params.Greeting&#125; World!"&#125; handle failure12345678910111213141516171819202122232425262728293031323334pipeline &#123; agent any stages &#123; stage('Test') &#123; steps &#123; sh 'make check' &#125; &#125; &#125; post &#123; always &#123; junit '**/target/*.xml' &#125; failure &#123; mail to: team@example.com, subject: 'The Pipeline failed :(' &#125; &#125;&#125;# scripted pipelinenode &#123; /* .. snip .. */ stage('Test') &#123; try &#123; sh 'make check' &#125;catch&#123; mail to: team@example.com, subject: 'The Pipeline failed :(' &#125; finally &#123; junit '**/target/*.xml' &#125; &#125; /* .. snip .. */&#125; 多个 angent/node 运行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273pipeline &#123; agent none stages &#123; stage('Build') &#123; agent any steps &#123; checkout scm sh 'make' stash includes: '**/target/*.jar', name: 'app' &#125; &#125; stage('Test on Linux') &#123; agent &#123; label 'linux' &#125; steps &#123; unstash 'app' sh 'make check' &#125; post &#123; always &#123; junit '**/target/*.xml' &#125; &#125; &#125; stage('Test on Windows') &#123; agent &#123; label 'windows' &#125; steps &#123; unstash 'app' bat 'make check' &#125; post &#123; always &#123; junit '**/target/*.xml' &#125; &#125; &#125; &#125;&#125;# scripted pipelinestage('Build') &#123; node &#123; checkout scm sh 'make' stash includes: '**/target/*.jar', name: 'app' &#125;&#125;stage('Test') &#123; node('linux') &#123; checkout scm try &#123; unstash 'app' sh 'make check' &#125; finally &#123; junit '**/target/*.xml' &#125; &#125; node('windows') &#123; checkout scm try &#123; unstash 'app' bat 'make check' &#125; finally &#123; junit '**/target/*.xml' &#125; &#125;&#125; stash： 捕获对应的文件，让流水线的其他angent 一起使用 label: jenkins lable expression mutibranch pipeline多分支的scm 流水线 detail docker pipeline12345678910111213141516171819202122pipeline &#123; agent &#123; docker &#123; image 'node:7-alpine' &#125; &#125; stages &#123; stage('Test') &#123; steps &#123; sh 'node --version' &#125; &#125; &#125;&#125;# scripted pipelinenode &#123; /* Requires the Docker Pipeline plugin to be installed */ docker.image('node:7-alpine').inside &#123; stage('Test') &#123; sh 'node --version' &#125; &#125;&#125; 缓存 docker container 数据12345678910111213141516171819202122232425pipeline &#123; agent &#123; docker &#123; image 'maven:3-alpine' args '-v $HOME/.m2:/root/.m2' &#125; &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'mvn -B' &#125; &#125; &#125;&#125;# scripted pipelinenode &#123; /* Requires the Docker Pipeline plugin to be installed */ docker.image('maven:3-alpine').inside('-v $HOME/.m2:/root/.m2') &#123; stage('Build') &#123; sh 'mvn -B' &#125; &#125;&#125; 使用多容器1234567891011121314151617181920212223242526272829303132333435363738pipeline &#123; agent none stages &#123; stage('Back-end') &#123; agent &#123; docker &#123; image 'maven:3-alpine' &#125; &#125; steps &#123; sh 'mvn --version' &#125; &#125; stage('Front-end') &#123; agent &#123; docker &#123; image 'node:7-alpine' &#125; &#125; steps &#123; sh 'node --version' &#125; &#125; &#125;&#125;# scripted pipelinenode &#123; /* Requires the Docker Pipeline plugin to be installed */ stage('Back-end') &#123; docker.image('maven:3-alpine').inside &#123; sh 'mvn --version' &#125; &#125; stage('Front-end') &#123; docker.image('node:7-alpine').inside &#123; sh 'node --version' &#125; &#125;&#125; 使用 DockerfileJenkins 支持从 scm 的 Dockerfile 来构建镜像并运行，而不是从镜像仓库里面拉取 123# file DockerfileFROM node:7-alpineRUN apk add -U subversion Jenkinsfile1234567891011pipeline &#123; agent &#123; dockerfile true &#125; stages &#123; stage('Test') &#123; steps &#123; sh 'node --version' sh 'svn --version' &#125; &#125; &#125;&#125; sidecar(解决docker 服务依赖问题)12345678910111213node &#123; checkout scm /* * In order to communicate with the MySQL server, this Pipeline explicitly * maps the port (`3306`) to a known port on the host machine. */ docker.image('mysql:5').withRun('-e "MYSQL_ROOT_PASSWORD=my-secret-pw" -p 3306:3306') &#123; c -&gt; /* Wait until mysql service is up */ sh 'while ! mysqladmin ping -h0.0.0.0 --silent; do sleep 1; done' /* Run some tests which require MySQL */ sh 'make check' &#125;&#125; 通过 docker link 来链接mysql 服务, cenos 提供了一个程序执行环境 12345678910111213141516node &#123; checkout scm docker.image('mysql:5').withRun('-e "MYSQL_ROOT_PASSWORD=my-secret-pw"') &#123; c -&gt; docker.image('mysql:5').inside("--link $&#123;c.id&#125;:db") &#123; /* Wait until mysql service is up */ sh 'while ! mysqladmin ping -hdb --silent; do sleep 1; done' &#125; docker.image('centos:7').inside("--link $&#123;c.id&#125;:db") &#123; /* * Run some tests which require MySQL, and assume that it is * available on the host name `db` */ sh 'make check' &#125; &#125;&#125; 构建新的镜像12345678910111213141516171819202122232425262728293031323334353637383940414243444546node &#123; checkout scm def customImage = docker.build("my-image:$&#123;env.BUILD_ID&#125;") customImage.inside &#123; sh 'make test' &#125;&#125;# 如何pushnode &#123; checkout scm def customImage = docker.build("my-image:$&#123;env.BUILD_ID&#125;") customImage.push()&#125;# 如何打tagnode &#123; checkout scm def customImage = docker.build("my-image:$&#123;env.BUILD_ID&#125;") customImage.push() customImage.push('latest')&#125;# 自定义dockerfile, 添加 build 函数参数node &#123; checkout scm // Builds test-image from the Dockerfile found at ./dockerfiles/test/Dockerfile. def testImage = docker.build("test-image", "./dockerfiles/test") testImage.inside &#123; sh 'make test' &#125;&#125;node &#123; //Builds my-image:$&#123;env.BUILD_ID&#125; from the Dockerfile found at ./dockerfiles/Dockerfile.test checkout scm def dockerfile = 'Dockerfile.test' def customImage = docker.build("my-image:$&#123;env.BUILD_ID&#125;", "-f $&#123;dockerfile&#125; ./dockerfiles") &#125; 自定义 registry1234567891011121314151617181920node &#123; checkout scm docker.withRegistry('https://registry.example.com') &#123; docker.image('my-custom-image').inside &#123; sh 'make test' &#125; &#125;&#125;# authenticationnode &#123; checkout scm //add a "Username/Password" Credentials item from the Jenkins home page docker.withRegistry('https://registry.example.com', 'credentials-id') &#123; def customImage = docker.build("my-image:$&#123;env.BUILD_ID&#125;") /* Push the container to the custom Registry */ customImage.push() &#125;&#125; 共享库Extending with Shared Libraries pipeline 语法1 Declarative Pipelines 1234pipeline &#123; /* insert Declarative Pipeline here */&#125; detail blueocean一款新的UI，detail jenkins in k8sJenkins Server和slave节点直接有几种连接方式：ssh连接和jnlp连接。Kubernetes plugin插件用的是jnlp方式。这种方式是通过运行slave.jar，指定Jenkins Server的url参数和secret token参数，来建立连接。 docker 运行jenkins slave (ssh 模式)这种模式docker 运行一个slave 容器跟普通物理机使用完全一致，这里不做说明。 同样可以再在同一个slave节点（docker 容器）上绑定很多个工程或者任务。 docker 运行jenkins slave (jnlp 模式)Jnlp 模式的则相对应用的比较少，jnlp 是由jenkins slave节点（物理节点，虚机或者容器均可）发起连接的，他 会根据配置的jenkins master的url , Jenkins连接的token和jenkins slave name( lable)来进行进行连接。 jenkins k8s plugins的使用配置安装 kubernetes plugins ，进入jenkins 系统设置，如下图所示 注意事项： 在使用自定义的镜像的时候，因为/home/jenkins 目录被挂载到了NFS上面，因此在镜像中保留的文件全部被清空掉，kube/config文件需要通过NFS才能挂载 参考资料: Jenkins On Kubernetes—Jenkins上Kubernetes Plugin的使用 初试 Jenkins 使用 Kubernetes Plugin 完成持续构建与发布 Kubernetes集群上基于Jenkins的CI/CD流程实践]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s学习-1--常用命令]]></title>
    <url>%2F2018%2F04%2F27%2Fk8s%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[k8s 采用声明式的 API , 因此许多命令可以组合使用 查看查看资源 kubectl get \&lt;resource type\&gt; | all [-n namespace] [-o wide] 查看集群 kubectl cluster-info 查看各组件的状态 kubectl -s http://masterip:8080 get componentstatuses 详细信息查看资源的详细信息，类似docker inspect kubectl describe \&lt;resource type\&gt; 创建创建k8s资源 kubectl create -f filename filename 为定义资源的yaml文件。也可以直接只用子命令 [run/namespace/secret/configmap/serviceaccount] 等直接创建相应的resource。从追踪和维护的角度出发，建议使用json或yaml的方式定义资源。 更新更新资源有以下几种方式： 1.replace kubectl replace -f filename replace命令用于对已有资源进行更新、替换。当我们需要更新resource的一些属性的时候，如果修改副本数量，增加、修改label，更改image版本，修改端口等。都可以直接修改原yaml文件，然后执行replace命令。 注意名字不可以被更新 2.patch 对一个已经在运行的pod进行更新操作，不会删除容器 3.edit 交互式编辑资源文件并更新 4.apply 比 pathch 和 edit 更加严格的更新操作，保留更新历史版本库 5.rolling-update 不中断更新，先产生新的 pod, 更新完成后再生成再删除旧的 pod, 直到替换掉所有的pod 6.scale 资源的扩容或缩容 7.autoscale 自动根据系统资源的情况进行扩容或缩容 删除kubectl delete &lt;resource type&gt; 日志kubectl logs 进入容器kubectl attach kubectl exec [-c container-name] 节点管理kubectl get nodes //查看所有节点 节点维护：cordon, drain, uncordon cordon: 标记节点为SchedulingDisable, 禁止新的资源被调度到该节点 drain: 将要维护的节点的pod赶到其他的节点 uncordon: 恢复维护节点到正常的工作状态]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据平台维护笔记]]></title>
    <url>%2F2017%2F06%2F09%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%BB%B4%E6%8A%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1.hdfs文件迁移方法：参考链接：http://blog.csdn.net/bigkeen/article/details/51034902http://www.cnblogs.com/juncaoit/p/6178747.htmlhttp://blog.csdn.net/weipanp/article/details/42713149 可以相互通信的两个集群在老的hadoop集群中开启yarn和hdfs服务，新的集群开启hdfs服务即可执行以下命令： 1hadoop distcp -i hftp://old cluster ip:50070/src directory hdfs://192.168.91.130:8020/new cluster directory 删除老集群的hdfs文件使用hdfs命令删除文件后执行hadoop dfs -expunge删除对应的DataNode和namenode路径下的文件夹 2.多次格式化NameNode导致无法启动DataNode的解决方案http://www.cnblogs.com/yeahwell/p/5642798.html 3.查看某端口被映射到端口上iptables -t nat -L -n | grep 80iptables -t nat –list //检查nat列表信息iptables -t nat -D PREROUTING 1 /Nat列表信息删除：序号从1 开始，后边以此+1. 参考链接：http://blog.csdn.net/xin_yu_xin/article/details/46416101 4.安装mysqlhttp://blog.csdn.net/chenpy/article/details/50344085 5.storm 并行度rebalance操作：http://blog.csdn.net/jmppok/article/details/17243857storm并行度理解：http://www.cnblogs.com/catkins/p/5254377.html 6.自定义系统定制Ubuntu镜像：https://www.zybuluo.com/fanisfun/note/802272 7.cloudera-agent 启动报错解决方法错误1：ERROR Failed to connect to previous supervisor.通常是由于之前已经启动了agent残留下来的进程产生的影响，因此需要将之前的进程清除掉执行命令 kill -9 $(pgrep -f supervisord) 然后重启，除了第一次安装要求复制cloudera-agent到系统/etc/init.d/目录下，建议放置到rc.local文件启动吧]]></content>
      <categories>
        <category>笔记</category>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe相关博客]]></title>
    <url>%2F2017%2F06%2F04%2Fcaffe%E7%9B%B8%E5%85%B3%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[深度学习（六）caffe入门学习 Deep Learning模型之：CNN卷积神经网络（一）深度解析CNN - 莫小 - 博客园]]></content>
      <categories>
        <category>笔记</category>
        <category>caffe</category>
      </categories>
      <tags>
        <tag>caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解Linux系统/etc/init.d目录和/etc/rc.local脚本]]></title>
    <url>%2F2017%2F05%2F24%2F%E7%90%86%E8%A7%A3Linux%E7%B3%BB%E7%BB%9F-etc-init-d%E7%9B%AE%E5%BD%95%E5%92%8C-etc-rc-local%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[一、关于/etc/init.d如果你使用过Linux系统，那么你一定听说过init.d目录。这个目录到底是干嘛的呢？它归根结底只做了一件事情，但这件事情非同小可，是为整个系统做的，因此它非常重要。init.d目录包含许多系统各种服务的启动和停止脚本。它控制着所有从acpid到x11-common的各种事务。当然，init.d远远没有这么简单。（译者注：acpid 是linux操作系统新型电源管理标准 ；X11也叫做X Window系统，X Window系统 (X11或X)是一种位图显示的 视窗系统 。它是在 Unix 和 类Unix 操作系统 ，以及 OpenVMS 上建立图形用户界面 的标准工具包和协议，并可用于几乎已有的现代操作系统）。 当你查看/etc目录时，你会发现许多rc#.d 形式存在的目录（这里#代表一个指定的初始化级别，范围是0~6）。在这些目录之下，包含了许多对进程进行控制的脚本。这些脚本要么以”K”开头，要么以”S”开头。以K开头的脚本运行在以S开头的脚本之前。这些脚本放置的地方，将决定这些脚本什么时候开始运行。在这些目录之间，系统服务一起合作，就像运行状况良好的机器一样。然而，有时候你希望能在不使用kill 或killall 命令的情况下，能干净的启动或杀死一个进程。这就是/etc/init.d能够派上用场的地方了！ 如果你在使用Fedora系统，你可以找到这个目录：/etc/rc.d/init.d。实际上无论init.d放在什么地方，它都发挥着相同的作用。 为了能够使用init.d目录下的脚本，你需要有root权限或sudo权限。每个脚本都将被作为一个命令运行，该命令的结构大致如下所示： /etc/init.d/command 选项comand是实际运行的命令，选项可以有如下几种： start stop reload restart force-reload 大多数的情况下，你会使用start,stop,restart选项。例如，如果你想关闭网络，你可以使用如下形式的命令：123456789101112 /etc/init.d/networking stop又比如，你改变了网络设置，并且需要重启网络。你可以使用如下命令：/etc/init.d/networking restartinit.d目录下常用初始化脚本有：networkingsambaapache2ftpdsshddovecotmysql 当然，你可能有其他更多常用的脚本，这个取决于你安装了什么linux操作系统。 二、关于/etc/rc.localrc.local也是我经常使用的一个脚本。该脚本是在系统初始化级别脚本运行之后再执行的，因此可以安全地在里面添加你想在系统启动之后执行的脚本。常见的情况是你可以再里面添加nfs挂载/mount脚本。此外，你也可以在里面添加一些调试用的脚本命令。例如，我就碰到过这种情况：samba服务总是无法正常运行，而检查发现，samba是在系统启动过程中就该启动执行的，也就是说，samba守护程序配置保证了这种功能本应该正确执行。碰到这种类似情况，一般我也懒得花大量时间去查为什么，我只需要简单的在/etc/rc.local脚本里加上这么一行： /etc/init.d/samba start 这样就成功的解决了samba服务异常的问题。 三、总结Linux是灵活的。正因为它的灵活性，我们总是可以找到许多不同的办法来解决同一个问题。启动系统服务的例子就是一个很好的佐证。有了/etc/init.d目录下的脚本，再加上/etc/rc.local这个利器，你可以放心的确保你的服务可以完美的启动和运行。]]></content>
      <categories>
        <category>IT</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统操作命令笔记（持续更新...）]]></title>
    <url>%2F2017%2F05%2F24%2F%E5%8E%9F-Ubuntu%E7%B3%BB%E7%BB%9F%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0-%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1、修改用户密码1sudo passwd =&gt;&gt;输入new-root-password 2、切换用户1su username =&gt;&gt;输入待切换用户的密码 3、提升权限12su root (临时提升权限)sudo gedit /etc/passwd (永久提升权限) 4、设置环境变量 为单个用户设置（～/.bashrc） 全局设置（/etc/profile） /etc/bashrc. 该文件是为每一个运行的shell用户执行操作，当bashshell被打开是，文件被读取 ～/bash_profile: 每个用户可以使用该文件输入专用于自己的shell信息 /etc/environment: 在登录的时候操作系统使用的的第二个文件，系统在读取你的profile之前，设置文件的环境变量 5、ssh使用1.登录远程主机ssh username@host [-p port] =&gt;input your host passwordequals (ssh -l username host)2.文件传输scp username@serverhost:/serverfile /save path (download from server)scp /local file username@serverhost:/server save path(upload to server)从服务器下载或者上传整个目录scp -r username@serverhost:/remote directory /local directoryscp -r /local directory username@serverhost:/remote directory3.开启无密码ssh登录client A; server B A: ssh-keygen -t rsa (三次回车，在～/.ssh目录下生成id_ras，id_rsa.pub两个文件，分别是私钥和公钥) A: cat ~/.ssh/id_ras.pub &gt;&gt; ~/.ssh/authorized-keys（复制公钥到文件authorized-keys） A: scp ~/.ssh/id_rsa.pub XXX@remotehost:/home/XXX/id_rsa.pub B: cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys(追加公钥到服务器的authorizied_keys文件中，注意登录到远程服务器操作此步骤) A: ssh-add ~/.ssh/id_rsa (添加私钥) 更改权限: chmod 700 ~/.ssh; chmod 600 ~/.ssh/authorized_keys 6、更改文件权限和所有者chmod [options] mode files/directorymode=u,g,o 7=4读+2写+1执行，u用户，g，用户组，o，其他+，-表示增加或者删除权限r,w,x表示读，写，执行三种权限，对应上面的三个数字。加上-R参数后就可以修改整个目录的文件的权限了。chown username file/directory 更改文件的所有者 7、系统查看指令tail -n number file 查看文件末尾number行cat file 查看文件所有内容ls -lh查看文件详细情du -lh查看单独文件的大小df -lh查看磁盘分区gnome-system-monitor 查看资源管理器 8、用户和用户组管理http://www.cnblogs.com/xd502djj/archive/2011/11/23/2260094.html 9、修改localehttp://dgd2010.blog.51cto.com/1539422/1684813http://blog.csdn.net/myweishanli/article/details/23576847]]></content>
      <categories>
        <category>IT</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu端口转发]]></title>
    <url>%2F2017%2F05%2F23%2Fubuntu%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[1. 内网有一台公网服务器iptables方法 2. 内网没有公网服务器，只有云服务器 思路：利用ssh反向代理实现内网穿透 准备工作：假设内网有机器A(192.168.1.2),机器B(192.168.1.3),机器A机器B在一个局域网内，但是只有机器A能够访问互联网，本身没有静态公网IP,机器B可以访问机器A，但是无法访问互联网。另外有一台可访问的云服务器C(公网IP: 104.28.39.108) 目的：实现在任意有网络的地方访问服务器A和服务器B 将机器A的ssh公钥复制到机器C的authorized_keys，实现A到C的免密码登陆 在机器A执行如下脚本： 12touch /home/hadoop/autossh/monitor-auto-ssh.sh &amp;&amp; chmod +x /home/hadoop/autossh/monitor-auto-ssh.shvim /home/hadoop/autossh/monitor-auto-ssh.sh monitor-auto-ssh.sh内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#! /bin/sh# check every 30 seconds# crontab -e# */1 * * * * bash /home/hadoop/autossh/monitor-auto-ssh.sh# * * * * * sleep 30; bash /home/hadoop/autossh/monitor-auto-ssh.shPROCESS_NAME='55566'PROCESS_PATH='/home/hadoop/autossh'START_PROCESS="autossh -f -M 55567 -NR 55566:localhost:22 hadoop@104.28.39.108"VPN_PROCESS="autossh -f -M 55577 -NR 10012:localhost:13838 hadoop@104.28.39.108"VPN_PROCESS_NAME="10012"#PORT_TRANS="ssh -C -f -N -g -R 8888:127.0.0.1:8888 hadoop@39.108.120.127"#PORT_TRANS_NAME="8888:127.0.0.1:8888"proc_num() #查询进程数量 &#123; num=`ps -ef | grep $&#123;PROCESS_NAME&#125; | grep -v grep | wc -l` return $num &#125; proc_num2()&#123; num=`ps -ef | grep $&#123;VPN_PROCESS_NAME&#125; | grep -v grep | wc -l` return $num&#125;proc_num number=$?proc_num2number2=$?if [ $number -eq 0 ] #如果进程数量为0 then #重新启动服务 echo "Restarting $&#123;PROCESS_NAME&#125; ..." echo $(date '+%Y-%m-%d %T') &gt;&gt; $&#123;PROCESS_PATH&#125;/restart.log ($&#123;START_PROCESS&#125;) &amp; echo "over"elif [ $number2 -eq 2 ]then echo "ssh proxy has been started!"fiif [ $number2 -eq 0 ] #如果进程数量为0 then #重新启动服务 echo "Restarting $&#123;VPN_PROCESS_NAME&#125; ..." echo $(date '+%Y-%m-%d %T') &gt;&gt; $&#123;PROCESS_PATH&#125;/restart.log ($&#123;VPN_PROCESS&#125;) &amp; echo "over"elif [ $number -eq 2 ]then echo "shadow proxy has been started!"fi 机器A执行定时检查任务，确保ssh隧道断开自动重连 1234# check every 30 secondscrontab -e*/1 * * * * bash /home/hadoop/autossh/monitor-auto-ssh.sh* * * * * sleep 30; bash /home/hadoop/autossh/monitor-auto-ssh.sh 服务器C需要在云网络安全组开放55566和10012两个端口，这两个端口分别通过隧道反向代理A机器的22号端口和13838端口 外网访问方式 ssh 指定机器C的55566端口就可以连接到A机器了，通过A机器可以跳转到B机器，实现间接链接 搭建VPN。在机器A上安装shadowsocks服务器端，并且设置端口为13838（要和脚本中的端口保持一致），然后客户端机器安装shadowsocks客户端,代理服务器地址为104.28.39.108，端口为10012，用户名和密码从A机器上获取。 至此，代理服务器搭建完毕，设置shadowsocks全局代理模式，默认将本地127.0.0.1的1080端口的请求全部转发到C服务器上的10012端口，而C服务器的10012端口通过autossh反向代理到了A机器的13838端口，从而实现了从外网任何一台可以上网的设备远程连接到没有公网环境的内网服务器A和服务器B，能够访问内网的任何服务。]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>iptable</tag>
        <tag>端口转发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu14.04下 Cloudera Manager和CDH5.11的配置]]></title>
    <url>%2F2017%2F05%2F23%2FCloudera%20Manager%E5%92%8CCDH5-11%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[本教程用于搭建Clodera Manager和CDH5的大数据分析平台的搭建工作 1.参考链接：http://www.cnblogs.com/codedevelop/p/6762555.html （博客园）http://blog.csdn.net/a921122/article/details/51939692 （csdn）http://blog.csdn.net/hualiu163/article/details/46659375 （CDH5.33 详细）http://www.aboutyun.com/thread-9075-1-1.html （在线安装，不推荐） 基本思路：集群主机ip配置，关闭防火墙，设置ssh无密码登录，统一root密码，集群时间同步，安装oracle jdk，主节点安装mysql，并初始化scm数据库，下载parcel包，进入控制台设置等 2.注意的问题：jdbc的问题：安装hive时，需要将mysql驱动包复制到/opt/cloudera/parcels/CDH/lib/hive/lib/目录下，并且需要把mysql驱动复制到/usr/share/java/mysql-connector-java.jar下 目录权限问题，ssh免密码登录问题，mysql远程访问设置。。。 注意要添加root用户的访问host，不然后面初始化会出问题grant all privileges on . to ‘root‘@’n1’ identified by ‘xxxx’ with grant option; 3、官方安装教程官方手动安装教程（强烈建议按照官方教程来操作，可以少走很多坑，阿西吧）：https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_install_path_c.html#id_v4k_pnn_25system requirement:https://www.cloudera.com/downloads/manager/5-11-0.html 4.主节点安装mysql5.6在线安装：http://blog.csdn.net/chenpy/article/details/50344085离线安装：http://blog.csdn.net/linlinv3/article/details/51774040注意要设置远程登录（具体参照官方教程：MySQL设置） 创建数据库：123456789101112131415161718192021222324create database amon default character set utf8;grant all on amon.* to 'amon'@'%' identified by 'amon';create database rman default character set utf8;grant all on rman.* to 'rman'@'%' identified by 'rman';create database metastore default character set utf8;grant all on metastore.* to 'hive'@'%' identified by 'hive';create database sentry default character set utf8;grant all on sentry.* to 'sentry'@'%' identified by 'sentry';create database nav default character set utf8;grant all on nav.* to 'nav'@'%' identified by 'nav';create database navms default character set utf8;grant all on navms.* to 'navms'@'%' identified by 'navms';create database hue default character set utf8 default collate utf8_general_ci;grant all on hue.* to 'hue'@'%' identified by 'hue';select * from information_schema.schemata;create database oozie;grant all privileges on oozie.* to 'oozie'@'localhost' identified by 'oozie';grant all privileges on oozie.* to 'oozie'@'%' identified by 'oozie'; master节点交换内存设置：http://blog.chinaunix.net/uid-20051192-id-3557817.html 这里注意下，官网教程上面的reboot后自动启动的命令有点问题，直接启动和命令启动的时候运行的进程不一致update-rc.d -f cloudera-scm-server removeupdate-rc.d -f cloudera-scm-agent remove貌似不能随便去掉这个过程，否则后面又会出现这个问题 安装kafka的问题：首先参考官方教程，分配kafka parcel包，然后安装，第一次安装会遇到问题，解决方案如下：http://www.aboutyun.com/thread-19903-1-1.html]]></content>
      <categories>
        <category>解决方案</category>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>CDH5</tag>
        <tag>Cloudera Manager</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux服务器时间同步]]></title>
    <url>%2F2017%2F04%2F25%2Flinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[Ubuntu下服务器时间同步1.时间服务器配置123456789101112131415161718192021222324252627282930#服务器cloud01,cloud02,cloud03都安装ntp服务sudo apt-get install ntp#查看服务是否启动service --status-all[+]表示启动#选择cloud01作为时间同步服务器ssh cloud01sudo vi /etc/ntp.conf=====1. 修改serverserver [IP or hostname] [prefer]在 server 后端可以接 IP 或主机名，个人比较喜欢使用 IP 来设定， perfer 表示『优先使用』的服务器。server 2.cn.pool.ntp.org preferserver 0.asia.pool.ntp.org preferserver 3.asia.pool.ntp.org prefer2. 修改本地server#让NTP Server和其自身保持同步，如果在/etc/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端server 127.127.1.0fudge 127.127.1.0 stratum 53. restrict管理时间服务器权限#不允许来自公网上ipv4和ipv6客户端的访问restrict -4 default kod notrap nomodify nopeer noqueryrestrict -6 default kod notrap nomodify nopeer noquery#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap===== 2.请求对时客户端配置这里cloud02和cloud03分别是客户端1234567#安装ntp服务sudo apt-get install ntpsudo vi /etc/ntp.conf#去掉之前默认的serverserver 192.168.1.1（时间服务器的ip）fudge 192.168.1.1 stratum 5 3.客户端和时间服务器同步 使用ntpdate更新时间 注意要停止ntp服务才能使用ntpdate更新时间sudo ntpdate 192.168.1.1sudo hwclock –systohc #将系统时间写入硬件时间sudo hwclock –hctosys #将硬件时间写入系统时间 使用ntpd更新时间sudo service ntp start #启动ntp进程，自动逐渐同步时间 4.查看时间状态timedatectl statussudo ntpq -p 5.更换时区sudo tzselect 常见错误解决方案 no server suitable for synchronization found参考链接：http://www.blogjava.net/spray/archive/2008/07/10/213964.html]]></content>
      <categories>
        <category>解决方案</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ntp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql命令]]></title>
    <url>%2F2017%2F04%2F24%2Fmysql%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1、mysql的安装linux下mysql安装-博客园 2、用户管理启动服务：net start mysqld链接数据库：mysql -uroot -p修改root用户密码：mysqladmin -u root password “new_password”; 2.1新建用户mysql -uroot -p //登录mysqlmysql&gt; insert into mysql.user(Host,User,Password) values(“localhost”,”test”,password(“1234”));//localhost表示只能在本机登录，改为”%”则可以远程登录 或者：mysql&gt; CREATE USER ‘username‘@’host’ IDENTIFIED BY ‘password’; 2.2用户授权grant 权限 on 数据库.* to ‘username‘@’host’ identified by ‘password’权限：select, update, all, delete, create, drop 2.3删除用户Delete FROM user Where User=’test’ and Host=’localhost’;flush privileges;drop database 用户数据库名;drop user 用户名@’%’drop user 用户名@‘localhost’ 2.4修改用户密码mysql&gt;update mysql.user set password=password(‘新密码’) where User=”test” and Host=”localhost”;mysql&gt;flush privileges; 在5.7版本的mysql中，没有“password”这个字段，因此需要使用“authentication_string”这个字段来替换“password”字段 或者采用以下命令：ALTER USER ‘root‘@’localhost’IDENTIFIED BY ‘**‘ 2.5撤销用户权限REVOKE 权限 ON databasename.tablename FROM ‘username‘@’host’; 2.6常用命令show databases;//列出所有数据库use ‘databasename’;//切换数据库show tables;//列出所有表describe tablename;//显示数据表结构drop database 数据库名;//删除数据库drop database 表名;//删除表 2.7重置root密码 修改安装目录下的my.ini文件，添加一行：skip-grant-tables 重启mysql服务：windows(管理员模式):net stop mysql; net start mysql; mysql -uroot -p(直接回车登录) update mysql.user set authentication_string=password(‘新密码’) where User=”root” 注释my.ini文件中skip-grant-tables这一行 重启mysql服务 3.常见问题 远程连接问题： 解决方案如下：1、授权mysql&gt;grant all privileges on . to ‘root‘@’%’ identified by ‘youpassword’ with grant option;mysql&gt;flush privileges;2、修改/etc/mysql/my.conf找到bind-address = 127.0.0.1这一行,注释即可 重启mysql服务 12[root@localhost /]# service mysqld start (5.0版本是mysqld)[root@szxdb etc]# service mysql start (5.5.7版本是mysql)]]></content>
      <categories>
        <category>笔记</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java核心技术（一）]]></title>
    <url>%2F2017%2F04%2F21%2Fjava%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[java基本程序设计结构1.java字符串 java编译器让不可变的字符串共享，所有的不可变字符串会存放在公共的存储池中，字符串变量指向存储池中的字符串的相应位置。类似于c++中的字符串指针，一旦字符串没人用，java自动回收机制会自动回收该字符串。 如何判断String字符串是否为空？ 123456789case 1: 判断java字符串是否为空======if(str.length()==0)或 if(str.equals(""))case 2: 判断是否为null======if(str == null)这两种方式不一样，null表示当前的String变量没有与对象关联。 常用String API trim() 去掉原始字符串头尾空格 lasetIndexOf(String str) 返回str匹配的第一个子串的开始位置 toLowerCase() toUpperCase() 2.java输入输出 读取文本输入 1234Scanner in = new Scanner(System.in);String name = in.nextLine();//输入如果有空格采用该种方法String sex = in.next();//输入空格隔开调用该方法int age = in.nextInt();//读取整数,nextDouble类似返回双精度浮点数 读取密码输入 123Console cons = System.console();//console对象每次只能读取一行输入String user = cons.readLine("User name: ");char[] passwd = cons.readPassword("Password: "); 大数值的计算java的基本数据类型： 类型 字节 int 4 short 2 logn 8 byte 1 float 4 double 8 NaN：当数据溢出时显示无穷大 java提供了BigInteger和BigDecimal两个类，可以处理包含任意长度数字序列的数值，分别实现了任意精度的整数运算和浮点数运算。 java数组for each循环: for(T element: collection){};匿名数组 new String[] {“ss”,”rr”};java中允许数组长度为0，但数组长度为0不等于nullnew elementType[0];// 不是null数组拷贝：Arrays.copyOf(T[] arrayVar, int lenth); java对象和类 java运行内存管理http://www.importnew.com/21463.htmlhttp://www.cnblogs.com/gw811/archive/2012/10/18/2730117.html堆和栈的区别 访问时间Date()类： 1234Date date = new Date();date.getTime();// = System.currentTimeMillis()//还可以使用 LocalDate()和Calendar()这两个类 java编译javac 类名.javajava有两种编译方式：显示编译和隐式编译。显示编译某个文件时，如果该文件调用了其他的类，则会对引用的类进行编译操作，如果被引用的类被修改了，则会重新编译新版本的.class文件 java封装java类的成员都应该设置为私有的，否则很危险。通常使用共有的方法来对私有成员进行读写。成员方法大部分设计为共有方法，一旦设计成公有的，不能随便删除，因为其他的代码可能依赖它。 静态导入包 12import static java.lang.System.*;out.println("hello world!");//静态导入包，不用加类名前缀就可以直接访问方法。]]></content>
      <categories>
        <category>笔记</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java设计模式（三）：行为型模式]]></title>
    <url>%2F2017%2F04%2F07%2Fjava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考链接：Java开发中的23种设计模式详解(转)Java经典设计模式之五大创建型模式（附实例和详解） 行为型模式细分为如下11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 行为型模式(Behavioral Pattern)是对在不同的对象之间划分责任和算法的抽象化。 行为型模式不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。 先来张图，看看这11中模式的关系： 第一类：通过父类与子类的关系进行实现。第二类：两个类之间。第三类：类的状态。第四类：通过中间类 1. 策略模式策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。需要设计一个接口，为一系列实现类提供统一的方法，多个实现类实现该接口，设计一个抽象类（可有可无，属于辅助类），提供辅助函数，关系图如下： 图中ICalculator提供统一的方法，AbstractCalculator是辅助类，提供辅助方法，接下来，依次实现下每个类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public interface ICalculator &#123; public int calculate(String exp); &#125;public abstract class AbstractCalculator &#123; public int[] split(String exp,String opt)&#123; String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; &#125; &#125; # 3个实现类## 加法public class Plus extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"\\+"); return arrayInt[0]+arrayInt[1]; &#125; &#125;## 减法public class Minus extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"-"); return arrayInt[0]-arrayInt[1]; &#125; &#125; ## 乘法public class Multiply extends AbstractCalculator implements ICalculator &#123; @Override public int calculate(String exp) &#123; int arrayInt[] = split(exp,"\\*"); return arrayInt[0]*arrayInt[1]; &#125; &#125; # 测试类public class StrategyTest &#123; public static void main(String[] args) &#123; String exp = "2+8"; ICalculator cal = new Plus(); int result = cal.calculate(exp); System.out.println(result); &#125; &#125; 策略模式的决定权在用户，系统本身提供不同算法的实现，新增或者删除算法，对各种算法做封装。因此，策略模式多用在算法决策系统中，外部用户只需要决定用哪个算法即可。 2. 模板方法模式一个抽象类中，有一个主方法，再定义1…n个方法，可以是抽象的，也可以是实际的方法，定义一个类，继承该抽象类，重写抽象方法，通过调用抽象类，实现对子类的调用，先看个关系图： 12345678910111213141516171819202122232425262728293031323334353637public abstract class AbstractCalculator &#123; /*主方法，实现对本类其它方法的调用*/ public final int calculate(String exp,String opt)&#123; int array[] = split(exp,opt); return calculate(array[0],array[1]); &#125; /*被子类重写的方法*/ abstract public int calculate(int num1,int num2); public int[] split(String exp,String opt)&#123; String array[] = exp.split(opt); int arrayInt[] = new int[2]; arrayInt[0] = Integer.parseInt(array[0]); arrayInt[1] = Integer.parseInt(array[1]); return arrayInt; &#125; &#125; public class Plus extends AbstractCalculator &#123; @Override public int calculate(int num1,int num2) &#123; return num1 + num2; &#125; &#125; public class StrategyTest &#123; public static void main(String[] args) &#123; String exp = "8+8"; AbstractCalculator cal = new Plus(); int result = cal.calculate(exp, "\\+"); System.out.println(result); &#125; &#125; 3. 观察者模式观察者模式很好理解，类似于邮件订阅和RSS订阅，当我们浏览一些博客或wiki时，经常会看到RSS图标，就这的意思是，当你订阅了该文章，如果后续有更新，会及时通知你。其实，简单来讲就一句话：当一个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是一种一对多的关系。先来看看关系图： MySubject类就是我们的主对象，Observer1和Observer2是依赖于MySubject的对象，当MySubject变化时，Observer1和Observer2必然变化。AbstractSubject类中定义着需要监控的对象列表，可以对其进行修改：增加或删除被监控对象，且当MySubject变化时，负责通知在列表内存在的对象。我们看实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public interface Observer &#123; public void update(); &#125; public class Observer1 implements Observer &#123; @Override public void update() &#123; System.out.println("observer1 has received!"); &#125; &#125; public class Observer2 implements Observer &#123; @Override public void update() &#123; System.out.println("observer2 has received!"); &#125; &#125; public interface Subject &#123; /*增加观察者*/ public void add(Observer observer); /*删除观察者*/ public void del(Observer observer); /*通知所有的观察者*/ public void notifyObservers(); /*自身的操作*/ public void operation(); &#125; public abstract class AbstractSubject implements Subject &#123; private Vector&lt;Observer&gt; vector = new Vector&lt;Observer&gt;(); @Override public void add(Observer observer) &#123; vector.add(observer); &#125; @Override public void del(Observer observer) &#123; vector.remove(observer); &#125; @Override public void notifyObservers() &#123; Enumeration&lt;Observer&gt; enumo = vector.elements(); while(enumo.hasMoreElements())&#123; enumo.nextElement().update(); &#125; &#125; &#125; public class MySubject extends AbstractSubject &#123; @Override public void operation() &#123; System.out.println("update self!"); notifyObservers(); &#125; &#125; # testpublic class ObserverTest &#123; public static void main(String[] args) &#123; Subject sub = new MySubject(); sub.add(new Observer1()); sub.add(new Observer2()); sub.operation(); &#125; &#125; 4. 迭代子模式顾名思义，迭代器模式就是顺序访问聚集中的对象，一般来说，集合中非常常见，如果对集合类比较熟悉的话，理解本模式会十分轻松。这句话包含两层意思：一是需要遍历的对象，即聚集对象，二是迭代器对象，用于对聚集对象进行遍历访问。我们看下关系图： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public interface Collection &#123; public Iterator iterator(); /*取得集合元素*/ public Object get(int i); /*取得集合大小*/ public int size(); &#125; public interface Iterator &#123; //前移 public Object previous(); //后移 public Object next(); public boolean hasNext(); //取得第一个元素 public Object first(); &#125; public class MyCollection implements Collection &#123; public String string[] = &#123;"A","B","C","D","E"&#125;; @Override public Iterator iterator() &#123; return new MyIterator(this); &#125; @Override public Object get(int i) &#123; return string[i]; &#125; @Override public int size() &#123; return string.length; &#125; &#125; public class MyIterator implements Iterator &#123; private Collection collection; private int pos = -1; public MyIterator(Collection collection)&#123; this.collection = collection; &#125; @Override public Object previous() &#123; if(pos &gt; 0)&#123; pos--; &#125; return collection.get(pos); &#125; @Override public Object next() &#123; if(pos&lt;collection.size()-1)&#123; pos++; &#125; return collection.get(pos); &#125; @Override public boolean hasNext() &#123; if(pos&lt;collection.size()-1)&#123; return true; &#125;else&#123; return false; &#125; &#125; @Override public Object first() &#123; pos = 0; return collection.get(pos); &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; Collection collection = new MyCollection(); Iterator it = collection.iterator(); while(it.hasNext())&#123; System.out.println(it.next()); &#125; &#125; &#125; 输出A B C D E 5. 责任链模式有多个对象，每个对象持有对下一个对象的引用，这样就会形成一条链，请求在这条链上传递，直到某一对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进行动态的调整。先看看关系图： Abstracthandler类提供了get和set方法，方便MyHandle类设置和修改引用对象，MyHandle类是核心，实例化后生成一系列相互持有的对象，构成一条链。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface Handler &#123; public void operator(); &#125; public abstract class AbstractHandler &#123; private Handler handler; public Handler getHandler() &#123; return handler; &#125; public void setHandler(Handler handler) &#123; this.handler = handler; &#125; &#125; public class MyHandler extends AbstractHandler implements Handler &#123; private String name; public MyHandler(String name) &#123; this.name = name; &#125; @Override public void operator() &#123; System.out.println(name+"deal!"); if(getHandler()!=null)&#123; getHandler().operator(); &#125; &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; MyHandler h1 = new MyHandler("h1"); MyHandler h2 = new MyHandler("h2"); MyHandler h3 = new MyHandler("h3"); h1.setHandler(h2); h2.setHandler(h3); h1.operator(); &#125; &#125; 输出： h1deal!h2deal!h3deal! 此处强调一点就是，链接上的请求可以是一条链，可以是一个树，还可以是一个环，模式本身不约束这个，需要我们自己去实现，同时，在一个时刻，命令只允许由一个对象传给另一个对象，而不允许传给多个对象。 6. 命令模式命令模式很好理解，举个例子，司令员下令让士兵去干件事情，从整个事情的角度来考虑，司令员的作用是，发出口令，口令经过传递，传到了士兵耳朵里，士兵去执行。这个过程好在，三者相互解耦，任何一方都不用去依赖其他人，只需要做好自己的事儿就行，司令员要的是结果，不会去关注到底士兵是怎么实现的。我们看看关系图： Invoker是调用者（司令员），Receiver是被调用者（士兵），MyCommand是命令，实现了Command接口，持有接收对象，看实现代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface Command &#123; public void exe(); &#125; public class MyCommand implements Command &#123; private Receiver receiver; public MyCommand(Receiver receiver) &#123; this.receiver = receiver; &#125; @Override public void exe() &#123; receiver.action(); &#125; &#125; public class Receiver &#123; public void action()&#123; System.out.println("command received!"); &#125; &#125; public class Invoker &#123; private Command command; public Invoker(Command command) &#123; this.command = command; &#125; public void action()&#123; command.exe(); &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; Receiver receiver = new Receiver(); Command cmd = new MyCommand(receiver); Invoker invoker = new Invoker(cmd); invoker.action(); &#125; &#125; 输出： command received! 这个很好理解，命令模式的目的就是达到命令的发出者和执行者之间解耦，实现请求和执行分开，熟悉Struts的同学应该知道，Struts其实就是一种将请求和呈现分离的技术，其中必然涉及命令模式的思想！* 7. 备忘录模式主要目的是保存一个对象的某个状态，以便在适当的时候恢复对象，个人觉得叫备份模式更形象些，通俗的讲下：假设有原始类A，A中有各种属性，A可以决定需要备份的属性，备忘录类B是用来存储A的一些内部状态，类C呢，就是一个用来存储备忘录的，且只能存储，不能修改等操作。做个图来分析一下： Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例，该模式很好理解。直接看源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Original &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public Original(String value) &#123; this.value = value; &#125; public Memento createMemento()&#123; return new Memento(value); &#125; public void restoreMemento(Memento memento)&#123; this.value = memento.getValue(); &#125; &#125; public class Memento &#123; private String value; public Memento(String value) &#123; this.value = value; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; &#125; public class Storage &#123; private Memento memento; public Storage(Memento memento) &#123; this.memento = memento; &#125; public Memento getMemento() &#123; return memento; &#125; public void setMemento(Memento memento) &#123; this.memento = memento; &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; // 创建原始类 Original origi = new Original("egg"); // 创建备忘录 Storage storage = new Storage(origi.createMemento()); // 修改原始类的状态 System.out.println("初始化状态为：" + origi.getValue()); origi.setValue("niu"); System.out.println("修改后的状态为：" + origi.getValue()); // 回复原始类的状态 origi.restoreMemento(storage.getMemento()); System.out.println("恢复后的状态为：" + origi.getValue()); &#125; &#125; 8. 状态模式核心思想就是：当对象的状态改变时，同时改变其行为，很好理解！就拿QQ来说，有几种状态，在线、隐身、忙碌等，每个状态对应不同的操作，而且你的好友也能看到你的状态，所以，状态模式就两点：1、可以通过改变状态来获得不同的行为。2、你的好友能同时看到你的变化。看图： State类是个状态类，Context类可以实现切换，我们来看看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class State &#123; private String value; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125; public void method1()&#123; System.out.println("execute the first opt!"); &#125; public void method2()&#123; System.out.println("execute the second opt!"); &#125; &#125; public class Context &#123; private State state; public Context(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125; public void setState(State state) &#123; this.state = state; &#125; public void method() &#123; if (state.getValue().equals("state1")) &#123; state.method1(); &#125; else if (state.getValue().equals("state2")) &#123; state.method2(); &#125; &#125; &#125; # testpublic class Test &#123; public static void main(String[] args) &#123; State state = new State(); Context context = new Context(state); //设置第一种状态 state.setValue("state1"); context.method(); //设置第二种状态 state.setValue("state2"); context.method(); &#125; &#125; 输出： execute the first opt!execute the second opt! 根据这个特性，状态模式在日常开发中用的挺多的，尤其是做网站的时候，我们有时希望根据对象的某一属性，区别开他们的一些功能，比如说简单的权限控制等。 9. 访问者模式访问者模式把数据结构和作用于结构上的操作解耦合，使得操作集合可相对自由地演化。访问者模式适用于数据结构相对稳定算法又易变化的系统。因为访问者模式使得算法操作增加变得容易。若系统数据结构对象易于变化，经常有新的数据对象增加进来，则不适合使用访问者模式。访问者模式的优点是增加操作很容易，因为增加操作意味着增加新的访问者。访问者模式将有关行为集中到一个访问者对象中，其改变不影响系统数据结构。其缺点就是增加新的数据结构很困难。—— From 百科 简单来说，访问者模式就是一种分离对象数据结构与行为的方法，通过这种分离，可达到为一个被访问者动态添加新的操作而无需做其它的修改的效果。简单关系图： 123456789101112131415161718192021222324252627282930313233343536373839public interface Visitor &#123; public void visit(Subject sub); &#125; public class MyVisitor implements Visitor &#123; @Override public void visit(Subject sub) &#123; System.out.println("visit the subject："+sub.getSubject()); &#125; &#125; public interface Subject &#123; public void accept(Visitor visitor); public String getSubject(); &#125; public class MySubject implements Subject &#123; @Override public void accept(Visitor visitor) &#123; visitor.visit(this); &#125; @Override public String getSubject() &#123; return "love"; &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; Visitor visitor = new MyVisitor(); Subject sub = new MySubject(); sub.accept(visitor); &#125; &#125; 输出：visit the subject：love 该模式适用场景：如果我们想为一个现有的类增加新功能，不得不考虑几个事情：1、新功能会不会与现有功能出现兼容性问题？2、以后会不会再需要添加？3、如果类不允许修改代码怎么办？ 面对这些问题，最好的解决方法就是使用访问者模式，访问者模式适用于数据结构相对稳定的系统，把数据结构和算法解耦 10. 中介者模式中介者模式也是用来降低类类之间的耦合的，因为如果类类之间有依赖关系的话，不利于功能的拓展和维护，因为只要修改一个对象，其它关联的对象都得进行修改。如果使用中介者模式，只需关心和Mediator类的关系，具体类类之间的关系及调度交给Mediator就行，这有点像spring容器的作用。先看看图： User类统一接口，User1和User2分别是不同的对象，二者之间有关联，如果不采用中介者模式，则需要二者相互持有引用，这样二者的耦合度很高，为了解耦，引入了Mediator类，提供统一接口，MyMediator为其实现类，里面持有User1和User2的实例，用来实现对User1和User2的控制。这样User1和User2两个对象相互独立，他们只需要保持好和Mediator之间的关系就行，剩下的全由MyMediator类来维护！基本实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public interface Mediator &#123; public void createMediator(); public void workAll(); &#125; public class MyMediator implements Mediator &#123; private User user1; private User user2; public User getUser1() &#123; return user1; &#125; public User getUser2() &#123; return user2; &#125; @Override public void createMediator() &#123; user1 = new User1(this); user2 = new User2(this); &#125; @Override public void workAll() &#123; user1.work(); user2.work(); &#125; &#125; public abstract class User &#123; private Mediator mediator; public Mediator getMediator()&#123; return mediator; &#125; public User(Mediator mediator) &#123; this.mediator = mediator; &#125; public abstract void work(); &#125; public class User1 extends User &#123; public User1(Mediator mediator)&#123; super(mediator); &#125; @Override public void work() &#123; System.out.println("user1 exe!"); &#125; &#125; public class User2 extends User &#123; public User2(Mediator mediator)&#123; super(mediator); &#125; @Override public void work() &#123; System.out.println("user2 exe!"); &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; Mediator mediator = new MyMediator(); mediator.createMediator(); mediator.workAll(); &#125; &#125; user1 exe!user2 exe! 11. 解释器模式一般主要应用在OOP开发中的编译器的开发中，所以适用面比较窄。 Context类是一个上下文环境类，Plus和Minus分别是用来计算的实现，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public interface Expression &#123; public int interpret(Context context); &#125; public class Plus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()+context.getNum2(); &#125; &#125; public class Minus implements Expression &#123; @Override public int interpret(Context context) &#123; return context.getNum1()-context.getNum2(); &#125; &#125; public class Context &#123; private int num1; private int num2; public Context(int num1, int num2) &#123; this.num1 = num1; this.num2 = num2; &#125; public int getNum1() &#123; return num1; &#125; public void setNum1(int num1) &#123; this.num1 = num1; &#125; public int getNum2() &#123; return num2; &#125; public void setNum2(int num2) &#123; this.num2 = num2; &#125; &#125; public class Test &#123; public static void main(String[] args) &#123; // 计算9+2-8的值 int result = new Minus().interpret((new Context(new Plus() .interpret(new Context(9, 2)), 8))); System.out.println(result); &#125; &#125; 最后输出正确的结果：3 基本就这样，解释器模式用来做各种各样的解释器，如正则表达式等的解释器等等！]]></content>
      <categories>
        <category>笔记</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java设计模式（二）：结构型模式]]></title>
    <url>%2F2017%2F04%2F07%2Fjava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考链接：Java开发中的23种设计模式详解(转)Java经典设计模式之五大创建型模式（附实例和详解） 一、结构型模式分类：一共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。其中适配器模式主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。其中的对象的适配器模式是各种结构型模式的起源。 二、适配器模式：适配器模式主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。 适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。有点抽象，我们来看看详细的内容。 应用场景： 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 三、装饰模式：装饰模式：在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能。它是通过创建一个包装对象，也就是装饰来包裹真实的对象。 关系图： 装饰模式的特点： （1） 装饰对象和真实对象有相同的接口。这样客户端对象就能以和真实对象相同的方式和装饰对象交互。（2） 装饰对象包含一个真实对象的引用（reference）（3） 装饰对象接受所有来自客户端的请求。它把这些请求转发给真实的对象。（4） 装饰对象可以在转发这些请求以前或以后增加一些附加功能。这样就确保了在运行时，不用修改给定对象的结构就可以在外部增加附加的功能。在面向对象的设计中，通常是通过继承来实现对给定类的功能扩展。继承不能做到这一点，继承的功能是静态的，不能动态增删。123456789101112131415161718192021222324252627282930313233343536373839404142# 1. sourceablepublic interface Sourceable &#123; public void method(); &#125;# 2. sourcepublic class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125; &#125;# 3. decoratorpublic class Decorator implements Sourceable &#123; private Sourceable source; public Decorator(Sourceable source)&#123; super(); this.source = source; &#125; @Override public void method() &#123; System.out.println("before decorator!"); source.method(); System.out.println("after decorator!"); &#125; &#125;# 4. testpublic class DecoratorTest &#123; public static void main(String[] args) &#123; Sourceable source = new Source(); Sourceable obj = new Decorator(source); obj.method(); &#125; &#125; 装饰器模式的应用场景： 1、需要扩展一个类的功能。 2、动态的为一个对象增加功能，而且还能动态撤销。（继承不能做到这一点，继承的功能是静态的，不能动态增删。） 缺点：产生过多相似的对象，不易排错！ 四、代理模式：代理模式就是多一个代理类出来，替原对象进行一些操作。代理类就像中介，它比我们掌握着更多的信息。 关系图： 12345678910111213141516171819202122232425262728293031323334# 3. proxypublic class Proxy implements Sourceable &#123; private Source source; public Proxy()&#123; super(); this.source = new Source(); &#125; @Override public void method() &#123; before(); source.method(); atfer(); &#125; private void after() &#123; System.out.println("after proxy!"); &#125; private void before() &#123; System.out.println("before proxy!"); &#125; &#125;# 4. testpublic class ProxyTest &#123; public static void main(String[] args) &#123; Sourceable source = new Proxy(); source.method(); &#125; &#125; 代理模式的应用场景： 如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法： 1、修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 2、就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 使用代理模式，可以将功能划分的更加清晰，有助于后期维护！ 五、外观模式：外观模式是为了解决类与类之间的依赖关系的，像spring一样，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口。 关系图： 六、桥接模式：在软件系统中，某些类型由于自身的逻辑，它具有两个或多个维度的变化，那么如何应对这种“多维度的变化”？如何利用面向对象的技术来使得该类型能够轻松的沿着多个方向进行变化，而又不引入额外的复杂度？这就要使用Bridge模式。 在提出桥梁模式的时候指出，桥梁模式的用意是将抽象化(Abstraction)与实现化(Implementation)脱耦，使得二者可以独立地变化。这句话有三个关键词，也就是抽象化、实现化和脱耦。 抽象化：存在于多个实体中的共同的概念性联系，就是抽象化。作为一个过程，抽象化就是忽略一些信息，从而把不同的实体当做同样的实体对待。 实现化：抽象化给出的具体实现，就是实现化。 脱耦：所谓耦合，就是两个实体的行为的某种强关联。而将它们的强关联去掉，就是耦合的解脱，或称脱耦。在这里，脱耦是指将抽象化和实现化之间的耦合解脱开，或者说是将它们之间的强关联改换成弱关联 关系图： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public interface Sourceable &#123; public void method(); &#125; public class SourceSub1 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the first sub!"); &#125; &#125; public class SourceSub2 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the second sub!"); &#125; &#125; public abstract class Bridge &#123; private Sourceable source; public void method()&#123; source.method(); &#125; public Sourceable getSource() &#123; return source; &#125; public void setSource(Sourceable source) &#123; this.source = source; &#125; &#125; public class MyBridge extends Bridge &#123; public void method()&#123; getSource().method(); &#125; &#125; public class BridgeTest &#123; public static void main(String[] args) &#123; Bridge bridge = new MyBridge(); /*调用第一个对象*/ Sourceable source1 = new SourceSub1(); bridge.setSource(source1); bridge.method(); /*调用第二个对象*/ Sourceable source2 = new SourceSub2(); bridge.setSource(source2); bridge.method(); &#125; &#125; 这样，就通过对Bridge类的调用，实现了对接口Sourceable的实现类SourceSub1和SourceSub2的调用。接下来我再画个图，大家就应该明白了，因为这个图是我们JDBC连接的原理，有数据库学习基础的，一结合就都懂了。 七、组合模式组合模式，将对象组合成树形结构以表示“部分-整体”的层次结构，组合模式使得用户对单个对象和组合对象的使用具有一致性。掌握组合模式的重点是要理解清楚 “部分/整体” 还有 ”单个对象“ 与 “组合对象” 的含义。 组合模式让你可以优化处理递归或分级数据结构。 《设计模式》：将对象组合成树形结构以表示“部分整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 涉及角色： Component：是组合中的对象声明接口，在适当的情况下，实现所有类共有接口的默认行为。声明一个接口用于访问和管理Component子部件。 Leaf：在组合中表示叶子结点对象，叶子结点没有子结点。 Composite：定义有枝节点行为，用来存储子部件，在Component接口中实现与子部件有关操作，如增加(add)和删除(remove)等。 比如现实中公司内各部门的层级关系，请看代码： Component：是组合中的对象声明接口，在适当的情况下，实现所有类共有接口的默认行为。声明一个接口用于访问和管理Component子部件。 关系图： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class TreeNode &#123; private String name; private TreeNode parent; private Vector&lt;TreeNode&gt; children = new Vector&lt;TreeNode&gt;(); public TreeNode(String name)&#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public TreeNode getParent() &#123; return parent; &#125; public void setParent(TreeNode parent) &#123; this.parent = parent; &#125; //添加孩子节点 public void add(TreeNode node)&#123; children.add(node); &#125; //删除孩子节点 public void remove(TreeNode node)&#123; children.remove(node); &#125; //取得孩子节点 public Enumeration&lt;TreeNode&gt; getChildren()&#123; return children.elements(); &#125; &#125; public class Tree &#123; TreeNode root = null; public Tree(String name) &#123; root = new TreeNode(name); &#125; public static void main(String[] args) &#123; Tree tree = new Tree("A"); TreeNode nodeB = new TreeNode("B"); TreeNode nodeC = new TreeNode("C"); nodeB.add(nodeC); tree.root.add(nodeB); System.out.println("build the tree finished!"); &#125; &#125; 应用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等。 八、享元模式享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。 一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 关系图： FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 举个例子，数据库连接池： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ConnectionPool &#123; private Vector&lt;Connection&gt; pool; /*公有属性*/ private String url = "jdbc:mysql://localhost:3306/test"; private String username = "root"; private String password = "root"; private String driverClassName = "com.mysql.jdbc.Driver"; private int poolSize = 100; private static ConnectionPool instance = null; Connection conn = null; /*构造方法，做一些初始化工作*/ private ConnectionPool() &#123; pool = new Vector&lt;Connection&gt;(poolSize); for (int i = 0; i &lt; poolSize; i++) &#123; try &#123; Class.forName(driverClassName); conn = DriverManager.getConnection(url, username, password); pool.add(conn); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /* 返回连接到连接池 */ public synchronized void release() &#123; pool.add(conn); &#125; /* 返回连接池中的一个数据库连接 */ public synchronized Connection getConnection() &#123; if (pool.size() &gt; 0) &#123; Connection conn = pool.get(0); pool.remove(conn); return conn; &#125; else &#123; return null; &#125; &#125; &#125;]]></content>
      <categories>
        <category>笔记</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java设计模式（一）：创建型模式]]></title>
    <url>%2F2017%2F04%2F07%2Fjava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[参考链接：Java开发中的23种设计模式详解(转)Java经典设计模式之五大创建型模式（附实例和详解） 一、设计模式分类总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 其实还有两类：并发型模式和线程池模式。用一个图片来整体描述一下： 二、设计模式的六大原则 开闭原则（Open Close Principle）开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 里氏代换原则（Liskov Substitution Principle）里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。 依赖倒转原则（Dependence Inversion Principle）这个是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 迪米特法则（最少知道原则）（Demeter Principle）一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）原则是尽量使用合成/聚合的方式，而不是使用继承。 三、工厂方法模式1、普通工厂模式建立一个工厂类，对实现了同一接口的类进行实例的创建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 创建类的共同接口======Active.java======public Interface Active&#123; public void eat(); public void spark();&#125;# 创建实现类======Cat.java======public class Cat implements Active&#123; @Override pubic void eat()&#123; System.out.println("I eat fish!"); &#125;&#125;======Dog.java======public class Dog implements Active&#123; @Override pubic void eat()&#123; System.out.println("I eat meat!"); &#125;&#125;# 创建工厂类======ActiveFactory.java======public class ActiveFactory&#123; public Active produce(String type)&#123; if(type.equals("cat"))&#123; return new Cat(); &#125;else if(type.equals("dog"))&#123; return new Dog(); &#125;else &#123; System.out.println("Error! please intput correct type!"); return null; &#125; &#125; # test public static void main(String[] args)&#123; ActiveFactory activeFactory = new ActiveFactory(); Active active = activeFactory.produce("cat"); active.eat(); //output ===&gt; "I eat fish!" &#125;&#125; 2.多个工厂方法模式在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象12345678910111213141516171819======ActiveFactory.java======public class ActiveFactory&#123; public Active produceCat()&#123; return new Cat(); &#125; public Active produceDog()&#123; return new Dog(); &#125; # test public static void main(String[] args)&#123; ActiveFactory activeFactory = new ActiveFactory(); Active active = activeFactory.produceCat("cat"); active.eat(); //output ===&gt; "I eat fish!" &#125;&#125; 3.静态工厂模式将多个工厂方法模式中的方法置为静态的，不需要创建实例，直接调用即可123456789101112131415161718======ActiveFactory.java======public class ActiveFactory&#123; public static Active produceCat()&#123; return new Cat(); &#125; public static Active produceDog()&#123; return new Dog(); &#125; # test public static void main(String[] args)&#123; Active active = ActiveFactory.produceCat("cat"); active.eat(); //output ===&gt; "I eat fish!" &#125;&#125; 四、抽象工厂模式在一般的工厂模式中，类的创建依赖工厂类，如果要扩展程序，必须对工厂类进行修改，违背了闭包原则，因此需要用抽象工厂模式，创建多个工厂类，一旦需要增加新的功能，直接增加新的工厂类就可以123456789101112131415161718192021222324======Provider.java======public interface Provider&#123; public Active produce();&#125;======ActiveCatFactory.java======public class ActiveCatFactory implements Provider&#123; public Active produce()&#123; return new Cat(); &#125;&#125;======ActiveDogFactory.java======public class ActiveDogFactory implements Provider&#123; public Active produce()&#123; return new Dog(); &#125;&#125; 五、单例模式在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在. 12345678910111213141516171819202122232425======Singleton.java======public class Singleton &#123; /* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */ private static Singleton instance = null; /* 私有构造方法，防止被实例化 */ private Singleton() &#123; &#125; /* 静态工程方法，创建实例 */ public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() &#123; return instance; &#125; &#125; 这个类可以满足基本要求，但是，像这样毫无线程安全保护的类，如果我们把它放入多线程的环境下，肯定就会出现问题了，如何解决？我们首先会想到对getInstance方法加synchronized关键字，如下： 123456public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; 但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个：12345678910public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (instance) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; 改程序在多线程的时候还是有可能发生错误，因此需要进一步改善123456private static class SingletonFactory&#123; private static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonFactory.instance; &#125; 参考链接 六、建造者模式工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来得到的。 123456789101112131415161718192021public class Builder &#123; private List&lt;Active&gt; list = new ArrayList&lt;Active&gt;(); public void produceCatActive(int count)&#123; for(int i=0; i&lt;count; i++)&#123; list.add(new Cat()); &#125; &#125; public void produceDogActive(int count)&#123; for(int i=0; i&lt;count; i++)&#123; list.add(new Dog()); &#125; &#125; public static void main(String[] args)&#123; Builder builder = new Builder(); builder.produceMailSender(10); &#125; &#125; 七、原型模式原型模式虽然是创建型的模式，但是与工厂模式没有关系，从名字即可看出，该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。本小结会通过对象的复制，进行讲解。在Java中，复制对象是通过clone()实现的，先创建一个原型类：1234567public class Prototype implements Cloneable &#123; public Object clone() throws CloneNotSupportedException &#123; Prototype proto = (Prototype) super.clone(); return proto; &#125; &#125; 深浅复制的例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Prototype implements Cloneable, Serializable &#123; private static final long serialVersionUID = 1L; private String string; private SerializableObject obj; /* 浅复制 */ public Object clone() throws CloneNotSupportedException &#123; Prototype proto = (Prototype) super.clone(); return proto; &#125; /* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException &#123; /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); &#125; public String getString() &#123; return string; &#125; public void setString(String string) &#123; this.string = string; &#125; public SerializableObject getObj() &#123; return obj; &#125; public void setObj(SerializableObject obj) &#123; this.obj = obj; &#125; &#125; class SerializableObject implements Serializable &#123; private static final long serialVersionUID = 1L; &#125;]]></content>
      <categories>
        <category>笔记</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[storm学习笔记-storm.yaml配置项]]></title>
    <url>%2F2017%2F03%2F18%2Fstorm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-storm-yaml%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[配置项 配置说明 storm.zookeeper.servers Zookeeper服务器列表 storm.zookeeper.port zookeeper 连接端口 storm.local.dir storm使用的本地文件系统目录（必须存在并且storm进程可读写） storm.cluster.mode Storm集群运行模式([distributedllocall) storm.local.mode.zmq Local模式下是否使用ZeroMQ作消息系统，如果设置为false则使用java消息系统默认为false storm.zookeeper.root ZooKeeper中Storm的根目录位置 storm.zookeeper.session.timeout 客户端连接ZooKeeper超时时间 storm.id 运行中拓扑的id,由stormname和一个唯随机数组成 nimbus.host nimbus服务器地址 nimbus.thrift.port nimbus的thrift监听端口 nimbus.childopts 通过storm-deploy项目部署时指定给nimbus进程的jvm选项 nimbus.task.timeout.secs 心跳超时时间，超时后nimbus会认为task死掉并重分配给另一个地址 nimbus.monitor. freq .secs nimbu归心跳和重分配任务的时间间隔注意如果是机器宫掉nimbus会立即接管并处理 nimbus.supervisor.timeout.secs supervisor的心跳超时时间，一旦超过nimbus会认为该supervisor已死并停止为它分发新任务 nimbus.task.launch.secs task启动时的一个特殊超时设置在启动后第一次心跳前会使用该值来临时 替代nimbus.task.timeout.secs. nimbus.reassign 当发现task失败是nimbus是否重新分配执行，默认为真 nimbus.file.copy.expiration.secs nimbus判断上传I下载链接的超时时间，当空闲时间超过该设定时nimbus会认为链接死掉并主动断开 ui.port Storm UI的服务端口 drpc.servers DRPC服务器列表，以便DRPCSpout知道和谁通讯 drpc.port Storm DRPC的服务端口 supervisor.slots.ports supervisor上能够运行workers的端口列表.每个worker占用一个端口,且每个端口只运行一个worker.通过这项配置可以调整每台机器上运行的worker数.(调整slot数/每机) supervisor.childopts 在storm-deploy项目中使用,用来配置supervisor守护进程的jvm选项 supervisor.worker.timeout.secs supervisor中的worker心跳超时时间,一旦超时supervisor会尝试重启worker进程. supervisor.worker.start.timeout.secs supervisor初始启动时，worker的心跳超时时间，当超过该时间supervisor会尝试重启worker。因为JVM初始启动和配置会带来的额外消耗，从而使得第一次心跳会超过supervisor.worker.timeout.secs的设定 supervisor.enable supervisor是否应当运行分配给他的workers.默认为true,该选项用来进行Storm的单元测试,一般不应修改. supervisor.heartbeat.frequency.secs supervisor心跳发送频率(多久发送一次) supervisor.monitor.frequency.secs supervisor 检查worker心跳的频率 worker.childopts supervisor启动worker时使用的jvm选项.所有的”%ID%”字串会被替换为对应worker的标识符 worker.heartbeat.frequency.secs worker的心跳发送时间间隔 task.heartbeat.frequency.secs task汇报状态心跳时间间隔 task.refresh.poll.secs task与其他tasks之间链接同步的频率.(如果task被重分配,其他tasks向它发送消息需要刷新连接).一般来讲，重分配发生时其他tasks会理解得到通知。该配置仅仅为了防止未通知的情况。 topology.debug 如果设置成true，Storm将记录发射的每条信息。 topology.optimize master是否在合适时机通过在单个线程内运行多个task以达到优化topologies的目的. topology.workers 执行该topology集群中应当启动的进程数量.每个进程内部将以线程方式执行一定数目的tasks.topology的组件结合该参数和并行度提示来优化性能 topology.ackers topology中启动的acker任务数.Acker保存由spout发送的tuples的记录，并探测tuple何时被完全处理.当Acker探测到tuple被处理完毕时会向spout发送确认信息.通常应当根据topology的吞吐量来确定acker的数目，但一般不需要太多.当设置为0时,相当于禁用了消息可靠性,storm会在spout发送tuples后立即进行确认. topology.message.timeout.secs topology中spout发送消息的最大处理超时时间.如果一条消息在该时间窗口内未被成功ack,Storm会告知spout这条消息失败。而部分spout实现了失败消息重播功能。 topology.kryo.register 注册到Kryo(Storm底层的序列化框架)的序列化方案列表.序列化方案可以是一个类名,或者是com.esotericsoftware.kryo.Serializer的实现. topology.skip.missing.kryo.registrations Storm是否应该跳过它不能识别的kryo序列化方案.如果设置为否task可能会装载失败或者在运行时抛出错误. topology.max.task.parallelism 在一个topology中能够允许的最大组件并行度.该项配置主要用在本地模式中测试线程数限制. topology.max.spout.pending 一个spout task中处于pending状态的最大的tuples数量.该配置应用于单个task,而不是整个spouts或topology. topology.state.synchronization.timeout.secs 组件同步状态源的最大超时时间(保留选项,暂未使用) topology.stats.sample.rate 用来产生task统计信息的tuples抽样百分比 topology.fall.back.on.java.serialization topology中是否使用java的序列化方案 zmq.threads 每个worker进程内zeromq通讯用到的线程数 zmq.linger.millis 当连接关闭时,链接尝试重新发送消息到目标主机的持续时长.这是一个不常用的高级选项,基本上可以忽略. java.library.path JVM启动(如Nimbus,Supervisor和workers)时的java.library.path设置.该选项告诉JVM在哪些路径下定位本地库.]]></content>
      <categories>
        <category>笔记</category>
        <category>storm</category>
      </categories>
      <tags>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下U盘分区]]></title>
    <url>%2F2017%2F03%2F18%2Flinux%E4%B8%8BU%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[转载自：https://www.zybuluo.com/fanisfun/note/677301]]></content>
      <categories>
        <category>解决方案</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>分区</tag>
        <tag>U盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux磁盘分区和挂载]]></title>
    <url>%2F2017%2F03%2F18%2Flinux%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E5%92%8C%E6%8C%82%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[磁盘分区显示磁盘和分区情况sudo fdisk -l 1234567891011121314151617181920Disk /dev/xvda: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylinders, total 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00054506 Device Boot Start End Blocks Id System/dev/xvda1 * 2048 75495423 37746688 83 Linux/dev/xvda2 75497470 83884031 4193281 5 Extended/dev/xvda5 75497472 83884031 4193280 82 Linux swap / SolarisDisk /dev/xvdb: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylinders, total 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/xvdb doesn\'t contain a valid partition table 对磁盘进行分区操作sudo fdisk /dev/xvdb 123456789101112131415161718Command (m for help): m ## 打印命令列表Command action a toggle a bootable flag # 将分区标记为可启动盘 b edit bsd disklabel c toggle the dos compatibility flag d delete a partition # 删除一个分区 l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition\'s system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) 输入n，增加硬盘一个新分区选择e，指定分区为扩展分区（extended）出现Partition number(1-4)时，输入１表示只分一个区输入p，打印分区表123456789Disk /dev/xvdb: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylinders, total 209715200 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0xf88fabb6 Device Boot Start End Blocks Id System/dev/xvdb1 2048 209715199 104856576 5 Extended 硬盘格式化操作sudo mkfs -t ext4 /dev/xvdb 1234567mkfs 命令的语法如下：mkfs [-V] [-t fstype] [fs-options] filesys说明：-V 显示简要的使用方法。-t 指定要建立何种文件系统，如：ext3, ext4。fs 指定建立文件系统时的参数。-v 显示版本信息与详细的使用方法。 挂载硬盘分区sudo mount -t ext4 /dev/xvdb /deb/sdb #指定硬盘分区文件系统为ext4，将/dev/xvdb 分区挂载到/dev/sdb sudo df -h #查看分区挂载情况123456789Filesystem Size Used Avail Use% Mounted on/dev/xvda1 36G 2.3G 32G 7% /none 4.0K 0 4.0K 0% /sys/fs/cgroupudev 476M 12K 476M 1% /devtmpfs 98M 392K 97M 1% /runnone 5.0M 4.0K 5.0M 1% /run/locknone 486M 0 486M 0% /run/shmnone 100M 0 100M 0% /run/user/dev/xvdb 99G 60M 94G 1% /dev/sdb 1234567891011121314# mount命令详解mount [-afFnrsvw] [-t vfstype] [-L label] [-o options] device dirmount [-lhv]说明：-a 加载文件/etc/fstab中设置的所有设备。-f 不实际加载设备。可与-v等参数同时使用以查看mount的执行过程。-F 需与-a参数同时使用。所有在/etc/fstab中设置的设备会被同时加载，可加快执行速度。-t vfstype 指定加载的文件系统类型，如：ext3, ext4。-L label 给挂载点指定一个标签名称。-l 显示分区的label。-h 显示帮助信息。-v 显示mount的版本信息。device 要挂载的分区或文件。如果device是一个文件，挂载时须加上 -o loop参数。dir 分区的挂载点。 设置开机自动挂载sudo vi /etc/fstab UUID=XXXXX /dev/sdb ext4 defaults 0 3 UUID获取命令： ls -l /dev/disk/by-uuid/ 或者 blkid /dev/xvdb fstab配置详解：/etc/fstab 中一共有６列： file system：指定要挂载的文件系统的设备名称（如：/dev/sdb）。也可以采用UUID，UUID可以通过使用blkid命令来查看（如：blkid /dev/sdb）指定设备的UUID号。 mount point：挂载点。就是自己手动创建一个目录，然后把分区挂载到这个目录下。 type：用来指定文件系统的类型。如：ext3, ext4, ntfs等。 option dump：0表示不备份；１表示要将整个中的内容备份。此处建议设置为0。 pass：用来指定fsck如何来检查硬盘。0表示不检查；挂载点为分区／（根分区）必须设置为1，其他的挂载点不能设置为1；如果有挂载ass设置成大于1的值，则在检查完根分区后，然后按pass的值从小到大依次检查，相同数值的同时检查。如：/home 和 /boot 的pass 设置成2，/devdata 的pass 设置成3，则系统在检查完根分区，接着同时检查/boot和/home，再检查/devdata。]]></content>
      <categories>
        <category>解决方案</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka操作命令]]></title>
    <url>%2F2017%2F03%2F16%2Fkafka%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[kafka常用操作命令123456789101112131415## 1 创建新的topickafka-topic --create --zookeeper zkhost:2181/kafka --replication-factor 1 --partitions 3 --topic topic-name## 2 查询所有的topickafka-topics --list --zookeeper zkhost:2181/kafka## 3 查看topic详细信息kafka-topics --describe --zookeeper zkhost:2181/kafka --topic topicname## 4 生产消息kafka-console-producer --broker-list kafkahost:9092 --topic topicname## 5 消费消息kafka-console-consumer --bootstrap-server kafkahost:9092 --topic topicname]]></content>
      <categories>
        <category>笔记</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hbase基本操作命令]]></title>
    <url>%2F2017%2F03%2F09%2FHbase%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一、基本命令： 建表：create ‘testtable’,’coulmn1’,’coulmn2’ 也可以建表时加coulmn的属性如： 1create 'testtable',&#123;NAME =&gt; 'coulmn1', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; '0', VERSIONS =&gt; '10', COMPRESSION =&gt; 'LZO', TTL =&gt; '30000', IN_MEMORY =&gt; 'false', BLOCKCACHE =&gt; 'false'&#125;, &#123;NAME =&gt; 'coulmn', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; '0', VERSIONS =&gt; '30', COMPRESSION =&gt; 'LZO', TTL =&gt; '30000', IN_MEMORY =&gt; 'true'&#125; (其中的属性有versions：设置历史版本数，TTL：过期时间，COMPRESSION：压缩方式，当配置lzo的情况) 删除表：drop ‘testtable’ （删除表之前先要禁用表，命令disable ‘testtable’） 启用和禁用表： enable ‘testtable’ 和disable ‘testtable’ 其它的基本命令：describe ‘testtable’（查看表结构），alert 修改表结构，list 列出所有表。 查询前10条数据: scan&apos;testtable&apos;,{COLUMNS=&gt;&apos;info&apos;,LIMIT=&gt;10,STARTROW=&gt;&apos;666632331200000020160305&apos;,STOPROW=&gt;&apos;666632331200000020160308&apos;} 分区合并合并两个预分区，合并预分区要提供该区encode值，该值在16010hbase管理web可查 merge_region &apos;region1的encode值&apos;,&apos;region2的encode值&apos; 手动触发major_compact动作cd /opt/hbase-1.2.1/bin./hbase shellmajor_compact ‘table’quit 手动触发flush动作cd /opt/hbase-1.2.1/bin./hbase shellflush ‘table1’flush ‘table2’quit 每次hbase启动，最好设置一下参数，让hbase区自动均衡cd /opt/hbase-1.2.1/bin./hbase shellbalance_switch true 二、日常维护的命令1，major_compact ‘testtable’，通常生产环境会关闭自动major_compact(配置文件中hbase.hregion.majorcompaction设为0)，选择一个晚上用户少的时间窗口手工major_compact，如果hbase更新不是太频繁，可以一个星期对所有表做一次major_compact，这个可以在做完一次major_compact后，观看所有的storefile数量，如果storefile数量增加到major_compact后的storefile的近二倍时，可以对所有表做一次major_compact，时间比较长，操作尽量避免高锋期。 2，flush ‘testtable’，将所有memstore刷新到hdfs，通常如果发现regionserver的内存使用过大，造成该机的regionserver很多线程block，可以执行一下flush操作，这个操作会造成hbase的storefile数量剧增，应尽量避免这个操作，还有一种情况，在hbase进行迁移的时候，如果选择拷贝文件方式，可以先停写入，然后flush所有表，拷贝文件。 3，balance_switch true或者balance_switch flase，配置master是否执行平衡各个regionserver的region数量，当我们需要维护或者重启一个regionserver时，会关闭balancer，这样就使得region在regionserver上的分布不均，这个时候需要手工的开启balance。 三、重启一个regionserverbin/graceful_stop.sh –restart –reload –debug nodename 这个操作是平滑的重启regionserver进程，对服务不会有影响，他会先将需要重启的regionserver上面的所有region迁移到其它的服务器，然后重启，最后又会将之前的region迁移回来，但我们修改一个配置时，可以用这种方式重启每一台机子，这个命令会关闭balancer，所以最后我们要在hbase shell里面执行一下balance_switch true，对于hbase regionserver重启，不要直接kill进程，这样会造成在zookeeper.session.timeout这个时间长的中断，也不要通过bin/hbase-daemon.sh stop regionserver去重启，如果运气不太好，-ROOT-或者.META.表在上面的话，所有的请求会全部失败。 四、关闭下线一台regionserverbin/graceful_stop.sh –stop nodename 和上面一样，系统会在关闭之前迁移所有region，然后stop进程，同样最后我们要手工balance_switch true，开启master的region均衡。 五、检查region是否正常以及修复bin/hbase hbck (检查) bin/hbase hbck -fix （修复） 会返回所有的region是否正常挂载，如没有正常挂载可以使用下一条命令修复，如果还是不能修复，那需要看日志为什么失败，手工处理。 六、hbase的迁移1，copytable方式 bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable –peer.adr=zookeeper1,zookeeper2,zookeeper3:/hbase ‘testtable’ 目前0.92之前的版本的不支持多版本的复制，0.94已经支持多个版本的复制。当然这个操作需要添加hbase目录里的conf/mapred-site.xml，可以复制hadoop的过来。 2，Export/Import bin/hbase org.apache.hadoop.hbase.mapreduce.Export testtable /user/testtable [versions] [starttime] [stoptime] bin/hbase org.apache.hadoop.hbase.mapreduce.Import testtable /user/testtable 跨版本的迁移，我觉得是一个不错的选择，而且copytable不支持多版本，而export支持多版本，比copytable更实用一些。 3，直接拷贝hdfs对应的文件 首先拷贝hdfs文件，如bin/hadoop distcp hdfs://srcnamenode:9000/hbase/testtable/ hdfs://distnamenode:9000/hbase/testtable/ 然后在目的hbase上执行bin/hbase org.jruby.Main bin/add_table.rb /hbase/testtable 生成meta信息后，重启hbase 这个操作是简单的方式，操作之前可以关闭hbase的写入，执行flush所有表（上面有介绍）,再distcp拷贝，如果hadoop版本不一致，可以用hftp接口的方式，我推荐使用这种方式，成本低。]]></content>
      <categories>
        <category>笔记</category>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>hbase</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式大数据分析平台环境搭建]]></title>
    <url>%2F2017%2F03%2F07%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[安装ubuntu在windows上使用ultraISO软件来刻录Ubuntu系统安装盘，设置U盘启动，安装系统参考链接：Ubuntu 14.04 64位系统安装cuda8.0+cudnn7.5+opencv+caffe 血泪教程 安装NVIDIA驱动http://www.nvidia.cn/Download/index.aspx?lang=cn选择合适型号，下载驱动包 首先按Ctrl+Alt+F1，进入text mode，关闭显示驱动 sudo service lightdm stop 增加执行权限 12sudo chmod +x NVIDIA-Linux-x86_64-375.39.runsudo ./NVIDIA-Linux-x86_64-375.39.run 安装成功后，重启图像界面服务 sudo service lightdm start 安装cuda+cudnn+opencv+caffe参考这个链接：原-Ubuntu-14-04-64位系统安装cuda8-0-cudnn7-5-opencv-caffe-血泪教程 caffe_github_link:https://github.com/BVLC/caffe.gitopencv_github_link:https://github.com/opencv/opencv 配置静态ip + 安装ssh-server静态ipubuntu14.04设置静态ip 找到文件并作如下修改： sudo vim /etc/network/interfaces 修改如下部分： auto eth0iface eth0 inet staticaddress 192.168.1.4gateway 192.168.1.1 #这个地址你要确认下 网关是不是这个地址netmask 255.255.255.0 #network 192.168.0.0 #broadcast 192.168.0.255 修改dns解析 因为以前是dhcp解析，所以会自动分配dns服务器地址 而一旦设置为静态ip后就没有自动获取到的dns服务器了 要自己设置一个 sudo vim /etc/resolv.conf 写上一个公网的DNS nameserver 202.114.0.131(公网dns服务器)nameserver 202.114.0.242（公网dns服务器）nameserver 192.168.1.1（局域网内可以访问外网的机器，非网关服务器放在前面） sudo vim /etc/resolvconf/resolv.d/base nameserver 202.114.0.131(公网dns服务器)nameserver 202.114.0.242（公网dns服务器）nameserver 192.168.1.1（局域网内可以访问外网的机器，非网关服务器放在前面） 重启网卡： sudo /etc/init.d/network restart 安装ssh-server 判断是否安装ssh服务Ubuntu系统默认安装ssh-client，如果想远程登录主机，就需要安装ssh-server，如下命令： 1ps -e|grep sshps -e|grep ssh ssh-agent表示ssh-client启动，sshd表示ssh-server启动了 如果缺少sshd，说明ssh服务没有启动或者没有安装。1234sudo apt-get install openssh-client #安装ssh-client命令sudo apt-get install openssh-server #安装ssh-server命令sudo /etc/init.d/ssh start #启动服务ps -e|grep sshps -e|grep ssh #查看是否正确启动。 配置ssh服务端口默认端口是 22sudo gedit /etc/ssh/sshd_configsudo /etc/init.d/ssh restart #重启ssh服务生效 设置开机自动启动 安装storm+kafka+zookeeper+hdfs+hbase+jdk前期准备工作 首先下载好这几个文件，这里用的版本分别是： storm 0.9.6 zookeeper 3.4.0 jdk 1.8.0.92 kafka 2.11.0.10.0.0 hadoop 2.6.4 hbase 1.2.4 设置ip地址映射sudo vi /etc/hosts 12345678910111213141516171819202122232425262728293031323334# test192.168.0.136 pc1080192.168.0.116 pcwrp192.168.0.117 pcxrr192.168.0.136 cloud01192.168.0.116 cloud02192.168.0.117 cloud03192.168.0.136 hadoop01192.168.0.116 hadoop02192.168.0.117 hadoop03192.168.0.136 zk01192.168.0.116 zk02192.168.0.117 zk03192.168.0.136 kafka01192.168.0.116 kafka02192.168.0.117 kafka03192.168.0.136 kafka01192.168.0.116 kafka02192.168.0.117 kafka03192.168.0.136 storm01192.168.0.116 storm02192.168.0.117 storm03192.168.0.136 hbase01192.168.0.116 hbase02192.168.0.117 hbase03# end test 这里面需要注意一下，之所以需要配置多组ip映射，是因为在相应的软件中很多默认参数需要用到这些映射 三台机机器实现互相ssh免密码登录，并且实现自身环回登录参考链接：ssh免密码登录 设置环境变量vi ~/.bashrc 123456789101112131415161718192021222324252627282930313233343536# javaexport JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin# hadoopexport MAVEN_HOME=/home/hadoop/cloud/apache-maven-3.3.9/export ZOOKEEPER_HOME=/home/hadoop/cloud/zookeeper-3.4.9/export HADOOP_HOME=/home/hadoop/cloud/hadoop-2.6.4/export HBASE_HOME=/home/hadoop/cloud/hbase-1.2.4/export FLUME_HOME=/home/hadoop/cloud/apache-flume-1.6.0/export KAFKA_HOME=/home/hadoop/cloud/kafka_2.11-0.10.0.0/export STORM_HOME=/home/hadoop/cloud/apache-storm-0.9.6/export HIVE_HOME=/home/hadoop/cloud/apache-hive-1.2.1/export HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_PREFIX=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_OPTS="-Djava.library.path=$HADOOP_PREFIX/lib/native"#export CHUKWA_HOME=/home/hadoop/cloud/chukwa-0.8.0/#export CHUKWA_CONF_DIR=$CHUKWA_HOME/etc/chukwaPATH=$PATH:$HOME/binPATH=$JAVA_HOME/bin/:$PATHPATH=$MAVEN_HOME/bin/:$PATHPATH=$ZOOKEEPER_HOME/bin/:$PATHPATH=$HBASE_HOME/bin/:$PATHPATH=$FLUME_HOME/bin/:$PATHPATH=$KAFKA_HOME/bin/:$PATHPATH=$STORM_HOME/bin/:$PATHPATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/binPATH=$HIVE_HOME/bin/:$PATHPATH=$PATH:$CHUKWA_HOME/bin:$CHUKWA_HOME/sbinexport PATH 安装zookeeper 下载安装包，解压到 /home/hadoop/cloud 目录下 添加环境变量 配置/etc/hosts 文件，做好ip地址映射 cat zoo_sample.cfg &gt;&gt; zoo.cfg 编辑 zoo.cfg文件 12345678910111213tickTime=2000initLimit=10syncLimit=5# zookeeper数据保存路径dataDir=/home/hadoop/cloud/zookeeper-3.4.9/data/clientPort=2181maxClientCnxns=150maxSessionTimeout=100000autopurge.snapRetainCount=6autopurge.purgeInterval=48server.1=zk01:2888:3888server.2=zk02:2888:3888server.3=zk03:2888:3888 在节点配置的dataDir目录中创建一个myid文件，里面内容为一个数字，用来标识当前主机，$ZOOKEEPER_HOME/conf/zoo.cfg文件中配置的server.X，则myid文件中就输入这个数字X。（即在每个节点上新建并设置文件myid，其内容与zoo.cfg中的id相对应） 123cd /home/hadoop/cloud/zookeeper-3.4.9/data/mkdir myidvi myid 启动zookeeper 1$ZOOKEEPER_HOME/bin/zkServer.sh start 安装storm 下载安装包，解压到 /home/hadoop/cloud 目录下 设置环境变量 修改 storm 主目录下conf/storm.yaml文件 12345678910111213141516171819202122232425262728293031323334353637383940414243storm.zookeeper.servers: - "zk01" - "zk02" - "zk03"storm.zookeeper.port: 2181storm.zookeeper.root: "/storm"nimbus.host: "storm01"supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 - 6704 - 6705 - 6706 - 6707 - 6708storm.local.dir: "/home/hadoop/cloud/apache-storm-0.9.6/local"drpc.servers: - "storm01"drpc.port: 3772drpc.worker.threads: 100drpc.queue.size: 1024drpc.invocations.port: 3773drpc.request.timeout.secs: 800drpc.childopts: "-Xmx2048m"drpc.port: 3772drpc.worker.threads: 100drpc.queue.size: 1024drpc.invocations.port: 3773drpc.request.timeout.secs: 800drpc.childopts: "-Xmx2048m"#JVM options of worker#edited by persistsuperivisor.childopts: "-Xmx2048m"worker.childopts: "-Xmx2048m"#JVM options of worker#edited by persistsuperivisor.childopts: "-Xmx2048m"worker.childopts: "-Xmx2048m" 启动storm命令（启动storm之前需要启动zookeeper） 123nimubs-host: nohup bin/storm nimbus&amp;nimubs-host: nohup bin/storm ui&amp;superivisor-hosts: nohup bin/storm superivisor&amp; 浏览器输入：http://pc1080:8080 查看storm UI界面 安装hadoop 下载安装包，解压到 /home/hadoop/cloud 目录下 设置环境变量 修改主目录下 etc/hadoop-env.sh 1export JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/ 修改主目录下 etc/yarn-env.sh 1export JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/ 修改 etc/hadoop/mapred-env.sh 1export JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/ 修改主目录下 etc/core-site.xml 123456789101112131415161718192021222324252627&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/home/hadoop/cloud/hadoop-2.6.4/data/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;zk01:2181,zk02:2181,zk03:2181&lt;/value&gt; &lt;description&gt;这里是ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点&lt;/description&gt; &lt;/property&gt; # add ours here &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;description&gt;允许所有用户组用户代理&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt; &lt;value&gt;hadoop01&lt;/value&gt; &lt;description&gt;允许挂载的主机域名&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 修改主目录下 etc/hdfs-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nfs.exports.allowed.hosts&lt;/name&gt; &lt;value&gt;hadoop01 rw;hadoop02 rw;hadoop03 rw;&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop01:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/hadoop/cloud/hadoop-2.6.4/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/hadoop/cloud/hadoop-2.6.4/tmp/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; ## add options here &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;/name&gt; &lt;value&gt;NEVER&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.max-component-length&lt;/name&gt; &lt;value&gt;255&lt;/value&gt; &lt;description&gt;Defines the maximum number of bytes in UTF-8 encoding in each component of a path. A value of 0 will disable the check.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.max-directory-items&lt;/name&gt; &lt;value&gt;6000000&lt;/value&gt; &lt;description&gt;Defines the maximum number of items that a directory may contain. Cannot set the property to a value less than 1 or more than 6400000.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.min-block-size&lt;/name&gt; &lt;value&gt;1048576&lt;/value&gt; &lt;description&gt;Minimum block size in bytes, enforced by the Namenode at create time. This prevents the accidental creation of files with tiny block sizes (and thus many blocks), which can degrade performance.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.max-blocks-per-file&lt;/name&gt; &lt;value&gt;1048576&lt;/value&gt; &lt;description&gt;Maximum number of blocks per file, enforced by the Namenode on write. This prevents the creation of extremely large files which can degrade performance.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.max-xattrs-per-inode&lt;/name&gt; &lt;value&gt;32&lt;/value&gt; &lt;description&gt; Maximum number of extended attributes per inode. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.fs-limits.max-xattr-size&lt;/name&gt; &lt;value&gt;16384&lt;/value&gt; &lt;description&gt; The maximum combined size of the name and value of an extended attribute in bytes. It should be larger than 0, and less than or equal to maximum size hard limit which is 32768. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt; &lt;value&gt;8192&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改主目录下 etc/httpfs-env.sh 123456789101112131415161718export JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/export HTTPFS_HOME=/home/hadoop/cloud/hadoop-2.6.4/export HTTPFS_CONFIG=/home/hadoop/cloud/hadoop-2.6.4/etc/hadoopexport CATALINA_BASE=/home/hadoop/cloud/hadoop-2.6.4/share/hadoop/httpfs/tomcatexport HTTPFS_LOG=$&#123;HTTPFS_HOME&#125;/httpfs/logsexport HTTPFS_TEMP=$&#123;HTTPFS_HOME&#125;/httpfs/tempexport HTTPFS_HTTP_PORT=14000export HTTPFS_ADMIN_PORT=`expr $&#123;HTTPFS_HTTP_PORT&#125; + 1` 修改 etc/hadoop/slavers 123hadoop01hadoop02hadoop03 以上只是部分配置，其中hadoop01是默认的主节点，默认配置的主机 启动hadoop 首先需要启动zookeeper 格式化hdfs： bin/hdfs namenode -format 启动hdfs和yarn： sbin/start-all.sh,启动成功master出现NameNode，SecondaryNameNode，ResourceManger进程，slave节点出现DataNode和NodeManager注意事项：如果增加了多个ip映射，那么有可能提醒是否需要添加host到ssh表，这种情况框需要重新设置ssh互通 web查看hdfs: https://hadoop01:50070/yarn: https://hadoop01:8088/ 遇到的问题：主节点上启动start-all.sh, 只有主节点的NameNode和SecondaryNameNode和DataNode启动，从节点的DataNode没有启动 重启部分坏死节点：bin/Hadoop-daemon.sh start DataNodebin/Hadoop-daemon.sh start jobtracker 动态加入新节点：bin/Hadoop-daemon.sh –config ./conf start DataNodebin/Hadoop-daemon.sh –config ./conf start tasktracker 更新配置文件命令：1for ip in `seq 2 3`; do scp /home/hadoop/cloud/hadoop-2.6.4/etc/hadoop/* hadoop@hadoop0$ip:/home/hadoop/cloud/hadoop-2.6.4/etc/hadoop/; done 更新环境变量：1for ip in `seq 2 3`; do scp /home/hadoop/.bashrc hadoop@hadoop0$ip:/home/hadoop/; done 安装HBase 下载安装包，解压到 /home/hadoop/cloud 目录下 修改～/.bashrc文件，添加HBASE_HOME环境变量； 修改 conf/hbase-env.sh 1234567export JAVA_HOME=/home/hadoop/cloud/jdk1.8.0_92/export HBASE_CLASSPATH=/opt/hbase/conf (extral classpath like java, Optional)# 此配置信息，设置由zk集群管理，故为false export HBASE_MANAGES_ZK=false export HBASE_HOME=/opt/hbase (Optional)#Hbase日志目录 export HBASE_LOG_DIR=$HBASE_HOME/logs(Optional) 修改 conf/hbase-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hbase01:9000/hbase&lt;/value&gt; &lt;description&gt;The directory shared by region servers.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;description&gt;Property from ZooKeeper config zoo.cfg. The port at which the clients will connect. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.bindAddress&lt;/name&gt; &lt;value&gt;192.168.100.101&lt;/value&gt; &lt;description&gt;HBase Master web ui bind address&lt;/description&gt; **必须填写master节点地址** &lt;/property&gt; &lt;property&gt; &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; &lt;value&gt;60000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hbase01,hbase02,hbase03&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/cloud/hbase-1.2.4/data/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/hadoop/cloud/hbase-1.2.4/zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.maxClientCnxns&lt;/name&gt; &lt;value&gt;300&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;/name&gt; &lt;value&gt;NEVER&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 regionservers 123hbase01hbase02 #设置regionserver的节点hbase03 同步配置 1for ip in `seq 2 3`; do scp /home/hadoop/cloud/hbase-1.2.4/conf/* hadoop@hadoop0$ip:/home/hadoop/cloud/hbase-1.2.4/conf/; done 启动hbase 1234bin/start-hbase.sh启动后，jps可以看到有这两个进程HRegionServerHMaster 启动Hbase Shell 1bin/hbase shell 访问HBase UI查看hbase管理界面http://192.168.181.66:16010 hbase日常维护参考链接：Hbase基本操作命令 注意hbase集群安装的大坑 hbase-site.xml必须添加hbase.master.info.bindAddress配置项，设置为master节点的ip地址 设置/etc/hosts文件，注释掉 127.0.1.1 hostname这一行，替换成局域网ip hostname，否则HRegionServer 无法链接Master节点 错误参考链接：http://www.cnblogs.com/colorfulkoala/archive/2012/07/09/2583841.html 安装kafka参考链接：kafka]]></content>
      <categories>
        <category>解决方案</category>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>深度学习</tag>
        <tag>大数据</tag>
        <tag>cuda</tag>
        <tag>opencv</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu制作UbuntuLiveCD+备份系统镜像教程]]></title>
    <url>%2F2017%2F03%2F03%2FUbuntu%E5%88%B6%E4%BD%9CUbuntuLiveCD-%E5%A4%87%E4%BB%BD%E7%B3%BB%E7%BB%9F%E9%95%9C%E5%83%8F%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装UbuntuLiveCD 准备：U盘，ubuntu官方镜像文件 windows解决方案 安装UltralSO，打开ubuntu镜像文件，写入U盘 安装UNetBootin，打开Ubuntu镜像文件，写入U盘 linux解决方案 插入U盘 sudo fdisk -l cd ubuntu-iso的目录 sudo dd if=ubuntu-14.04.5-desktop-amd64.iso of=/dev/sdX(sdX表示插入的U盘) 备份系统镜像linux提供的dd命令可以直接复制磁盘的数据 使用U盘启动UbuntuLiveCD，类似WinPE系统 sudo fdisk -l /dev/sdX(sdX代表你要克隆的磁盘)如图所示，linux系统有三个分区分别是sda8 sda9 sda10,其中sda8 是交换分区，不用备份，只需要备份sda9和sda10空间 1sudo dd bs=512 count=1953523712 skip=1646948352 if=/dev/sda of=savedPath/ghost.img 将ghost.img恢复到新硬盘 1dd if=savedPath/ghost.img of=/dev/sda 不要直接在计算机上用本地磁盘启动系统后执行dd命令生成本地磁盘的镜像。而应该用livecd启动计算机。因此计算机运行时会对系统盘产生大量写操作。 直接对运行中的系统盘生成的镜像，在恢复到其他硬盘上时，很可能会无法启动！ 使用gzip进行压缩和解压缩gzip参数：-c 表示输出到stdout-d 表示解压缩-1 表示最快压缩-9 表示最好压缩默认使用的是-6压缩级别 dd备份命令：1sudo dd bs=512 count=1953523712 skip=1646948352 if=/dev/sda | gzip -6 &gt; /ghost.img.gz dd还原命令：1gzip -dc /ghost.img.gz.gz | dd of=/dev/sda]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe学习笔记-生成deploy.prototxt文件]]></title>
    <url>%2F2017%2F02%2F28%2Fcaffe%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%94%9F%E6%88%90deploy-prototxt%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[deploy.prototxt文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137name: "LeNet"/*原来训练与测试两层数据层*//*layer &#123; name: "mnist" type: "Data" top: "data" top: "label" include &#123; phase: TRAIN &#125; transform_param &#123; scale: 0.00390625 &#125; data_param &#123; source: "examples/mnist/mnist_train_lmdb" batch_size: 64 backend: LMDB &#125;&#125;layer &#123; name: "mnist" type: "Data" top: "data" top: "label" include &#123; phase: TEST &#125; transform_param &#123; scale: 0.00390625 &#125; data_param &#123; source: "examples/mnist/mnist_test_lmdb" batch_size: 100 backend: LMDB &#125;&#125;*//*被替换成如下*/layer &#123; name: "data" type: "Input" top: "data" input_param &#123; shape: &#123; dim: 1 dim: 1 dim: 28 dim: 28 &#125; &#125;&#125;/*卷积层与全连接层中的权值学习率，偏移值学习率，偏移值初始化方式,因为这些值在caffemodel文件中已经提供*/layer &#123; name: "conv1" type: "Convolution" bottom: "data" top: "conv1" convolution_param &#123; num_output: 20 kernel_size: 5 stride: 1 weight_filler &#123; type: "xavier" &#125; &#125;&#125;layer &#123; name: "pool1" type: "Pooling" bottom: "conv1" top: "pool1" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: "conv2" type: "Convolution" bottom: "pool1" top: "conv2" convolution_param &#123; num_output: 50 kernel_size: 5 stride: 1 weight_filler &#123; type: "xavier" &#125; &#125;&#125;layer &#123; name: "pool2" type: "Pooling" bottom: "conv2" top: "pool2" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: "ip1" type: "InnerProduct" bottom: "pool2" top: "ip1" inner_product_param &#123; num_output: 500 weight_filler &#123; type: "xavier" &#125; &#125;&#125;layer &#123; name: "relu1" type: "ReLU" bottom: "ip1" top: "ip1"&#125;layer &#123; name: "ip2" type: "InnerProduct" bottom: "ip1" top: "ip2" inner_product_param &#123; num_output: 10 weight_filler &#123; type: "xavier" &#125; &#125;&#125;/*删除了原有的测试模块的测试精度层*//*输出层的类型由SoftmaxWithLoss变成Softmax，训练是输出时是loss，应用时是prob*/layer &#123; name: "prob" type: "Softmax" bottom: "ip2" top: "prob"&#125; 总结 去掉前面的训练数据和验证数据层，换成Input类型的层，其中input参数意思如下： 第一个：对待识别样本图片进行数据增广的数量，一个图片会变成10个，之后输入到网络进行识别。如果不进行数据增广，可以设置成1。第二个：图片的通道数，一般灰度图片为单通道，则值为1，如果为非灰度图3通道图片则为3。第三个：图片的高度，单位像素。第四个：图片的宽度，单位像素。 卷积层与全连接层中的权值学习率，偏移值学习率，偏移值初始化方式,因为这些值在caffemodel文件中已经提供 删除了原有的测试模块的测试精度层 输出层的类型由SoftmaxWithLoss变成Softmax，训练是输出时是loss，应用时是prob]]></content>
      <categories>
        <category>笔记</category>
        <category>caffe</category>
      </categories>
      <tags>
        <tag>caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[storm学习笔记--流分组]]></title>
    <url>%2F2017%2F02%2F28%2Fstorm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%B5%81%E5%88%86%E7%BB%84%2F</url>
    <content type="text"><![CDATA[storm 数据流分组 Shuffle grouping:随机分组，保证每个bolts得到相同数量的tuple Fields grouping：根据上一个bolts发出的tuple的字段来分组，同一字段的tuple被分到同一个Task里面 Partical Key grouping： 同Fields grouping,增加负载均衡策略 All grouping: 每个bolt的task都执行一遍上一级的bolt发射的tuples，慎重选择 Global grouping：全局分组，tuple被分配到bolt中的一个task，实现事务性的topology，一般来讲所有的tuple都被分配到拥有最小task_id的bolt任务处理 None grouping：不分组，不关注并行处理、负载均衡策略时采用该方式分组，目前等同于shuffle grouping，另外storm会把bolt任务和他的上游提供数据的任务安排在同一个线程下 Direct grouping：指定分組，只有被声明为DirectStream的消息流才能用这种分组方法，而且这种消息tuple必须使用emitDirect方法来发射tuple Local or shuffle grouping：如果目标bolt在一个work进程中一个或者多个task，那么tuples将会被随机分派到这个进程中的tasks，否则，如同shuffle grouping storm 分组策略及代码实现参考链接]]></content>
      <categories>
        <category>笔记</category>
        <category>storm</category>
      </categories>
      <tags>
        <tag>storm</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe学习笔记--solver.prototxt配置文件]]></title>
    <url>%2F2017%2F02%2F28%2Fcaffe%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-solver-prototxt%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[solver配置选项在Deep Learning中，往往loss function是非凸的，没有解析解，我们需要通过优化方法来求解。solver的主要作用就是交替调用前向（forward)算法和后向（backward)算法来更新参数，从而最小化loss，实际上就是一种迭代的优化算法。 到目前的版本，caffe提供了六种优化算法来求解最优参数，在solver配置文件中，通过设置type类型来选择。 Stochastic Gradient Descent (type: “SGD”), AdaDelta (type: “AdaDelta”), Adaptive Gradient (type: “AdaGrad”), Adam (type: “Adam”), Nesterov’s Accelerated Gradient (type: “Nesterov”) and RMSprop (type: “RMSProp”) 参数含义net: “examples/AAA/train_val.prototxt” #训练或者测试配置文件test_iter: 40 #完成一次测试需要的迭代次数test_interval: 475 #测试间隔base_lr: 0.01 #基础学习率lr_policy: “step” #学习率变化规律gamma: 0.1 #学习率变化指数stepsize: 9500 #学习率变化频率display: 20 #屏幕显示间隔max_iter: 47500 #最大迭代次数momentum: 0.9 #动量weight_decay: 0.0005 #权重衰减snapshot: 5000 #保存模型间隔snapshot_prefix: “models/A1/caffenet_train” #保存模型的前缀solver_mode: GPU #是否使用GPU 训练样本总共:121368个batch_szie:256将所有样本处理完一次（称为一代，即epoch)需要：121368/256=475 次迭代才能完成所以这里将test_interval设置为475，即处理完一次所有的训练数据后，才去进行测试。所以这个数要大于等于475.如果想训练100代，则最大迭代次数为47500； 测试样本同理，如果有1000个测试样本，batch_size为25，那么需要40次才能完整的测试一次。 所以test_iter为40；这个数要大于等于40. 学习率学习率变化规律我们设置为随着迭代次数的增加，慢慢变低。总共迭代47500次，我们将变化5次，所以stepsize设置为47500/5=9500，即每迭代9500次，我们就降低一次学习率。]]></content>
      <categories>
        <category>笔记</category>
        <category>caffe</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库和数据仓库的区别]]></title>
    <url>%2F2017%2F02%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[知乎问题：https://www.zhihu.com/question/20623931 数据库数据库是面向事务的设计，一般存储在线交易数据，尽量避免冗余，一般采用符合范式的规则来设计，主要是基本的、日常的事务处理，例如银行交易。例如MySQL，Oracle，MS SQL 数据仓库数据仓库是面向主题设计的。一般存储历史数据，采用反范式的规则来设计，有意引入冗余，为了分析数据而设计，反映历史变化，用于支持管理决策。例如Hive]]></content>
      <categories>
        <category>IT</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh免密码登录]]></title>
    <url>%2F2017%2F02%2F17%2Fssh%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[单机配置方式客户端（A）免密码登录服务器（B） A: ssh-keygen -t rsa A: cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys A: scp ~/.ssh/id_rsa.pub XXX@remotehost:/home/XXX/pubfile B: ssh-keygen -t rsa B: cat ~/pubfile &gt;&gt; ~/.ssh/authorized_keys A: ssh-add ~/.ssh/id_rsa A: chmod 700 ~/.ssh A: chmod 600 ~/.ssh/authorized_keys 集群配置方式12345#在cluster1上操作。并且假设共有3个集群ssh-keygen -t rsa #生成密钥对for ip in `seq 2 3`; do ssh-copy-id -i .ssh/id_rsa.pub uname@192.168.100.10$ip; done #这里集群的ip地址为192.168.100.101~103#同样在cluster2和cluster3上做同样的操作 安装ansibleansible是一个很方便的集群管理工作，打通了ssh之后，可以在集群上面操作同样的命令 1234567sudo apt-get install ansiblecd /etc/ansible/vi hosts #修改组名称ansible groupId -m shell -a 'shell commands;' #shell命令# 查看某组的目标机器上的当前时间ansible groupname -a 'date' 数据某组上所有目标机器的当前时间]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>教程</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu安装hadoop和hbase教程]]></title>
    <url>%2F2017%2F02%2F17%2Fubuntu%E5%AE%89%E8%A3%85hadoop%E5%92%8Chbase%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[ubuntu安装hadoop和hbase教程创建hadoop用户和hadoop用户组sudo addgroup hadoop sudo adduser -ingourp hadoop hadoop sudo gedit /etc/sudoers 最后显示结果如下： 安装ssh免密码登录见此文 配置java环境见此文 安装hadoop2 官网下载： http://mirror.bit.edu.cn/apache/hadoop/common/ 安装,修改文件拥有者为hadoop,修改权限为774 sudo chown -R hadoop:hadoop hadoop-install-path sudo chmod 774 hadoop-install-path 配置环境变量 123456789101112#HADOOP VARIABLES STARTexport JAVA_HOME=/usr/lib/jvm/java­7­openjdk­amd64 #注意修改路径export HADOOP_INSTALL=/usr/local/hadoopexport PATH=$PATH:$HADOOP_INSTALL/binexport PATH=$PATH:$HADOOP_INSTALL/sbinexport HADOOP_MAPRED_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_HOME=$HADOOP_INSTALLexport HADOOP_HDFS_HOME=$HADOOP_INSTALLexport YARN_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/nativeexport HADOOP_OPTS="­Djava.library.path=$HADOOP_INSTALL/lib"#HADOOP VARIABLES END 单机配置（非分布式）执行如下操作：12345cd /usr/local/hadoop$ mkdir ./input$ cp ./etc/hadoop/*.xml ./input # 将配置文件作为输入文件$ ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop­mapreduce­examples­*.jar grep ./input ./output 'dfs[az.]+'$ cat ./output/* # 查看运行结果 注意hadoop不会覆盖结果文件，因此需要删除./output 伪分布式配置（单台机器模拟多个节点）需要修改两个配置文件：core-site.xml hdfs-site.xml 修改 core-sit.xml 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改配置文件 hdfs-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 执行NameNode初始化 ./bin/hdfs namenode -format 成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示，若为 “Exitting with status 1” 则是出错。 开启NameNode 和 DataNode守护进程 ./sbin/start-dfs.sh 通过$jps命令可以查看是否启动相关进程（NameNode，DataNode,SecondaryNameNode） 成功启动后在浏览器输入http://localhost:50070可以查看NameNode和DataNode信息 注意：启动失败可以尝试如下操作 12345# 针对 DataNode 没法启动的解决方法./sbin/stop-dfs.sh # 关闭rm -r ./tmp # 删除 tmp 文件，注意这会删除 HDFS 中原有的所有数据./bin/hdfs namenode -format # 重新格式化 NameNode./sbin/start-dfs.sh # 重启 启动YARN 伪分布式不一定要启动YARN 启动Yarn来管理资源，负责任务调度 修改配置文件 mapred-site.xml mv ./etc/hadoop/mapred­site.xml.template ./etc/hadoop/mapred­site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改配置文件 yarn-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux­services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动yarn ./sbin/start­-yarn.sh # 启动YARN ./sbin/mr­jobhistory­daemon.sh start historyserver # 开启历史服务器，才能在Web中查看任务运行情况 开启jps，出现NodeManager和ResourceManager两个后台进程，通过web界面ResourceManager 可以查看任务运行情况 关闭yarn./sbin/stop-yarn.sh ./sbin/mr­jobhistory­daemon.sh stop historyserver 注意:不启动 YARN 需重命名 mapred­site.xml如果不想启动 YARN，务必把配置文件 mapred­site.xml 重命名，改成 mapred­site.xml.template，需要用时改回来就行。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred­site.xml.template。]]></content>
      <categories>
        <category>解决方案</category>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hbase</tag>
        <tag>ubuntu</tag>
        <tag>教程</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]解决 Ubuntu14.04 系统WiFi经常掉线问题]]></title>
    <url>%2F2017%2F01%2F17%2F%E5%8E%9F-%E8%A7%A3%E5%86%B3-Ubuntu14-04-%E7%B3%BB%E7%BB%9FWiFi%E7%BB%8F%E5%B8%B8%E6%8E%89%E7%BA%BF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[首先使用$lspci -vv &gt;&gt; filename 命令来查看本机的硬件信息，查看网卡部分可以看到网卡驱动型号。我安装的Ubuntu14,04.5系统内核是4.4.0-31-generic, 系统自带的无线网卡驱动是RealtekRTL8723BE. 由于内核版本和无线网卡驱动版本不兼容导致无线网卡过一段时间就会出现自动休眠省电，因此需要进行设置来保证无线网卡的正常使用。 解决方案： 找到/etc/modprobe.d/rtl8723be.conf (没有的话自己新建)， 写入下面的代码：1options rtl8723be ips=0 fwlps=0 swlps=0 swenc=1 保存后重启就ok 说明： ips, “using no link power save (default 1 is open）不使用链接省电 默认是1 默认是开启 就是启用省电。 fwlps, “using linked fw control power save (default 1 is open）链接FW控制省电 默认是1 就是打开省电设置 swenc, “using hardware crypto (default 0 [hardware]）硬件加密设置 默认是0]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>wifi</tag>
        <tag>系统bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]Ubuntu 14.04 64位系统安装cuda8.0+cudnn7.5+opencv+caffe 血泪教程]]></title>
    <url>%2F2017%2F01%2F14%2F%E5%8E%9F-Ubuntu-14-04-64%E4%BD%8D%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85cuda8-0-cudnn7-5-opencv-caffe-%E8%A1%80%E6%B3%AA%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Ubuntu 14.04 64位系统安装caffe 血泪教程1.安装环境 硬件配置： 笔记本：神舟战神 Z6-i78154S2 CPU: Intel Core i7-4720HQ 显卡: Intel 集成显卡 + GTX 960M 硬盘: SSD + HDD 软件配置： 操作系统：Win10 (SSD) + Ubuntu 14.04（内核版本：4.4.0-31-generic ，使用$ uname -r 可以查看） 2.安装Ubuntu 14.04 64位操作系统由于我电脑有两块硬盘，SSD已经安装了Win10，因此在HDD里面划分150G用于安装Ubuntu系统，启动文件还是在SSD中。1、需要准备的软件：ubuntu14.04系统镜像，EasyBCD软件，用于在windows上面安装ubuntu系统引导。2、进入windows操作系统，安装easyBCD软件，打开磁盘管理器，压缩卷（空间大小不少于8G，用于存放Ubuntu系统），删除卷，使之成为“未分配”状态（黑色）3、把Ubuntu系统镜像拷贝到C盘根目录下，把ubuntu系统镜像文件中casper目录下 initrd.lz 和 vmlinuz.efi 拷贝出来放到C盘根目录下。4、运行EasyBCD软件，“添加新条目”==》”NeoGrub”==》“安装”==》“配置”输入一下内容：1234title Install Ubunturoot (hd0,0)kernel (hd0,0)/vmlinuz.efi boot=casper iso-scan/filename=/ubuntu-14.04.5-desktop-amd64.iso ro quiet splash locale=zh_CN.UTF-8initrd (hd0,0)/initrd.lz menu.list格式一般有四行，kernel到……UTF-8需要放在一行，且每个参数需要用空格隔开，注意kernel后面的文件名要和下载的文件名一致。 title xxx, bootloader进去之后看到的菜单选项名称，必须保留 root (hd[n],[m])，root开头,然后一个空格,加一个分区名称(hd[n­],[m­])。表示 iso、vmlinuz.efi和 initrd.lz 的绝对路径，其中n表示iso文件所在的盘符序号，m表示第几个分区，n和m都是从0开始算起 kernel (hd[n],[m]), 以kernel 开头,然后加一个空格,并在其后给定vmlinuz.efi文件存放路径,这个命令行的作用是告诉计算机将使用(hd[n­1],[m­1])分区下的 linux 目录中的 kernel 内核来启动。ro表示只读。filename后面的iso务必与目标iso文件命名一致。 initrd (hd[n,hd[m])/initrd.lz ,he kernal 行类似，致命安装的文件放在哪个分区和哪个目录中 至此，windows上所有的准备工作完成5、重启选择NeoGrub引导加载器。进入ubuntu安装界面，桌面有一个“安装” 和“实例”，注意不要急着安装。6、Ctrl+ALt+t，打开终端，输入一下命令取消isodevice光驱分区，否则会有挂载错误。1sudo umount -l /isodevice/ 执行之后，点击桌面安装图标7、Ubuntu系统“安装类型”选择“其他选项”，我们进行手动分区 首先设置Swap挂载点：大小通常和自己的内存一样或者两倍，如果物理内存大，逻辑分区，也可以不用设置。 设置boot分区：不一定需要分出来，看你把引导挂在那个位置，逻辑分区，设置建议大小200～300MB，逻辑分区 设置“/”分区，剩下全部大小，逻辑分区 设置“安装系统引导的设备”：如果有/boot分区，则选择/boot分区，没有设置的话，可以放在其他位置。（提示：如果先设置了主分区，后面就默认全是主分区了，以后重装系统的话需要将基本磁盘转为动态磁盘才可以将硬盘划分为未分配状态，比较麻烦，建议全部设置为逻辑分区） 8、一路Next，安装成功，重启先进入windows系统，打开EasyBCD==”添加新条目“++》”Linux/BSD”==&gt;”GRUB 2”==&gt;”名称自己定义”==&gt;”驱动器和上一步设置的安装系统引导设备一致”==》“添加条目”。在编辑引导菜单里面可以修改引导顺序或者删除NeoGrub引导。重启进入Ubuntu 参考链接：http://blog.csdn.net/xlf13872135090/article/details/24093203 http://www.jb51.net/os/windows/298507.html 3.安装cuda8.0 1.更改系统默认源打开软件更新器=》Ubuntu软件==》下载自==》其他站点==》选择最佳服务器，我选择的是mirros.hust.edu.cn，这里说明一下，如果不更改系统默认源，后面安装cuda的依赖很多都找不到。2.准备安装文件：cuda8.0.44，从Nvida官网下载，下载链接 ，经过多次尝试，使用runfile (local)模式安装成功可能性要高些。下载cuDNN，下载链接 ，需要注册审核，可以从网上其他地方下载。3.安装开发依赖包，工具软件123sudo apt-get install build-essentialsudo apt-get install vim cmake gitsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler 更新gcc到4.9版本，如果是gcc5.0版本，需要进行降级。12345678910sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get updatesudo apt-get install gcc-4.9sudo apt-get install g++-4.9更新软链接sudo sucd ../../usr/binln -s /usr/bin/g++-4.9 /usr/bin/g++ -fln -s /usr/bin/gcc-4.9 /usr/bin/gcc -f 其他注意事项参加cuda的官方文档, 遇到问题首先查看官方文档4.检查电脑环境是否具备安装cuda条件 检查电脑GPU是否是CUDA-capable 12终端输入 $ lspci | grep -i nvidia如果显示自己的NVIDIA GPU版本信息，则表示没问题，可以去CUDA官网查看自己的GPU版本是否在支持的列表中 检查Linux版本是否支持（Ubuntu14.04没问题) 检查自己的系统的内核是否支持,内核可以用$ uname -r 命令查看，官网给出的内核版本是最低内核版本要求 5.安装cuda8.0 (a)禁用nouveau123456789101112$ lsmod | grep nouveau如果有输出则表示nouveau正在加载因此我们需要禁用,方法如下：在/etc/modprobe.d目录下添加文件blacklist-nouveau.conf输入以下内容blacklist nouveauoptions nouveau modeset=0打开终端运行$ sudo update-initramfs -u重启后再次运行$ lsmod | grep nouveau如果没有输出，则禁用成功 (b) 重启电脑，到达登录界面时，进入text mode ,按Ctrl+Alt+F1，登录账户，关闭图形化界面1$ sudo service lightdm stop (c) cd到cuda安装文件路径，运行 $ sudo sh cuda_8.0.44_linux.run根据提示一步步操作，注意不要安装openGL（如果你的电脑和我一样是双显卡，且主显卡为非NVIDIA的GPU，选择no，否则可以yes），否则会覆盖系统集成先看的openGL,导致无法进入桌面注意：如果没有安装oenpGL，则在后面编译cuda自带的samples会报错，缺少can not find /usr/ld -lglut，这个是由于没有安装openGL造成的，因此需要手动安装 (d)安装成功后显示installed，如果安装失败，在/tmp目录下有cuda的安装日志，可以查看日志排错。 我第一次安装遇到了 ”缺少 libGLU.so libXmu.so libGL.so 依赖“的问题, 解决方法：sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-devsudo update-initramfs -usudo ldconfig //环境变量立即生效 (e)输入$ sudo service lightdm start 重启图形化界面，如果能够成功登录，cuda安装没问题了 (f) 重启电脑，检查 Device Node Verification检查路径“/dev”是否存在 nvidia*的多个文件，没有的话，参考官方文档的操作步骤，进行添加 (g) 设置环境变量12345678910111213$ sudo vim /etc/profile在文件末尾添加以下两行$ export PATH=/usr/local/cuda-8.0/bin:$PATH$ export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64使文件生效$ source /etc/profile动态链接库设置创建文件：sudo vim /etc/ld.so.conf.d/cuda.conf写入：/usr/local/cuda/lib64保存之后使其立即生效：sudo ldconfig -v (h)安装cuda完毕后的检查工作 检查NVIDIA 驱动是否安装成功: $ cat /etc/driver/nvidia/version, 安装成功则输出版本号信息 检查cuda Toolkit：$ nvcc -V 会输出CUDA的版本信息 尝试编译cuda提供的例子 cd ~/NVIDIA_CUDA-8.0_Samplesmake all -j4cd bin/x86_64/linux/release/./deviceQuery如果显示了设备信息，则cuda安装成功 由于我之前没有安装openGL，因此报告”/usr/bin/ld: 找不到 -lglut“错误解决方案如下:$ sudo apt-get install freeglut3-dev 至此，CUDA8.0的安装结束 4.安装cuDNN进入到cuDNN的文件目录，执行以下命令1234567891011tar -zxvf cudnn-7.5-linux-x64-v5.0-ga.tgzcd cudasudo cp lib64/* /usr/local/cuda/lib64/sudo cp include/cudnn.h /usr/local/cuda/include/更新软链接：cd /usr/local/cuda/lib64/sudo chmod +r libcudnn.so.5.0.5sudo ln -sf libcudnn.so.5.0.5 libcudnn.so.5sudo ln -sf libcudnn.so.5 libcudnn.sosudo ldconfig 5.安装Intel MKL或者AtlasMKL需要收费，这里安装Atlas1sudo apt-get install libatlas-base-dev 6.安装OpenCV（不是必须的）根据官网的安装步骤来进行安装：官网链接, 安装编译opencv的环境：sudo apt-get install build-essential make cmake git libgtk2.0-dev pkg-config python python-dev python-numpy libavcodec-dev libavformat-dev libswscale-dev libjpeg-dev libpng-dev libtiff-dev git下载opencv源码：12345678910cd ~git clone https://github.com/itseez/opencvcd opencvgit checkout 2.4.13.2 # 你需要安装哪个版本就切换到哪个分支上sudo mkdir buildcd buildsudo cmake -j4 -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..sudo make -j4sudo make -j4 installsudo ldconfig 7.安装caffe所需要的Python环境有两种方法： 方法一：去Anaconda官网下载安装包切换到文件所在目录，执行 12345678bash Anaconda-2.3.0-Linux-x86_64.sh添加Anaconda Library Path在 /etc/ld.so.conf 中新建anaconda.conf添加以下路径(实际为你的anaconda安装路径)/home/username/anaconda/libsudo vim /etc/profileexport LD_LIBRARY_PATH="/home/username/anaconda/lib:$LD_LIBRARY_PATH"source /etc/profile 方法二：直接手动安装Python的依赖包 1sudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose python-dev python-sklearn python-skimage python-h5py python-protobuf python-leveldb python-networkx python-gflags cython ipython python-yaml 使用方法一或者方法二安装完caffe的Python依赖后，执行git命令，下载caffe12cd ~git clone https://github.com/BVLC/caffe.git 进入caffe目录下的python 文件夹，安装requirement里面的包，执行命令12sudo sufor req in $(cat requirements.txt); do pip install $req; done 安装完成后，退出root权限exit 8.编译caffe首先需要修改配置文件123cd ~/caffecp Makefile.config.example Makefile.configvim Makefile.config 需要修改两处：（1）使用cuDNN USE_CUDNN := 1 这里去掉#，取消注释为USE_CUDNN := 1（2）修改python包目录（如果使用方法二安装python依赖的需要修改，使用方法一不需要）PYTHON_INCLUDE := /usr/include/python2.7 \ /usr/lib/python2.7/dist-packages/numpy/core/include改为PYTHON_INCLUDE := /usr/include/python2.7 \ /usr/local/lib/python2.7/dist-packages/numpy/core/include因为新安装的python包目录在这里： /usr/local/lib/python2.7/dist-packages/ 接下来就到了激动人心的编译时刻了1234make all -j4make testmake runtestmake pycaffe 这个时候进入caffe下的python目录，试试python wrapper有没有安装好12$python$ import caffe 如果不报错，则安装成功]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>caffe</tag>
        <tag>ubuntu</tag>
        <tag>教程</tag>
        <tag>cuda</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]分布式网站架构后续：zookeeper技术浅析]]></title>
    <url>%2F2016%2F12%2F05%2F%E8%BD%AC-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%AB%99%E6%9E%B6%E6%9E%84%E5%90%8E%E7%BB%AD-zookeeper%E6%8A%80%E6%9C%AF%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[转载自：http://www.cnblogs.com/sharpxiajun/archive/2013/06/02/3113923.html Zookeeper是hadoop的一个子项目，虽然源自hadoop，但是我发现zookeeper脱离hadoop的范畴开发分布式框架的运用越来越多。今天我想谈谈zookeeper，本文不谈如何使用zookeeper，而是zookeeper到底有哪些实际的运用，哪些类型的应用能发挥zookeeper的优势，最后谈谈zookeeper对分布式网站架构能产生怎样的作用。 Zookeeper是针对大型分布式系统的高可靠的协调系统。由这个定义我们知道zookeeper是个协调系统，作用的对象是分布式系统。为什么分布式系统需要一个协调系统了？理由如下： 开发分布式系统是件很困难的事情，其中的困难主要体现在分布式系统的“部分失败”。“部分失败”是指信息在网络的两个节点之间传送时候，如果网络出了故障，发送者无法知道接收者是否收到了这个信息，而且这种故障的原因很复杂，接收者可能在出现网络错误之前已经收到了信息，也可能没有收到，又或接收者的进程死掉了。发送者能够获得真实情况的唯一办法就是重新连接到接收者，询问接收者错误的原因，这就是分布式系统开发里的“部分失败”问题。 Zookeeper就是解决分布式系统“部分失败”的框架。Zookeeper不是让分布式系统避免“部分失败”问题，而是让分布式系统当碰到部分失败时候，可以正确的处理此类的问题，让分布式系统能正常的运行。 下面我要讲讲zookeeper的实际运用场景： 场景一：有一组服务器向客户端提供某种服务（例如：我前面做的分布式网站的服务端，就是由四台服务器组成的集群，向前端集群提供服务），我们希望客户端每次请求服务端都可以找到服务端集群中某一台服务器，这样服务端就可以向客户端提供客户端所需的服务。对于这种场景，我们的程序中一定有一份这组服务器的列表，每次客户端请求时候，都是从这份列表里读取这份服务器列表。那么这分列表显然不能存储在一台单节点的服务器上，否则这个节点挂掉了，整个集群都会发生故障，我们希望这份列表时高可用的。高可用的解决方案是：这份列表是分布式存储的，它是由存储这份列表的服务器共同管理的，如果存储列表里的某台服务器坏掉了，其他服务器马上可以替代坏掉的服务器，并且可以把坏掉的服务器从列表里删除掉，让故障服务器退出整个集群的运行，而这一切的操作又不会由故障的服务器来操作，而是集群里正常的服务器来完成。这是一种主动的分布式数据结构，能够在外部情况发生变化时候主动修改数据项状态的数据机构。Zookeeper框架提供了这种服务。这种服务名字就是：统一命名服务，它和javaEE里的JNDI服务很像。 场景二：分布式锁服务。当分布式系统操作数据，例如：读取数据、分析数据、最后修改数据。在分布式系统里这些操作可能会分散到集群里不同的节点上，那么这时候就存在数据操作过程中一致性的问题，如果不一致，我们将会得到一个错误的运算结果，在单一进程的程序里，一致性的问题很好解决，但是到了分布式系统就比较困难，因为分布式系统里不同服务器的运算都是在独立的进程里，运算的中间结果和过程还要通过网络进行传递，那么想做到数据操作一致性要困难的多。Zookeeper提供了一个锁服务解决了这样的问题，能让我们在做分布式数据运算时候，保证数据操作的一致性。 场景三：配置管理。在分布式系统里，我们会把一个服务应用分别部署到n台服务器上，这些服务器的配置文件是相同的（例如：我设计的分布式网站框架里，服务端就有4台服务器，4台服务器上的程序都是一样，配置文件都是一样），如果配置文件的配置选项发生变化，那么我们就得一个个去改这些配置文件，如果我们需要改的服务器比较少，这些操作还不是太麻烦，如果我们分布式的服务器特别多，比如某些大型互联网公司的hadoop集群有数千台服务器，那么更改配置选项就是一件麻烦而且危险的事情。这时候zookeeper就可以派上用场了，我们可以把zookeeper当成一个高可用的配置存储器，把这样的事情交给zookeeper进行管理，我们将集群的配置文件拷贝到zookeeper的文件系统的某个节点上，然后用zookeeper监控所有分布式系统里配置文件的状态，一旦发现有配置文件发生了变化，每台服务器都会收到zookeeper的通知，让每台服务器同步zookeeper里的配置文件，zookeeper服务也会保证同步操作原子性，确保每个服务器的配置文件都能被正确的更新。 场景四：为分布式系统提供故障修复的功能。集群管理是很困难的，在分布式系统里加入了zookeeper服务，能让我们很容易的对集群进行管理。集群管理最麻烦的事情就是节点故障管理，zookeeper可以让集群选出一个健康的节点作为master，master节点会知道当前集群的每台服务器的运行状况，一旦某个节点发生故障，master会把这个情况通知给集群其他服务器，从而重新分配不同节点的计算任务。Zookeeper不仅可以发现故障，也会对有故障的服务器进行甄别，看故障服务器是什么样的故障，如果该故障可以修复，zookeeper可以自动修复或者告诉系统管理员错误的原因让管理员迅速定位问题，修复节点的故障。大家也许还会有个疑问，master故障了，那怎么办了？zookeeper也考虑到了这点，zookeeper内部有一个“选举领导者的算法”，master可以动态选择，当master故障时候，zookeeper能马上选出新的master对集群进行管理。 下面我要讲讲zookeeper的特点： zookeeper是一个精简的文件系统。这点它和hadoop有点像，但是zookeeper这个文件系统是管理小文件的，而hadoop是管理超大文件的。zookeeper提供了丰富的“构件”，这些构件可以实现很多协调数据结构和协议的操作。例如：分布式队列、分布式锁以及一组同级节点的“领导者选举”算法。zookeeper是高可用的，它本身的稳定性是相当之好，分布式集群完全可以依赖zookeeper集群的管理，利用zookeeper避免分布式系统的单点故障的问题。zookeeper采用了松耦合的交互模式。这点在zookeeper提供分布式锁上表现最为明显，zookeeper可以被用作一个约会机制，让参入的进程不在了解其他进程的（或网络）的情况下能够彼此发现并进行交互，参入的各方甚至不必同时存在，只要在zookeeper留下一条消息，在该进程结束后，另外一个进程还可以读取这条信息，从而解耦了各个节点之间的关系。zookeeper为集群提供了一个共享存储库，集群可以从这里集中读写共享的信息，避免了每个节点的共享操作编程，减轻了分布式系统的开发难度。zookeeper的设计采用的是观察者的设计模式，zookeeper主要是负责存储和管理大家关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper 就将负责通知已经在 Zookeeper 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式。 由此可见zookeeper很利于分布式系统开发，它能让分布式系统更加健壮和高效。 前不久我参加了部门的hadoop兴趣小组，测试环境的hadoop、mapreduce、hive及hbase都是我来安装的，安装hbase时候安装要预先安装zookeeper，最早我是在四台服务器上都安装了zookeeper，但是同事说安装四台和安装三台是一回事，这是因为zookeeper要求半数以上的机器可用，zookeeper才能提供服务，所以3台的半数以上就是2台了，4台的半数以上也是两台，因此装了三台服务器完全可以达到4台服务器的效果，这个问题说明zookeeper进行安装的时候通常选择奇数台服务器。在学习hadoop的过程中，我感觉zookeeper是最难理解的一个子项目，原因倒不是它技术负责，而是它的应用方向很让我困惑，所以我有关hadoop技术第一篇文章就从zookeeper开始，也不讲具体技术实现，而从zookeeper的应用场景讲起，理解了zookeeper应用的领域，我想再学习zookeeper就会更加事半功倍。 之所以今天要谈谈zookeeper，也是为我上一篇文章分布式网站框架的补充。虽然我设计网站架构是分布式结构，也做了简单的故障处理机制，比如：心跳机制，但是对集群的单点故障还是没有办法的，如果某一台服务器坏掉了，客户端任然会尝试连接这个服务器，导致部分请求的阻塞，也会导致服务器资源的浪费。不过我目前也不想去修改自己的框架，因为我总觉得在现有的服务上添加zookeeper服务会影响网站的效率，如果有独立的服务器集群部署zookeeper还是值得考虑的，但是服务器资源太宝贵了，这个可能性不大。幸好我们部门也发现了这样的问题，我们部门将开发一个强大的远程调用框架，将集群管理和通讯管理这块剥离出来，集中式提供高效可用的服务，等部门的远程框架开发完毕，我们的网站加入新的服务，我想我们的网站将会更加稳定和高效。]]></content>
      <categories>
        <category>综述</category>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>分布式</tag>
        <tag>zookeeper</tag>
        <tag>综述</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Linux下的Kafka配置步骤]]></title>
    <url>%2F2016%2F12%2F05%2F%E8%BD%AC-Linux%E4%B8%8B%E7%9A%84Kafka%E9%85%8D%E7%BD%AE%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[转载自：http://blog.csdn.net/suifeng3051/article/details/38321043 Kafka集群配置比较简单，为了更好的让大家理解，在这里要分别介绍下面三种配置 单节点：一个broker的集群 单节点：多个broker的集群 多节点：多broker集群 一、单节点单broker实例的配置 1. 首先启动zookeeper服务必须使用root用户启动kafkaKafka本身提供了启动zookeeper的脚本（在kafka/bin/目录下）和zookeeper配置文件（在kafka/config/目录下），首先进入Kafka的主目录（可通过 whereis kafka命令查找到）：1234567[root@localhost kafka-0.8]# bin/zookeeper-server-start.sh config/zookeeper.propertieszookeeper配置文件的一些重要属性:# Data directory where the zookeeper snapshot is stored.dataDir=/tmp/zookeeper# The port listening for client requestclientPort=2181默认情况下，zookeeper服务器会监听 2181端口，更详细的信息可去zookeeper官网查阅。## 2. 启动Kafka broker运行kafka提供的启动kafka服务脚本即可：12345678[root@localhost kafka-0.8]# bin/kafka-server-start.sh config/server.propertiesbroker配置文件中的重要属性：# broker的id. 每个broker的id必须是唯一的.Broker.id=0# 存放log的目录log.dir=/tmp/kafka8-logs# Zookeeper 连接串zookeeper.connect=localhost:2181## 3. 创建一个仅有一个Partition的topic [root@localhost kafka-0.8]# bin/kafka-create-topic.sh –zookeeper localhost:2181 –replica 1 –partition 1 –topic kafkatopic## 4. 用Kafka提供的生产者客户端启动一个生产者进程来发送消息 [root@localhost kafka-0.8]# bin/kafka-console-producer.sh –broker-list localhost:9092 –topic kafkatopic其中有两个参数需要注意：- broker-list:定义了生产者要推送消息的broker地址，以&lt;IP地址:端口&gt;形式- topic：生产者发送给哪个topic## 5. 启动一个Consumer实例来消费消息 [root@localhost kafka-0.8]# bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic kafkatopic –from-beginning当你执行这个命令之后，你便可以看到控制台上打印出的生产者生产的消息：和消费者相关的属性配置存放在Consumer.properties文件中，重要的属性有： # consumer的group id (A string that uniquely identifies a set of consumers # within the same consumer group) groupid=test-consumer-group # zookeeper 连接串 zookeeper.connect=localhost:2181# 二、单节点运行多broker实例前面的步骤和单节点运行但broker实例一样## 1、启动zookeeper## 2、启动Kafka的broker要想在一台机器上启动多个broker实例，只需要准备多个server.properties文件即可，比如我们要在一台机器上启动两个broker：首先我们要准备两个server.properties配置文件12345678server-1brokerid=1port=9092log.dir=/temp/kafka8-logs/broker1 server-2brokerid=2port=9093log.dir=/temp/kafka8-logs/broker2然后我们再用这两个配置文件分别启动一个broker12[root@localhost kafka-0.8]# env JMX_PORT=9999 bin/kafka-server-start.sh config/server-1.properties[root@localhost kafka-0.8]# env JMX_PORT=10000 bin/kafka-server-start.sh config/server-2.properties可以看到我们启动是为每个broker都指定了不同的JMX Port，JMX Port主要用来利用jconsole等工具进行监控和排错 3.创建一个topic现在我们要创建一个含有两个Partition分区和2个备份的broker： [root@localhost kafka-0.8]# bin/kafka-create-topic.sh --zookeeper localhost:2181 --replica 2 --partition 2 --topic othertopic 4.启动Producer发送消息如果我们要用一个Producer发送给多个broker，唯一需要改变的就是在broker-list属性中指定要连接的broker： [root@localhost kafka-0.8]# bin/kafka-console-producer.sh --broker-list localhost:9092,localhost:9093 --topic othertopic 如果我们要让不同的Producer发送给不同的broker，我们也仅仅需要为每个Producer配置响应的broker-list属性即可。 5.启动一个消费者来消费消息和之前的命令一样 [root@localhost kafka-0.8]# bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic othertopic --from-beginning 三、集群模式（多节点多实例）介绍了上面两种配置方法，再理解集群配置就简单了，比如我们要配置如下图所示集群：zookeeper配置文件（zookeeper.properties）：不变broker的配置配置文件(server.properties)：按照单节点多实例配置方法在一个节点上启动两个实例，不同的地方是zookeeper的连接串需要把所有节点的zookeeper都连接起来 Zookeeper 连接串 zookeeper.connect=node1:2181,node2:2181]]></content>
      <categories>
        <category>解决方案</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>linux</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Markdown使用技巧总结——字体，颜色，字号，背景，首行缩进等]]></title>
    <url>%2F2016%2F12%2F05%2F%E8%BD%AC-Markdown%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%E2%80%94%E2%80%94%E5%AD%97%E4%BD%93%EF%BC%8C%E9%A2%9C%E8%89%B2%EF%BC%8C%E5%AD%97%E5%8F%B7%EF%BC%8C%E8%83%8C%E6%99%AF%EF%BC%8C%E9%A6%96%E8%A1%8C%E7%BC%A9%E8%BF%9B%E7%AD%89%2F</url>
    <content type="text"><![CDATA[转载自：http://blog.csdn.net/u010177286/article/details/50358720 Markdown 常用技巧：换行: 方法1: 连续两个以上空格+回车方法2：使用html语言换行标签：首行缩进两个字符：(每个表示一个空格，连续使用两个即可） &ensp; 半角的空格&emsp; 全角的空格字体、字号与颜色: Markdown是一种可以使用普通文本编辑器编写的标记语言，通过类似HTML的标记语法，它可以使普通文本内容具有一定的格式。但是它本身是不支持修改字体、字号与颜色等功能的！ CSDN-markdown编辑器是其衍生版本，扩展了Markdown的功能（如表格、脚注、内嵌HTML等等）！对，就是内嵌HTML，接下来要讲的功能就需要使用内嵌HTML的方法来实现。 字体，字号和颜色编辑如下代码我是黑体字我是微软雅黑我是华文彩云color=#0099ff size=72 face=”黑体”color=#00ffffcolor=gray Size：规定文本的尺寸大小。可能的值：从 1 到 7 的数字。浏览器默认值是 3具体颜色分类及标记请参照：各种颜色 背景色:Markdown本身不支持背景色设置，需要采用内置html的方式实现：借助 table, tr, td 等表格标签的 bgcolor 属性来实现背景色的功能。举例如下： 背景色是：orange效果如下：背景色是：orange2015/12/19 16:04:07分割线：你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线 链接：链接文字都是用 [方括号] 来标记,在方块括号后面紧接着圆括号并插入网址链接即可:可参照This link has no title attribute. 代码块： 代码块：用2个以上TAB键起始的段落，会被认为是代码块（效果如下）： struct { int year; int month; int day; }bdate; 如果在一个行内需要引用代码，只要用反引号`引起来就好(Esc健） 代码块与语法高亮：在需要高亮的代码块的前一行及后一行使用三个反引号“`”，同时第一行反引号后面表面代码块所使用的语言插入互联网上图片： 使用LaTex数学公式:行内公式：使用两个”$”符号引用公式: $公式$行间公式：使用两对“$$”符号引用公式： $$公式$$]]></content>
      <categories>
        <category>IT</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Linux常用命令大全]]></title>
    <url>%2F2016%2F12%2F05%2F%E8%BD%AC-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[转载自：http://www.php100.com/html/webkaifa/Linux/2009/1106/3485.html 1、系统信息arch 显示机器的处理器架构(1)uname -m 显示机器的处理器架构(2)uname -r 显示正在使用的内核版本dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI)hdparm -i /dev/hda 罗列一个磁盘的架构特性hdparm -tT /dev/sda 在磁盘上执行测试性读取操作cat /proc/cpuinfo 显示CPU info的信息cat /proc/interrupts 显示中断cat /proc/meminfo 校验内存使用cat /proc/swaps 显示哪些swap被使用cat /proc/version 显示内核的版本cat /proc/net/dev 显示网络适配器及统计cat /proc/mounts 显示已加载的文件系统lspci -tv 罗列 PCI 设备lsusb -tv 显示 USB 设备date 显示系统日期cal 2007 显示2007年的日历表date 041217002007.00 设置日期和时间 - 月日时分年.秒clock -w 将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 )shutdown -h now 关闭系统(1)init 0 关闭系统(2)telinit 0 关闭系统(3)shutdown -h hours:minutes &amp; 按预定时间关闭系统shutdown -c 取消按预定时间关闭系统shutdown -r now 重启(1)reboot 重启(2)logout 注销 2、文件和目录cd /home 进入 ‘/ home’ 目录’cd .. 返回上一级目录cd ../.. 返回上两级目录cd 进入个人的主目录cd ~user1 进入个人的主目录cd - 返回上次所在的目录pwd 显示工作路径ls 查看目录中的文件ls -F 查看目录中的文件ls -l 显示文件和目录的详细资料ls -a 显示隐藏文件ls [0-9] 显示包含数字的文件名和目录名tree 显示文件和目录由根目录开始的树形结构(1)lstree 显示文件和目录由根目录开始的树形结构(2)mkdir dir1 创建一个叫做 ‘dir1’ 的目录’mkdir dir1 dir2 同时创建两个目录mkdir -p /tmp/dir1/dir2 创建一个目录树rm -f file1 删除一个叫做 ‘file1’ 的文件’rmdir dir1 删除一个叫做 ‘dir1’ 的目录’rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内容rm -rf dir1 dir2 同时删除两个目录及它们的内容mv dir1 new_dir 重命名/移动 一个目录cp file1 file2 复制一个文件cp dir/ . 复制一个目录下的所有文件到当前工作目录cp -a /tmp/dir1 . 复制一个目录到当前工作目录cp -a dir1 dir2 复制一个目录ln -s file1 lnk1 创建一个指向文件或目录的软链接ln file1 lnk1 创建一个指向文件或目录的物理链接touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm)file file1 outputs the mime type of the file as texticonv -l 列出已知的编码iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding.find . -maxdepth 1 -name .jpg -print -exec convert “{}” -resize 80x60 “thumbs/{}” \; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 3、文件搜索find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录find / -user user1 搜索属于用户 ‘user1’ 的文件和目录find /home/user1 -name *.bin 在目录 ‘/ home/user1’ 中搜索带有’.bin’ 结尾的文件find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件find / -name *.rpm -exec chmod 755 ‘{}’ \; 搜索以 ‘.rpm’ 结尾的文件并定义其权限find / -xdev -name *.rpm 搜索以 ‘.rpm’ 结尾的文件，忽略光驱、捷盘等可移动设备locate *.ps 寻找以 ‘.ps’ 结尾的文件 - 先运行 ‘updatedb’ 命令whereis halt 显示一个二进制文件、源码或man的位置which halt 显示一个二进制文件或可执行文件的完整路径 4、挂载一个文件系统mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 ‘/ mnt/hda2’ 已经存在umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 ‘/ mnt/hda2’ 退出fuser -km /mnt/hda2 当设备繁忙时强制卸载umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用mount /dev/fd0 /mnt/floppy 挂载一个软盘mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrommount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrommount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrommount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享 5、磁盘空间df -h 显示已经挂载的分区列表ls -lSr |more 以尺寸大小排列文件和目录du -sh dir1 估算目录 ‘dir1’ 已经使用的磁盘空间’du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小rpm -q -a –qf ‘%10{SIZE}t%{NAME}n’ | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)dpkg-query -W -f=’${Installed-Size;10}t${Package}n’ | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 6、用户和群组groupadd group_name 创建一个新用户组groupdel group_name 删除一个用户组groupmod -n new_group_name old_group_name 重命名一个用户组useradd -c “Name Surname “ -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 “admin” 用户组的用户useradd user1 创建一个新用户userdel -r user1 删除一个用户 ( ‘-r’ 排除主目录)usermod -c “User FTP” -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性passwd 修改口令passwd user1 修改一个用户的口令 (只允许root执行)chage -E 2005-12-31 user1 设置用户口令的失效期限pwck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的用户grpck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的群组newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 7、文件的权限 - 使用 “+” 设置权限，使用 “-“ 用于取消ls -lh 显示权限ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限chown user1 file1 改变一个文件的所有人属性chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性chgrp group1 file1 改变文件的群组chown user1:group1 file1 改变一个文件的所有人和群组属性find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限chmod u-s /bin/file1 禁用一个二进制文件的 SUID位chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的chmod g-s /home/public 禁用一个目录的 SGID 位chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件chmod o-t /home/public 禁用一个目录的 STIKY 位 8、文件的特殊属性 -使用 “+” 设置权限，使用 “-“ 用于取消chattr +a file1 只允许以追加方式读写文件chattr +c file1 允许这个文件能被内核自动压缩/解压chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接chattr +s file1 允许一个文件被安全地删除chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件lsattr 显示特殊的属性 9、打包和压缩文件bunzip2 file1.bz2 解压一个叫做 ‘file1.bz2’的文件bzip2 file1 压缩一个叫做 ‘file1’ 的文件gunzip file1.gz 解压一个叫做 ‘file1.gz’的文件gzip file1 压缩一个叫做 ‘file1’的文件gzip -9 file1 最大程度压缩rar a file1.rar test_file 创建一个叫做 ‘file1.rar’ 的包rar a file1.rar file1 file2 dir1 同时压缩 ‘file1’, ‘file2’ 以及目录 ‘dir1’rar x file1.rar 解压rar包unrar x file1.rar 解压rar包tar -cvf archive.tar file1 创建一个非压缩的 tarballtar -cvf archive.tar file1 file2 dir1 创建一个包含了 ‘file1’, ‘file2’ 以及 ‘dir1’的档案文件tar -tf archive.tar 显示一个包中的内容tar -xvf archive.tar 释放一个包tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包zip file1.zip file1 创建一个zip格式的压缩包zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包unzip file1.zip 解压一个zip格式压缩包 10、Ubuntu系统命令DEB 包 (Debian, Ubuntu 以及类似系统)dpkg -i package.deb 安装/更新一个 deb 包dpkg -r package_name 从系统删除一个 deb 包dpkg -l 显示系统中所有已经安装的 deb 包dpkg -l | grep httpd 显示所有名称中包含 “httpd” 字样的deb包dpkg -s package_name 获得已经安装在系统中一个特殊包的信息dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表dpkg –contents package.deb 显示尚未安装的一个包所提供的文件列表dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 APT 软件工具 (Debian, Ubuntu 以及类似系统)apt-get install package_name 安装/更新一个 deb 包apt-cdrom install package_name 从光盘安装/更新一个 deb 包apt-get update 升级列表中的软件包apt-get upgrade 升级所有已安装的软件apt-get remove package_name 从系统删除一个deb包apt-get check 确认依赖的软件仓库正确apt-get clean 从下载的软件包中清理缓存apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 11、查看文件内容cat file1 从第一个字节开始正向查看文件的内容tac file1 从最后一行开始反向查看一个文件的内容more file1 查看一个长文件的内容less file1 类似于 ‘more’ 命令，但是它允许在文件中和正向操作一样的反向操作head -2 file1 查看一个文件的前两行tail -2 file1 查看一个文件的最后两行tail -f /var/log/messages 实时查看被添加到一个文件中的内容 12、文本处理12345678910111213141516171819202122232425262728293031cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUTcat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中grep Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找关键词&quot;Aug&quot;grep ^Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找以&quot;Aug&quot;开始的词汇grep [0-9] /var/log/messages 选择 &apos;/var/log/messages&apos; 文件中所有包含数字的行grep Aug -R /var/log/* 在目录 &apos;/var/log&apos; 及随后的目录中搜索字符串&quot;Aug&quot;sed &apos;s/stringa1/stringa2/g&apos; example.txt 将example.txt文件中的 &quot;string1&quot; 替换成 &quot;string2&quot;sed &apos;/^$/d&apos; example.txt 从example.txt文件中删除所有空白行sed &apos;/ *#/d; /^$/d&apos; example.txt 从example.txt文件中删除所有注释和空白行echo &apos;esempio&apos; | tr &apos;[:lower:]&apos; &apos;[:upper:]&apos; 合并上下单元格内容sed -e &apos;1d&apos; result.txt 从文件example.txt 中排除第一行sed -n &apos;/stringa1/p&apos; 查看只包含词汇 &quot;string1&quot;的行sed -e &apos;s/ *$//&apos; example.txt 删除每一行最后的空白字符sed -e &apos;s/stringa1//g&apos; example.txt 从文档中只删除词汇 &quot;string1&quot; 并保留剩余全部sed -n &apos;1,5p;5q&apos; example.txt 查看从第一行到第5行内容sed -n &apos;5p;5q&apos; example.txt 查看第5行sed -e &apos;s/00*/0/g&apos; example.txt 用单个零替换多个零cat -n file1 标示文件的行数cat example.txt | awk &apos;NR%2==1&apos; 删除example.txt文件中的所有偶数行echo a b c | awk &apos;&#123;print $1&#125;&apos; 查看一行第一栏echo a b c | awk &apos;&#123;print $1,$3&#125;&apos; 查看一行的第一和第三栏paste file1 file2 合并两个文件或两栏的内容paste -d &apos;+&apos; file1 file2 合并两个文件或两栏的内容，中间用&quot;+&quot;区分sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)comm -1 file1 file2 比较两个文件的内容只删除 &apos;file1&apos; 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 &apos;file2&apos; 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 13、字符设置和文件格式转换dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIXunix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOSrecode ..HTML &lt; page.txt &gt; page.html 将一个文本文件转换成htmlrecode -l | more 显示所有允许的转换格式 14、文本处理12345678910111213141516171819202122232425262728293031cat file1 file2 ... | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUTcat file1 | command( sed, grep, awk, grep, etc...) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中cat file1 | command( sed, grep, awk, grep, etc...) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中grep Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找关键词&quot;Aug&quot;grep ^Aug /var/log/messages 在文件 &apos;/var/log/messages&apos;中查找以&quot;Aug&quot;开始的词汇grep [0-9] /var/log/messages 选择 &apos;/var/log/messages&apos; 文件中所有包含数字的行grep Aug -R /var/log/* 在目录 &apos;/var/log&apos; 及随后的目录中搜索字符串&quot;Aug&quot;sed &apos;s/stringa1/stringa2/g&apos; example.txt 将example.txt文件中的 &quot;string1&quot; 替换成 &quot;string2&quot;sed &apos;/^$/d&apos; example.txt 从example.txt文件中删除所有空白行sed &apos;/ *#/d; /^$/d&apos; example.txt 从example.txt文件中删除所有注释和空白行echo &apos;esempio&apos; | tr &apos;[:lower:]&apos; &apos;[:upper:]&apos; 合并上下单元格内容sed -e &apos;1d&apos; result.txt 从文件example.txt 中排除第一行sed -n &apos;/stringa1/p&apos; 查看只包含词汇 &quot;string1&quot;的行sed -e &apos;s/ *$//&apos; example.txt 删除每一行最后的空白字符sed -e &apos;s/stringa1//g&apos; example.txt 从文档中只删除词汇 &quot;string1&quot; 并保留剩余全部sed -n &apos;1,5p;5q&apos; example.txt 查看从第一行到第5行内容sed -n &apos;5p;5q&apos; example.txt 查看第5行sed -e &apos;s/00*/0/g&apos; example.txt 用单个零替换多个零cat -n file1 标示文件的行数cat example.txt | awk &apos;NR%2==1&apos; 删除example.txt文件中的所有偶数行echo a b c | awk &apos;&#123;print $1&#125;&apos; 查看一行第一栏echo a b c | awk &apos;&#123;print $1,$3&#125;&apos; 查看一行的第一和第三栏paste file1 file2 合并两个文件或两栏的内容paste -d &apos;+&apos; file1 file2 合并两个文件或两栏的内容，中间用&quot;+&quot;区分sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)comm -1 file1 file2 比较两个文件的内容只删除 &apos;file1&apos; 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 &apos;file2&apos; 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 15、文件系统分析badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 16、初始化一个文件系统mkfs /dev/hda1 在hda1分区创建一个文件系统mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统fdformat -n /dev/fd0 格式化一个软盘mkswap /dev/hda3 创建一个swap文件系统 17、SWAP文件系统mkswap /dev/hda3 创建一个swap文件系统swapon /dev/hda3 启用一个新的swap文件系统swapon /dev/hda2 /dev/hdb3 启用两个swap分区 18、备份dump -0aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的完整备份dump -1aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的交互式备份restore -if /tmp/home0.bak 还原一个交互式备份rsync -rogpav –delete /home /tmp 同步两边的目录rsync -rogpav -e ssh –delete /home ip_address:/tmp 通过SSH通道rsyncrsync -az -e ssh –delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录rsync -az -e ssh –delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr ‘dd of=hda.gz’ 通过ssh在远程主机上执行一次备份本地磁盘的操作dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件tar -Puf backup.tar /home/user 执行一次对 ‘/home/user’ 目录的交互式备份操作( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr ‘cd /home/share/ &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个目录内容( tar c /home ) | ssh -C user@ip_addr ‘cd /home/backup-home &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个本地目录tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接find /home/user1 -name ‘.txt’ | xargs cp -av –target-directory=/home/backup/ –parents 从一个目录查找并复制所有以 ‘.txt’ 结尾的文件到另一个目录find /var/log -name ‘.log’ | tar cv –files-from=- | bzip2 &gt; log.tar.bz2 查找所有以 ‘.log’ 结尾的文件并做成一个bzip包dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容 19、网络 - （以太网和WIFI无线）ifconfig eth0 显示一个以太网卡的配置ifup eth0 启用一个 ‘eth0’ 网络设备ifdown eth0 禁用一个 ‘eth0’ 网络设备ifconfig eth0 192.168.1.1 netmask 255.255.255.0 控制IP地址ifconfig eth0 promisc 设置 ‘eth0’ 成混杂模式以嗅探数据包 (sniffing)dhclient eth0 以dhcp模式启用 ‘eth0’route -n show routing tableroute add -net 0/0 gw IP_Gateway configura default gatewayroute add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network ‘192.168.0.0/16’route del 0/0 gw IP_gateway remove static routeecho “1” &gt; /proc/sys/net/ipv4/ip_forward activate ip routinghostname show hostname of systemhost www.example.com lookup hostname to resolve name to ip address and viceversa(1)nslookup www.example.com lookup hostname to resolve name to ip address and viceversa(2)ip link show show link status of all interfacesmii-tool eth0 show link status of ‘eth0’ethtool eth0 show statistics of network card ‘eth0’netstat -tup show all active network connections and their PIDnetstat -tupl show all network services listening on the system and their PIDtcpdump tcp port 80 show all HTTP trafficiwlist scan show wireless networksiwconfig eth1 show configuration of a wireless network cardhostname show hostnamehost www.example.com lookup hostname to resolve name to ip address and viceversanslookup www.example.com lookup hostname to resolve name to ip address and viceversawhois www.example.com lookup on Whois database]]></content>
      <categories>
        <category>IT</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
        <tag>笔记</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]Ubuntu下配置java+Eclipse开发环境]]></title>
    <url>%2F2016%2F12%2F05%2F%E5%8E%9F-Ubuntu%E4%B8%8B%E9%85%8D%E7%BD%AEjava-Eclipse%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[1、复制文件到待安装目录cp /media/ubuntu/娱乐/jdk-8u92-linux-x64.tar.gz /opt/software 2、提升文件的操作权限（必须做，否则无法配置成功）chmod +x /opt/software/jdk-8u92-linux-x64.tar.gz 3、解压文件tar zxvf /opt/software/jdk-8u92-linux-x64.tar.gz -C /opt/software/ 4、添加环境变量当前用户的path（/home/username/.bashrc 和 .bash_profile）全局的path（/etc/bashrc 和/etc/profile） 立即生效的方法 source 配置文件1234export JAVA_HOME=/opt/software/jdk1.8.0_92export JRE_HOME=/opt/software/jdk1.8.0_92/jreexport CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 修改默认的JDK（注意替换路径，如果能直接显示sun的jdk的话就不用操作）sudo update-alternatives –install “/usr/bin/java” “java” “/usr/java/jdk_8u60/bin/java” 300sudo update-alternatives –install “/usr/bin/javac” “javac” “/usr/java/jdk_8u60/bin/javac” 300sudo update-alternatives –install “/usr/bin/javaws” “javaws” “/usr/java/jdk_8u60/bin/javaws” 300 重要参考链接：http://www.linuxidc.com/Linux/2015-09/122689.htm 5、解压eclipse6、创建快捷方式sudo gedit /usr/share/applications/eclipse.desktop然后写入以下语句（绝对不能有空格，否则很苦逼的说）[Desktop Entry] Encoding=UTF-8 Name=eclipse Comment=Eclipse IDE Exec=/usr/local/eclipse/eclipse_SDK/eclipse Icon=/usr/local/eclipse/eclipse_SDK/icon.xpm Terminal=false StartupNotify=true Type=Application Categories=Application;Development; Exec=/usr/local/eclipse/eclipse_SDK/eclipseIcon=/usr/local/eclipse/eclipse_SDK/icon.xpm 这个地方要修改为你的eclipse安装目录。 7、手动把eclipse.desktop拷贝到桌面上（注意系统如果是中文，则/home/username/桌面/为桌面目录）sudo cp /usr/share/applications/eclipse.desktop /home/ubuntu/桌面 8、修改图标文件的访问权限，普通用户没有root权限sudo chmod 777 /home/ubuntu/桌面/eclipse.desktopchmod u+x /home/ubuntu/桌面/eclipse.desktop]]></content>
      <categories>
        <category>解决方案</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>教程</tag>
        <tag>java</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]Java线程同步，synchronized锁住的是代码还是对象]]></title>
    <url>%2F2016%2F10%2F24%2F%E8%BD%AC-Java%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%EF%BC%8Csynchronized%E9%94%81%E4%BD%8F%E7%9A%84%E6%98%AF%E4%BB%A3%E7%A0%81%E8%BF%98%E6%98%AF%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[作者：叉叉哥转载自： http://blog.csdn.net/xiao__gui/article/details/8188833 在Java中，synchronized关键字是用来控制线程同步的，就是在多线程的环境下，控制synchronized代码段不被多个线程同时执行。synchronized既可以加在一段代码上，也可以加在方法上。 关键是，不要认为给方法或者代码段加上synchronized就万事大吉，看下面一段代码： 123456789101112131415161718192021222324252627282930class Sync &#123; public synchronized void test() &#123; System.out.println("test开始.."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("test结束.."); &#125; &#125; class MyThread extends Thread &#123; public void run() &#123; Sync sync = new Sync(); sync.test(); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 3; i++) &#123; Thread thread = new MyThread(); thread.start(); &#125; &#125; &#125; 运行结果： test开始.. test开始.. test开始.. test结束.. test结束.. test结束.._ 可以看出来，上面的程序起了三个线程，同时运行Sync类中的test()方法，虽然test()方法加上了synchronized，但是还是同时运行起来，貌&#20284;synchronized没起作用。&nbsp; 将test()方法上的synchronized去掉，在方法内部加上synchronized(this)： 1234567891011public void test() &#123; synchronized(this)&#123; System.out.println("test开始.."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("test结束.."); &#125; &#125; 运行结果： test开始.. test开始.. test开始.. test结束.. test结束.. test结束.. 一切还是这么平静，没有看到synchronized起到作用。 实际上，synchronized(this)以及非static的synchronized方法（至于static synchronized方法请往下看），只能防止多个线程同时执行同一个对象的同步代码段。 回到本文的题目上：synchronized锁住的是代码还是对象。答案是：synchronized锁住的是括号里的对象，而不是代码。对于非static的synchronized方法，锁的就是对象本身也就是this。 当synchronized锁住一个对象后，别的线程如果也想拿到这个对象的锁，就必须等待这个线程执行完成释放锁，才能再次给对象加锁，这样才达到线程同步的目的。即使两个不同的代码段，都要锁同一个对象，那么这两个代码段也不能在多线程环境下同时运行。 所以我们在用synchronized关键字的时候，能缩小代码段的范围就尽量缩小，能在代码段上加同步就不要再整个方法上加同步。这叫减小锁的粒度，使代码更大程度的并发。原因是基于以上的思想，锁的代码段太长了，别的线程是不是要等很久，等的花儿都谢了。当然这段是题外话，与本文核心思想并无太大关联。 再看上面的代码，每个线程中都new了一个Sync类的对象，也就是产生了三个Sync对象，由于不是同一个对象，所以可以多线程同时运行synchronized方法或代码段。 为了验证上述的观点，修改一下代码，让三个线程使用同一个Sync的对象。 1234567891011121314151617181920212223class MyThread extends Thread &#123; private Sync sync; public MyThread(Sync sync) &#123; this.sync = sync; &#125; public void run() &#123; sync.test(); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; Sync sync = new Sync(); for (int i = 0; i &lt; 3; i++) &#123; Thread thread = new MyThread(sync); thread.start(); &#125; &#125; &#125; 运行结果： test开始.. test结束.. test开始.. test结束.. test开始.. test结束.. 可以看到，此时的synchronized就起了作用。 那么，如果真的想锁住这段代码，要怎么做？也就是，如果还是最开始的那段代码，每个线程new一个Sync对象，怎么才能让test方法不会被多线程执行。 解决也很简单，只要锁住同一个对象不就行了。例如，synchronized后的括号中锁同一个固定对象，这样就行了。这样是没问题，但是，比较多的做法是让synchronized锁这个类对应的Class对象。 1234567891011121314151617181920212223242526272829303132class Sync &#123; public void test() &#123; synchronized (Sync.class) &#123; System.out.println("test开始.."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("test结束.."); &#125; &#125; &#125; class MyThread extends Thread &#123; public void run() &#123; Sync sync = new Sync(); sync.test(); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 3; i++) &#123; Thread thread = new MyThread(); thread.start(); &#125; &#125; &#125; 运行结果： test开始.. test结束.. test开始.. test结束.. test开始.. test结束.. 上面代码用synchronized(Sync.class)实现了全局锁的效果。 最后说说static synchronized方法，static方法可以直接类名加方法名调用，方法中无法使用this，所以它锁的不是this，而是类的Class对象，所以，static synchronized方法也相当于全局锁，相当于锁住了代码段。 参考链接http://www.cnblogs.com/techyc/archive/2013/03/19/2969677.html]]></content>
      <categories>
        <category>IT</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]Ubuntu14.04下安装单机版Storm运行环境]]></title>
    <url>%2F2016%2F10%2F20%2F%E5%8E%9F-Ubuntu14-04%E4%B8%8B%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88Storm%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[1、安装java环境 如果选择的是sun的java安装包，去官网下载后，记得提升文件权限（chmod +x path/文件名） 设置环境变量，在/etc/profile文件中添加以下内容（针对所有用户，相当于windows下面的系统变量） 1234export JAVA_HOME=/opt/software/jdk1.8.0_92export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 设置默认jdk 12345sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_92/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_92/bin/javac 300 sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_92/bin/jar 300 sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk1.8.0_92/bin/javah 300 sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.8.0_92/bin/javap 300 查看系统已经存在的jdksudo update­alternatives ­­list java 配置默认jdksudo update­alternatives ­­config java 表示当前默认的JDK，我这里已经设置好了最后使用java javac java -version命令来查看是否配置成功 2、安装Python Ubuntu默认安装了，直接使用Python命令来检测是否安装成功 3、安装Zookeeper安装前，把后面要用到的安装工具全部安装好sudo apt-get install g++sudo apt-get install uuid-devsudo apt-get install gitsudo apt-get install automakesudo apt-get install libtool 下载Zookeeper3.4.6 提升文件权限（chnmod +x path/文件名） 解压 tar -xvzf filename 配置ZooKeeper环境变量 sudo gedit /etc/profile 在/etc/profile中添加环境变量 12export ZOOKEEPER_HOME=/opt/software/zookeeper-3.4.6export PATH=\$PATH:\$ZOOKEEPER_HOME/bin 利用source /etc/profile 命令来让环境变量立即生效 4、安装ZeroMQ123456下载zeromq2.1.7.tar.gz编译安装./configureMakeSudo make installSudo ldconfig 5、安装Jzmp安装git工具，不安装也可以直接去github下载release版本123456sudo apt-get install git进入jzmp解压包的根目录编译和安装（前面的java的环境变量没有配置好，或者没有设置成默认的，这里无法通过）./configuremakesudo make install 6、安装storm1234567去Apache下载apache-storm-0.9.6.tar.gz解压后设置环境变量Sudo gedit /etc/profile末尾添加export STORM_HOME=/opt/software/apache-storm-0.9.6export PATH=$PATH:$STORM_HOME/bin 7、设置Storm的配置文件####首先设置zookeeper的配置文件1234567891011进入 cd /opt/software/zookeeper-3.4.6/conf从sample_zoo.cfg文件复制一份并重命名为zoo.cfg添加以下内容dataDir=/opt/zookeeper/datadataLogDir=/opt/zookeeper/logserver.1=127.0.0.1:2888:3888dataDir放置数据信息dataLogDir放置日志信息注意：必须手动创建该目录，否则后面启动zookeeper的时候，zkServer.sh status将会报错，最终显示的界面都是错误信息server.1由于是本地模式，所以只配置了一个，如果有多个机器，可以进行多个配置server.2进入/opt/software/zookeeper-3.4.6/bin目录进行测试 zkServer.sh startzkServer.sh statuszkServer.sh stop ####接下来设置storm1234567891011121314151617进入 /opt/software/apache-storm-0.9.6/conf中的storm.yaml文件添加以下条目 storm.zookeeper.servers: - &quot;127.0.0.1&quot; nimbus.host: &quot;127.0.0.1&quot; storm.zookeeper.port: 2181 storm.local.dir : &quot;/home/linux/data&quot; supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703添加的时候注意，每一行必须有一个空格在前面，其中nimbus.host:后面有个空格，.local.dir后面的冒号前后都有空格，这个奇葩的设定让我浪费了半天的时间。进入opt/software/apache-storm-0.9.6/bin中用以下命令启动Storm nimbusStorm supervisorStorm ui 至此Storm的安装工作完成了]]></content>
      <categories>
        <category>解决方案</category>
        <category>storm</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>教程</tag>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]java中关键字super和this的使用]]></title>
    <url>%2F2016%2F10%2F11%2F%E5%8E%9F-java%E4%B8%AD%E5%85%B3%E9%94%AE%E5%AD%97super%E5%92%8Cthis%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1、子类的构造函数如果要引用super的话，必须把super放在函数的首位1234567891011121314151617class Base &#123;Base() &#123;System.out.println("Base");&#125;&#125;public class Checket extends Base &#123;Checket() &#123;super();//调用父类的构造方法，一定要放在方法的首个语句System.out.println("Checket");&#125;public static void main(String argv[]) &#123;Checket c = new Checket();&#125;&#125; 如果想用super继承父类构造的方法，但是没有放在第一行的话，那么在super之前的语句，肯定是为了满足自己想要完成某些行为的语句，但是又用了super继承父类的构造方法。那么以前所做的修改就都回到以前了，就是说又成了父类的构造方法了。 2．在Java中，有时还会遇到子类中的成员变量或方法与超类（有时也称父类）中的成员变量或方法同名。因为子类中的成员变量或方法名优先级高，所以子类中的同名成员变量或方法就隐藏了超类的成员变量或方法，但是我们如果想要使用超类中的这个成员变量或方法，就需要用到super. 1234567891011121314151617181920212223class Country &#123;String name;void value() &#123;name = "China";&#125;&#125;class City extends Country &#123;String name;void value() &#123;name = "Hefei";super.value();//不调用此方法时，super.name返回的是父类的成员变量的值nullSystem.out.println(name);System.out.println(super.name);&#125;public static void main(String[] args) &#123;City c=new City();c.value();&#125;&#125; 为了在子类中引用父类中的成员变量name和方法value()，在代码中使用了super、super.name和super.value(),若不调用super.value()时，super.name返回父类成员变量默认值null,调用此方法时，super.value()方法把成员变量name赋值为China,再利用super.name调用父类的成员变量的值。 另外，要注意的是super.name调用的是成员变量的值，12345678910111213141516171819202122232425class Country &#123;String name="xianfan";String value(String name) &#123;name = "China";return name;&#125;&#125;class City extends Country &#123;String name;String value(String name) &#123;name = "Hefei";super.value("失败");//不调用此方法时，super.name返回的是父类的成员变量的值nullSystem.out.println(name);System.out.println(super.name);return name;&#125;public static void main(String[] args) &#123;City c=new City();c.value("成功");&#125;&#125; 结果为：Hefeixianfan此时，super.name返回的值是父类成员变量的值xianfan,而此时的super.value()方法是不起作用的。 3．用super直接传递参数：123456789101112131415161718192021222324252627282930313233343536class Person &#123;public static void prt(String s) &#123;System.out.println(s);&#125;Person() &#123;prt("A Person.");&#125;Person(String name) &#123;prt("A person name is:" + name);&#125;&#125;public class Chinese extends Person &#123;Chinese() &#123;super(); // 调用父类构造函数（1）prt("A chinese.");// (4)&#125;Chinese(String name) &#123;super(name);// 调用父类具有相同形参的构造函数（2）prt("his name is:" + name);&#125;Chinese(String name, int age) &#123;this(name);// 调用当前具有相同形参的构造函数（3）prt("his age is:" + age);&#125;public static void main(String[] args) &#123;Chinese cn = new Chinese();cn = new Chinese("kevin");cn = new Chinese("kevin", 22);&#125;&#125; 结果为：A Person.A chinese.A person name is:kevinhis name is:kevinA person name is:kevinhis name is:kevinhis age is:22 在这段程序中，this和super不再是像以前那样用“.”连接一个方法或成员，而是直接在其后跟上适当的参数，因此它的意义也就有了变化。super后加参数的是用来调用父类中具有相同形式的构造函数，如1和2处。this后加参数则调用的是当前具有相同参数的构造函数，如3处。当然，在Chinese的各个重载构造函数中，this和super在一般方法中的各种用法也仍可使用，比如4处，你可以将它替换为“this.prt”(因为它继承了父类中的那个方法）或者是“super.prt”（因为它是父类中的方法且可被子类访问），它照样可以正确运行。但这样似乎就有点画蛇添足的味道了。 4．super和this的异同： super（参数）：调用基类中的某一个构造函数（应该为构造函数中的第一条语句） this（参数）：调用本类中另一种形成的构造函数（应该为构造函数中的第一条语句） super: 它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名） 调用super()必须写在子类构造方法的第一行，否则编译不通过。每个子类构造方法的第一条语句，都是隐含地调用super()，如果父类没有这种形式的构造函数，那么在编译的时候就会报错。 super()和this()类似,区别是，super()从子类中调用父类的构造方法，this()在同一类内调用其它方法。 super()和this()均需放在构造方法内第一行。 尽管可以用this调用一个构造器，但却不能调用两个。 this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。 通过上面的例子，下面总结一下super的用法：第一、在子类构造方法中要调用父类的构造方法，用“super(参数列表)”的方式调用，参数不是必须的。同时还要注意的一点是：“super(参数列表)”这条语句只能用在子类构造方法体中的第一行。 第二、当子类方法中的局部变量或者子类的成员变量与父类成员变量同名时，也就是子类局部变量覆盖父类成员变量时，用“super.成员变量名”来引用父类成员变量。当然，如果父类的成员变量没有被覆盖，也可以用“super.成员变量名”来引用父类成员变量，不过这是不必要的。 第三、当子类的成员方法覆盖了父类的成员方法时，也就是子类和父类有完全相同的方法定义（但方法体可以不同），此时，用“super.方法名(参数列表)”的方式访问父类的方法。]]></content>
      <categories>
        <category>IT</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]java网络编程--socket套接字]]></title>
    <url>%2F2016%2F10%2F11%2F%E5%8E%9F-java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-socket%E5%A5%97%E6%8E%A5%E5%AD%97%2F</url>
    <content type="text"><![CDATA[Java 网络编程网络编程是指编写运行在多个设备（计算机）的程序，这些设备都通过网络连接起来。java.net包中J2SE的API包含有类和接口，它们提供低层次的通信细节。你可以直接使用这些类和接口，来专注于解决问题，而不用关注通信细节。java.net包中提供了两种常见的网络协议的支持： TCP： TCP是传输控制协议的缩写，它保障了两个应用程序之间的可靠通信。通常用于互联网协议，被称TCP / IP。 UDP:UDP是用户数据报协议的缩写，一个无连接的协议。提供了应用程序之间要发送的数据的数据包。 Socket 编程: 这是使用最广泛的网络概念，它已被解释地非常详细。套接字使用TCP提供了两台计算机之间的通信机制。 客户端程序创建一个套接字，并尝试连接服务器的套接字。当连接建立时，服务器会创建一个Socket对象。客户端和服务器现在可以通过对Socket对象的写入和读取来进行进行通信。 当使用套接字建立TCP链接时有4个步骤： 服务器实例化一个ServerSocket对象 服务器调用ServerSocket类的accept()方法等待客户端的连接 服务器正在等待的过程中，一个客户端实例化一个Socket对象，指定服务器和端口号，发送连接请求 在服务器端，accept()方法返回一个Socket的引用，该socket和客户端的socket相连接 URL 处理: 这部分会在另外的篇幅里讲，点击这里更详细地了解在Java语言中的URL处理。 示例程序: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109//服务器端程序，文件名HelloServer.javaimport java.net.*;import java.io.*;public class HelloServer extends Thread&#123; private ServerSocket serverSocket; //constructor public HelloServer(int port) throws IOException &#123; //1.创建绑定到特定端口的服务器套接字 serverSocket=new ServerSocket(port); serverSocket.setSoTimeout(20000);//休眠20ms &#125; @Override public void run() &#123; while(true) &#123; try &#123; System.out.println("Waiting for client on prot " +serverSocket.getLocalPort()+"..."); //2.服务器端调用ServerSocket类的accept（）方法，侦听并接受到此套接字的连接。 Socket server=serverSocket.accept(); System.out.println("Just connected to "+server.getRemoteSocketAddress()); //返回此套接字绑定的端点的地址，如果尚未绑定则返回 null。 //服务器端接收来数据 DataInputStream in=new DataInputStream(server.getInputStream()); System.out.println(in.readUTF()); //服务端发送数据 DataOutputStream out=new DataOutputStream(server.getOutputStream()); out.writeUTF("Thanks for connneciton to"+ server.getLocalSocketAddress() +"\nGoodbye!"); //关闭客户端 server.close(); &#125;catch(SocketTimeoutException s) &#123; System.out.println("Socket timed out!"); break; &#125;catch(IOException e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; public static void main(String[] args) &#123; // TODO Auto-generated method stub int port=6063; try &#123; Thread t=new HelloServer(port); t.start(); &#125;catch(IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;``` ``` java//客户端程序，文件名HelloClient.javaimport java.net.*;import java.io.*;public class HelloClient &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub //1.设置服务器名称和端口 String serverName="localhost"; int port=6063; try &#123; System.out.println("Connecting to "+serverName+ " on port" +port); //2.建立socket对象，与服务器通信 Socket client=new Socket(serverName,port); System.out.println("Just connected to "+client.getRemoteSocketAddress()); //客户端发送数据给服务器端 OutputStream outToServer=client.getOutputStream(); DataOutputStream out=new DataOutputStream(outToServer); out.writeUTF("hello from"+client.getLocalSocketAddress()); //客户端接收来自服务器端的数据 InputStream inFromServer=client.getInputStream(); DataInputStream in=new DataInputStream(inFromServer); System.out.print("server says " +in.readUTF()); client.close(); &#125;catch(IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 编译运行结果：]]></content>
      <categories>
        <category>IT</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]C++继承：公有，私有，保护]]></title>
    <url>%2F2016%2F09%2F12%2F%E8%BD%AC-C-%E7%BB%A7%E6%89%BF-%E5%85%AC%E6%9C%89%EF%BC%8C%E7%A7%81%E6%9C%89%EF%BC%8C%E4%BF%9D%E6%8A%A4%2F</url>
    <content type="text"><![CDATA[转载自：csqlwy 好记性不如烂笔头–温故而知新的博客 C++继承：公有，私有，保护公有继承(public)、私有继承(private)、保护继承(protected)是常用的三种继承方式。 公有继承(public)公有继承的特点是基类的公有成员和保护成员作为派生类的成员时，它们都保持原有的状态，而基类的私有成员仍然是私有的，不能被这个派生类的子类所访问。 私有继承(private)私有继承的特点是基类的公有成员和保护成员都作为派生类的私有成员，并且不能被这个派生类的子类所访问。 保护继承(protected)保护继承的特点是基类的所有公有成员和保护成员都成为派生类的保护成员，并且只能被它的派生类成员函数或友元访问，基类的私有成员仍然是私有的。 下面列出三种不同的继承方式的基类特性和派生类特性。&amp;space | public | protected | private—-|—-|—|—-共有继承 | public | protected | 不可见私有继承 | private|private|不可见保护继承| protected|protected|不可见 在上图中：1）基类成员对派生类都是：共有和保护的成员是可见的，私有的的成员是不可见的。2）基类成员对派生类的对象来说：要看基类的成员在派生类中变成了什么类型的成员。如：私有继承时，基类的共有成员和私有成员都变成了派生类中的私有成员，因此对于派生类中的对象来说基类的共有成员和私有成员就是不可见的。 为了进一步理解三种不同的继承方式在其成员的可见性方面的区别，下面从三种不同角度进行讨论。 对于公有继承方式 基类成员对其对象的可见性：公有成员可见，其他不可见。这里保护成员同于私有成员。 基类成员对派生类的可见性：公有成员和保护成员可见，而私有成员不可见。这里保护成员同于公有成员。 基类成员对派生类对象的可见性：公有成员可见，其他成员不可见。 所以，在公有继承时，派生类的对象可以访问基类中的公有成员；派生类的成员函数可以访问基类中的公有成员和保护成员。这里，一定要区分清楚派生类的对象和派生类中的成员函数对基类的访问是不同的。 对于私有继承方式 基类成员对其对象的可见性：公有成员可见，其他成员不可见。 基类成员对派生类的可见性：公有成员和保护成员是可见的，而私有成员是不可见的。 基类成员对派生类对象的可见性：所有成员都是不可见的。所以，在私有继承时，基类的成员只能由直接派生类访问，而无法再往下继承。 对于保护继承方式 这种继承方式与私有继承方式的情况相同。两者的区别仅在于对派生类的成员而言，对基类成员有不同的可见性。 上述所说的可见性也就是可访问性。 关于可访问性还有另的一种说法。这种规则中，称派生类的对象对基类访问为水平访问，称派生类的派生类对基类的访问为垂直访问。 看看这样的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include&lt;iostream&gt;using namespace std;//////////////////////////////////////////////////////////////////////////class A //父类&#123;private: int privatedateA;protected: int protecteddateA;public: int publicdateA;&#125;;//////////////////////////////////////////////////////////////////////////class B :public A //基类A的派生类B（共有继承）&#123;public: void funct() &#123; int b; b=privatedateA; //error：基类中私有成员在派生类中是不可见的 b=protecteddateA; //ok：基类的保护成员在派生类中为保护成员 b=publicdateA; //ok：基类的公共成员在派生类中为公共成员 &#125;&#125;;//////////////////////////////////////////////////////////////////////////class C :private A //基类A的派生类C（私有继承）&#123;public: void funct() &#123; int c; c=privatedateA; //error：基类中私有成员在派生类中是不可见的 c=protecteddateA; //ok：基类的保护成员在派生类中为私有成员 c=publicdateA; //ok：基类的公共成员在派生类中为私有成员 &#125;&#125;;//////////////////////////////////////////////////////////////////////////class D :protected A //基类A的派生类D（保护继承）&#123;public: void funct() &#123; int d; d=privatedateA; //error：基类中私有成员在派生类中是不可见的 d=protecteddateA; //ok：基类的保护成员在派生类中为保护成员 d=publicdateA; //ok：基类的公共成员在派生类中为保护成员 &#125;&#125;;//////////////////////////////////////////////////////////////////////////int main()&#123; int a; B objB; a=objB.privatedateA; //error：基类中私有成员在派生类中是不可见的,对对象不可见 a=objB.protecteddateA; //error：基类的保护成员在派生类中为保护成员，对对象不可见 a=objB.publicdateA; //ok：基类的公共成员在派生类中为公共成员，对对象可见 C objC; a=objC.privatedateA; //error：基类中私有成员在派生类中是不可见的,对对象不可见 a=objC.protecteddateA; //error：基类的保护成员在派生类中为私有成员，对对象不可见 a=objC.publicdateA; //error：基类的公共成员在派生类中为私有成员，对对象不可见 D objD; a=objD.privatedateA; //error：基类中私有成员在派生类中是不可见的,对对象不可见 a=objD.protecteddateA; //error：基类的保护成员在派生类中为保护成员，对对象不可见 a=objD.publicdateA; //error：基类的公共成员在派生类中为保护成员，对对象不可见 return 0;&#125;]]></content>
      <categories>
        <category>IT</category>
        <category>c++</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]C++中友元详解]]></title>
    <url>%2F2016%2F09%2F11%2F%E8%BD%AC-C-%E4%B8%AD%E5%8F%8B%E5%85%83%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[转载自：zhm_sunboy的博客 问题的提出 我们已知道类具备封装和信息隐 藏的特性。只有类的成员函数才能访问类的私有成员，程式中的其他函数是无法访问私有成员的。非成员函数能够访问类中的公有成员，但是假如将数据成员都定义 为公有的，这又破坏了隐藏的特性。另外，应该看到在某些情况下，特别是在对某些成员函数多次调用时，由于参数传递，类型检查和安全性检查等都需要时间开 销，而影响程式的运行效率。 为了解决上述问题，提出一种使用友元的方案。友元是一种定义在类外部的普通函数，但他需要在类体内进行说 明，为了和该类的成员函数加以区别，在说明时前面加以关键字friend。友元不是成员函数，但是他能够访问类中的私有成员。友元的作用在于提高程式的运 行效率，但是，他破坏了类的封装性和隐藏性，使得非成员函数能够访问类的私有成员。 友元能够是个函数，该函数被称为友元函数；友元也能够是个类，该类被称为友元类。 友元函数 友元函数的特点是能够访问类中的私有成员的非成员函数。友元函数从语法上看，他和普通函数相同，即在定义上和调用上和普通函数相同。下面举一例子说明友元函数的应用。 123456789101112131415161718192021222324252627282930313233 #include #include class Point &#123; public: Point(double xx, double yy) &#123; x=xx; y=yy; &#125; void Getxy(); friend double Distance(Point &amp;a, Point &amp;b); private: double x, y; &#125;; void Point::Getxy() &#123; cout&lt;&lt;"("&lt;&lt;&lt;","&lt;&lt;&lt;")"&lt;&lt; FONT&gt; &#125; double Distance(Point &amp;a, Point &amp;b) &#123; double dx = a.x - b.x; double dy = a.y - b.y; return sqrt(dx*dx+dy*dy); &#125; void main() &#123; Point p1(3.0, 4.0), p2(6.0, 8.0); p1.Getxy(); p2.Getxy(); double d = Distance(p1, p2); cout&lt;&lt;"Distance is"&lt;&lt;&lt; FONT&gt; &#125; 说明：在该程式中的Point类中说明了一个友元函数Distance()，他在说明时前边加friend关键字，标识他不是成员函数，而是友元函数。 他的定义方法和普通函数定义相同，而不同于成员函数的定义，因为他无需指出所属的类。但是，他能够引用类中的私有成员，函数体中 a.x，b.x，a.y，b.y都是类的私有成员，他们是通过对象引用的。在调用友元函数时，也是同普通函数的调用相同，不要像成员函数那样调用。本例 中，p1.Getxy()和p2.Getxy()这是成员函数的调用，要用对象来表示。而Distance(p1, p2)是友元函数的调用，他直接调 用，无需对象表示，他的参数是对象。(该程式的功能是已知两点坐标，求出两点的距离。) 友元类 友元除了前面讲过的函数以外，友元还能够是类，即一个类能够作另一个类的友元。当一个类作为另一个类的友元时，这就意味着这个类的任何成员函数都是另一个类的友元函数。 ———————————–另一篇——————————————- 采用类的机制后实现了数据的隐藏与封装，类的数据成员一般定义为私有成员，成员函数一般定义为公有的，依此提供类与外界间的通信接口。但是，有时需要定义一 些函数，这些函数不是类的一部分，但又需要频繁地访问类的数据成员，这时可以将这些函数定义为该函数的友元函数。除了友元函数外，还有友元类，两者统称为 友元。友元的作用是提高了程序的运行效率（即减少了类型检查和安全性检查等都需要时间开销），但它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的 私有成员。 友元函数 ：友元函数是可以直接访问类的私有成员的非成员函数。它是定义在类外的普通函数，它不属于任何类，但需要在类的定义中加以声明，声明时只需在友元的名称前加上关键字friend，其格式如下： friend 类型 函数名(形式参数); 友元函数的声明可以放在类的私有部分，也可以放在公有部分，它们是没有区别的，都说明是该类的一个友元函数。一个函数可以是多个类的友元函数，只需要在各个类中分别声明。友元函数的调用与一般函数的调用方式和原理一致。 友元类 ：友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。当希望一个类可以存取另一个类的私有成员时，可以将该类声明为另一类的友元类。定义友元类的语句格式如下： friend class 类名; 其中：friend和class是关键字，类名必须是程序中的一个已定义过的类。 例如，以下语句说明类B是类A的友元类： 1234567class A&#123; …public: friend class B; …&#125;; 经过以上说明后，类B的所有成员函数都是类A的友元函数，能存取类A的私有成员和保护成员。 使用友元类时注意： 友元关系不能被继承。 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明 注意事项： 友元可以访问类的私有成员。 只能出现在类定义内部，友元声明可以在类中的任何地方，一般放在类定义的开始或结尾。 友元可以是普通的非成员函数，或前面定义的其他类的成员函数，或整个类。 类必须将重载函数集中每一个希望设为友元的函数都声明为友元。 友元关系不能继承，基类的友元对派生类的成员没有特殊的访问权限。如果基类被授予友元关系，则只有基类具有特殊的访问权限。该基类的派生类不能访问授予友元关系的类。]]></content>
      <categories>
        <category>IT</category>
        <category>c++</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]java对象的引用和对象的赋值]]></title>
    <url>%2F2016%2F08%2F23%2F%E8%BD%AC-java%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%BC%95%E7%94%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%B5%8B%E5%80%BC%2F</url>
    <content type="text"><![CDATA[JAVA 对象引用，以及对象赋值原文：http://blog.sina.com.cn/s/blog_4cd5d2bb0100ve9r.html Java对象及其引用关于对象与引用之间的一些基本概念: 初学Java时，在很长一段时间里，总觉得基本概念很模糊。后来才知道，在许多Java书中，把对象和对象的引用混为一谈。可是，如果我分不清对象与对象引用，那实在没法很好地理解下面的面向对象技术。把自己的一点认识写下来，或许能让初学Java的朋友们少走一点弯路。为便于说明，我们先定义一个简单的类： 12345 class Vehicle &#123; int passengers; int fuelcap; int mpg;&#125; 1Vehicle veh1 = new Vehicle(); 有了这个模板，就可以用它来创建对象：通常把这条语句的动作称之为创建一个对象，其实，它包含了四个动作。 右边的“new Vehicle”，是以Vehicle类为模板，在堆空间里创建一个Vehicle类对象（也简称为Vehicle对象）。 末尾的()意味着，在对象创建后，立即调用Vehicle类的构造函数，对刚生成的对象进行初始化。构造函数是肯定有的。如果你没写，Java会给你补上一个默认的构造函数。 左边的“Vehicle veh 1”创建了一个Vehicle类引用变量。所谓Vehicle类引用，就是以后可以用来指向Vehicle对象的对象引用。 =”操作符使对象引用指向刚创建的那个Vehicle对象。 我们可以把这条语句拆成两部分： Vehicle veh1; veh1 = new Vehicle(); 效果是一样的。这样写，就比较清楚了，有两个实体：一是对象引用变量，一是对象本身。 在堆空间里创建的实体，与在数据段以及栈空间里创建的实体不同。尽管它们也是确确实实存在的实体，但是，我们看不见，也摸不着。不仅如此，我们仔细研究一下第二句，找找刚创建的对象叫什么名字？有人说，它叫“Vehicle”。不对，“Vehicle”是类（对象的创建模板）的名字。一个Vehicle类可以据此创建出无数个对象，这些对象不可能全叫“Vehicle”。对象连名都没有，没法直接访问它。我们只能通过对象引用来间接访问对象。 为了形象地说明对象、引用及它们之间的关系，可以做一个或许不很妥当的比喻。对象好比是一只很大的气球，大到我们抓不住它。引用变量是一根绳， 可以用来系气球。如果只执行了第一条语句，还没执行第二条，此时创建的引用变量veh1还没指向任何一个对象，它的值是null。引用变量可以指向某个对象，或者为null。它是一根绳，一根还没有系上任何一个汽球的绳。执行了第二句后，一只新汽球做出来了，并被系在veh1这根绳上。我们抓住这根绳，就等于抓住了那只汽球。再来一句： Vehicle veh2; 就又做了一根绳，还没系上汽球。如果再加一句： veh2 = veh1; 系上了。这里，发生了复制行为。但是，要说明的是，对象本身并没有被复制，被复制的只是对象引用。结果是，veh2也指向了veh1所指向的对象。两根绳系的是同一只汽球。 如果用下句再创建一个对象： veh2 = new Vehicle(); 则引用变量veh2改指向第二个对象。 从以上叙述再推演下去，我们可以获得以下结论： （1）一个对象引用可以指向0个或1个对象（一根绳子可以不系汽球，也可以系一个汽球）； （2）一个对象可以有N个引用指向它（可以有N条绳子系住一个汽球）。如果再来下面语句： veh1 = veh2; 按上面的推断，veh1也指向了第二个对象。这个没问题。问题是第一个对象呢？没有一条绳子系住它，它飞了。多数书里说，它被Java的垃圾回收机制回收了。 这不确切。正确地说，它已成为垃圾回收机制的处理对象。至于什么时候真正被回收，那要看垃圾回收机制的心情了。 由此看来，下面的语句应该不合法吧？至少是没用的吧？ new Vehicle(); 不对。它是合法的，而且可用的。譬如，如果我们仅仅为了打印而生成一个对象，就不需要用引用变量来系住它。最常见的就是打印字符串： System.out.println(“I am Java!”); 字符串对象“I am Java!”在打印后即被丢弃。有人把这种对象称之为临时对象。对象与引用的关系将持续到对象回收。 Java对象及引用Java对象及引用是容易混淆却又必须掌握的基础知识，本章阐述Java对象和引用的概念，以及与其密切相关的参数传递。 先看下面的程序： StringBuffer s; s = new StringBuffer(“Hello World!”); 第一个语句仅为引用(reference)分配了空间，而第二个语句则通过调用类(StringBuffer)的构造函数StringBuffer(String str)为类生成了一个实例（或称为对象）。这两个操作被完成后，对象的内容则可通过s进行访问——在Java里都是通过引用来操纵对象的。 Java对象和引用的关系可以说是互相关联，却又彼此独立。彼此独立主要表现在：引用是可以改变的，它可以指向别的对象，譬如上面的s，你可以给它另外的对象，如： s = new StringBuffer(“Java”); 这样一来，s就和它指向的第一个对象脱离关系。 从存储空间上来说，对象和引用也是独立的，它们存储在不同的地方，对象一般存储在堆中，而引用存储在速度更快的堆栈中。 引用可以指向不同的对象，对象也可以被多个引用操纵，如： StringBuffer s1 = s; 这条语句使得s1和s指向同一个对象。既然两个引用指向同一个对象，那么不管使用哪个引用操纵对象，对象的内容都发生改变，并且只有一份，通过s1和s得到的内容自然也一样，(String除外，因为String始终不变，String s1=”AAAA”; String s=s1,操作s,s1由于始终不变，所以为s另外开辟了空间来存储s,)如下面的程序： 1234567891011StringBuffer s;s = new StringBuffer("Java");StringBuffer s1 = s;s1.append(" World");System.out.println("s1=" + s1.toString());//打印结果为：s1=Java WorldSystem.out.println("s=" + s.toString());//打印结果为：s=Java World 上面的程序表明，s1和s打印出来的内容是一样的，这样的结果看起来让人非常疑惑，但是仔细想想，s1和s只是两个引用，它们只是操纵杆而已，它们指向同一个对象，操纵的也是同一个对象，通过它们得到的是同一个对象的内容。这就像汽车的刹车和油门，它们操纵的都是车速，假如汽车开始的速度是80，然后你踩了一次油门，汽车加速了，假如车速升到了120，然后你踩一下刹车，此时车速是从120开始下降的，假如下降到60，再踩一次油门，车速则从60开始上升，而不是从第一次踩油门后的120开始。也就是说车速同时受油门和刹车影响，它们的影响是累积起来的，而不是各自独立（除非刹车和油门不在一辆车上）。所以，在上面的程序中，不管使用s1还是s操纵对象，它们对对象的影响也是累积起来的（更多的引用同理）。 只有理解了对象和引用的关系，才能理解参数传递。 一般面试题中都会考Java传参的问题，并且它的标准答案是 Java只有一种参数传递方式：那就是按值传递，即Java中传递任何东西都是传值。如果传入方法的是基本类型的东西，你就得到此基本类型的一份拷贝。如果是传递引用，就得到引用的拷贝。 一般来说，对于基本类型的传递，我们很容易理解，而对于对象，总让人感觉是按引用传递，看下面的程序： 12345678910111213141516171819202122232425262728public class ObjectRef &#123; //基本类型的参数传递 public static void testBasicType(int m) &#123; System.out.println("m=" + m);//m=50 m = 100; System.out.println("m=" + m);//m=100 &#125; //参数为对象，不改变引用的值 ？？？？？？ public static void add(StringBuffer s) &#123; s.append("_add"); &#125; //参数为对象，改变引用的值 ？？？？？ public static void changeRef(StringBuffer s) &#123; //牵着的绳子(s)换气球了 s = new StringBuffer("Java"); &#125; public static void main(String[] args) &#123; int i = 50; testBasicType(i); System.out.println(i);//i=50 StringBuffer sMain = new StringBuffer("init"); System.out.println("sMain=" + sMain.toString());//sMain=init add(sMain); System.out.println("sMain=" + sMain.toString());//sMain=init_add changeRef(sMain); System.out.println("sMain=" + sMain.toString());//sMain=init_add &#125;&#125; 以上程序的允许结果显示出，testBasicType方法的参数是基本类型，尽管参数m的值发生改变，但并不影响i。 add方法的参数是一个对象，当把sMain传给参数s时，s得到的是sMain的拷贝，所以s和sMain指向同一个对象，因此，使用s操作影响的其实就是sMain指向的对象，故调用add方法后，sMain指向的对象的内容发生了改变。 在changeRef方法中，参数也是对象，当把sMain传给参数s时，s得到的是sMain的拷贝，但与add方法不同的是，在方法体内改变了s指向的对象（也就是s指向了别的对象,牵着气球的绳子换气球了），给s重新赋值后，s与sMain已经毫无关联，它和sMain指向了不同的对象，所以不管对s做什么操作，都不会影响sMain指向的对象，故调用changeRef方法前后sMain指向的对象内容并未发生改变。 对于add方法的调用结果，可能很多人会有这种感觉：这不明明是按引用传递吗？对于这种问题，还是套用Bruce Eckel的话：这依赖于你如何看待引用，最终你会明白，这个争论并没那么重要。真正重要的是，你要理解，传引用使得（调用者的）对象的修改变得不可预期。 123456789101112131415161718192021222324252627public class Test&#123; public int i,j; public void test_m(Test a) &#123; Test b = new Test(); b.i = 1; b.j = 2; a = b; &#125; public void test_m1(Test a ) &#123; a.i = 1; a.j = 2; &#125; public static void main(String argv[]) &#123; Test t= new Test(); t.i = 5; t.j = 6; System.out.println( "t.i = "+ t.i + " t.j= " + t.j); //5,6 t.test_m(t); System.out.println( "t.i = "+ t.i + " t.j= " + t.j); //5,6,a和t都指向了一个对象，而在test_m中s又指向了另一个对象，所以对象t不变！！！ t.test_m1(t); System.out.println( "t.i = "+ t.i + " t.j= " + t.j); //1,2 &#125;&#125; 答案只有一个：Java里都是按值传递参数。如果参数是普通类型，传递的就是普通的，如果参数是对象的引用，传递的也是引用（引用本身也是一种类型）。而实际上，我们要明白，当参数是对象时，传引用会发生什么状况（就像上面的add方法）？ ========================================================================= 楼主，这样来记这个问题如下表达式：A a1 = new A();它代表A是类，a1是引用，a1不是对象，new A()才是对象，a1引用指向new A()这个对象。 在JAVA里，“=”不能被看成是一个赋值语句，它不是在把一个对象赋给另外一个对象，它的执行过程实质上是将右边对象的地址传给了左边的引用，使得左边的引用指向了右边的对象。JAVA表面上看起来没有指针，但它的引用其实质就是一个指针，引用里面存放的并不是对象，而是该对象的地址，使得该引用指向了对象。在JAVA里，“=”语句不应该被翻译成赋值语句，因为它所执行的确实不是一个赋值的过程，而是一个传地址的过程，被译成赋值语句会造成很多误解，译得不准确。 再如：A a2;它代表A是类，a2是引用，a2不是对象，a2所指向的对象为空null; 再如：a2 = a1;它代表，a2是引用，a1也是引用，a1所指向的对象的地址传给了a2(传址），使得a2和a1指向了同一对象。 综上所述，可以简单的记为，在初始化时，“=”语句左边的是引用，右边new出来的是对象。在后面的左右都是引用的“=”语句时，左右的引用同时指向了右边引用所指向的对象。 再所谓实例，其实就是对象的同义词。 如果需要赋值，就需要类实现Cloneable接口，实现clone()方法。 1234567891011class D implements Cloneable&#123;//实现Cloneable接口 String sex; D(String sex)&#123; this.sex=sex; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; // 实现clone方法 return super.clone(); &#125;&#125; 赋值的时候： 12D d=new D("男");D d2=(D) d.clone();//把d赋值给d2 如果类中的变量不是主类型，而是对象，也需要调用该对象的clone()方法下面是一个完整的例子： 1234567891011121314151617181920212223242526272829303132333435363738394041public class Test2 &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; // TODO Auto-generated method stub D d=new D("男"); C c=new C("张三","20",d); C new_c=(C) c.clone();//调用clone方法来赋值 new_c.name="李四"; d.sex="女";//d System.out.println(c.d.sex); System.out.println(c.name); &#125;&#125;class C implements Cloneable&#123; String name; String age; D d; C(String name,String age,D d) throws CloneNotSupportedException&#123; this.name=name; this.age=age; this.d=(D) d.clone();//调用clone方法来赋值，这样即便外部的d发生变化，c里的也不会变 &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; // TODO Auto-generated method stub return super.clone(); &#125;&#125;class D implements Cloneable&#123;//实现Cloneable接口 String sex; D(String sex)&#123; this.sex=sex; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; // 实现clone方法 return super.clone(); &#125;&#125;]]></content>
      <categories>
        <category>IT</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]Java学习笔记（一）]]></title>
    <url>%2F2016%2F08%2F23%2F%E5%8E%9F-Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[java的自动回收机制 java拥有自动回收机制，也可以手动使用finalize()方法进行释放资源。 java的参数传递123456789101112131415161718192021222324252627282930313233package com.test3;public class TestReference &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub A a1=new A(1,2); B b=new B(11,22); System.out.println(a1.b); a1.test(b); System.out.println(a1.b); //java中是值传递，输出都是2 &#125;&#125;class A&#123; int a,b; A(int a,int b)&#123; this.a=a; this.b=b; &#125; public void test(B b)&#123; b.a=a; &#125;&#125;class B&#123; int a,b; B(int a,int b)&#123; this.a=a; this.b=b; &#125; public void setA(int a)&#123; this.a=a; &#125;&#125; 从上面的代码看出，java的对象引用的传递和C++的不同，java的引用传递相当于值传递，C++的引用传递相当于传递的是地址。 java类的引用修饰符 类 成员变量 成员方法 public 包外可见 包外可见 包外可见 abstract 申明抽象类 X 抽象方法 final 不能有子类 最终域修饰符 最终方法控制符 static X 静态域修饰符 静态方法控制符 volatile X 共享域修饰符 X transient X 暂时性域修饰符 X private X 类内调用 类内调用 protected X 父子类之间调用 父子类之间调用 native X X 本地方法控制符 synchronized X X 同步方法控制符]]></content>
      <categories>
        <category>IT</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[原]欢迎使用CSDN-markdown编辑器]]></title>
    <url>%2F2016%2F08%2F22%2F%E5%8E%9F-%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8CSDN-markdown%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[欢迎使用Markdown编辑器写博客本Markdown编辑器使用StackEdit修改而来，用它写博客，将会带来全新的体验哦： Markdown和扩展Markdown简洁的语法 代码块高亮 图片链接和图片上传 LaTex数学公式 UML序列图和流程图 离线写博客 导入导出Markdown文件 丰富的快捷键 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + Y Markdown及扩展 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— [ 维基百科 ] 使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接等，详细语法参考帮助？。 本编辑器支持 Markdown Extra , 扩展了很多好用的功能。具体请参考Github. 表格Markdown Extra 表格语法： 项目 价格 Computer $1600 Phone $12 Pipe $1 可以使用冒号来定义对齐方式： 项目 价格 数量 Computer 1600 元 5 Phone 12 元 12 Pipe 1 元 234 ###定义列表 Markdown Extra 定义列表语法：项目１项目２: 定义 A: 定义 B 项目３: 定义 C : 定义 D &gt; 定义D内容 代码块代码块语法遵循标准markdown代码，例如：12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' ###脚注生成一个脚注[^footnote]. [^footnote]: 这里是 脚注 的 内容. 目录用 [TOC]来生成目录： [TOC] 数学公式使用MathJax渲染LaTex 数学公式，详见math.stackexchange.com. 行内公式，数学公式为：$\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$。 块级公式： $$ x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$ 更多LaTex语法请参考 这儿. UML 图:可以渲染序列图： 123张三-&gt;李四: 嘿，小四儿, 写博客了没?Note right of 李四: 李四愣了一下，说：李四--&gt;张三: 忙得吐血，哪有时间写。 或者流程图： 12345678st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 关于 序列图 语法，参考 这儿, 关于 流程图 语法，参考 这儿. 离线写博客即使用户在没有网络的情况下，也可以通过本编辑器离线写博客（直接在曾经使用过的浏览器中输入write.blog.csdn.net/mdeditor即可。Markdown编辑器使用浏览器离线存储将内容保存在本地。 用户写博客的过程中，内容实时保存在浏览器缓存中，在用户关闭浏览器或者其它异常情况下，内容不会丢失。用户再次打开浏览器时，会显示上次用户正在编辑的没有发表的内容。 博客发表后，本地缓存将被删除。 用户可以选择 把正在写的博客保存到服务器草稿箱，即使换浏览器或者清除缓存，内容也不会丢失。 注意：虽然浏览器存储大部分时候都比较可靠，但为了您的数据安全，在联网后，请务必及时发表或者保存到服务器草稿箱。 ##浏览器兼容 目前，本编辑器对Chrome浏览器支持最为完整。建议大家使用较新版本的Chrome。 IE９以下不支持 IE９，１０，１１存在以下问题 不支持离线功能 IE9不支持文件导入导出 IE10不支持拖拽文件导入]]></content>
      <categories>
        <category>IT</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>CSDN</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]ROC曲线-阈值评价标准]]></title>
    <url>%2F2016%2F04%2F11%2F%E8%BD%AC-ROC%E6%9B%B2%E7%BA%BF-%E9%98%88%E5%80%BC%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86%2F</url>
    <content type="text"><![CDATA[ROC曲线指受试者工作特征曲线 / 接收器操作特性曲线(receiver operating characteristic curve), 是反映敏感性和特异性连续变量的综合指标,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界&#20540;，从而计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为敏感性和特异性均较高的临界&#20540;。 ##ROC曲线的例子 考虑一个二分问题，即将实例分成正类（positive）或负类（negative）。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被 预测成正类，即为真正类（True positive）,如果实例是负类被预测成正类，称之为假正类（False positive）。相应地，如果实例是负类被预测成负类，称之为真负类（True negative）,正类被预测成负类则为假负类（false negative）。 TP：正确肯定的数目； FN：漏报，没有正确找到的匹配的数目； FP：误报，给出的匹配是不正确的； TN：正确拒绝的非匹配对数； 列联表如下表所示，1代表正类，0代表负类。 &nbsp;&nbsp;预测&nbsp;&nbsp;&nbsp;10合计实际1True Positive（TP）False Negative（FN）Actual Positive(TP&#43;FN)&nbsp;0False Positive（FP)True Negative(TN)Actual Negative(FP&#43;TN)合计&nbsp;Predicted Positive(TP&#43;FP)Predicted Negative(FN&#43;TN)TP&#43;FP&#43;FN&#43;TN从列联表引入两个新名词。其一是真正类率(true positive rate ,TPR), 计算公式为TPR=TP/ (TP&#43;&nbsp;FN)，刻画的是分类器所识别出的 正实例占所有正实例的比例。另外一个是负正类率(false positive rate,&nbsp;FPR),计算公式为FPR= FP / (FP &#43; TN)，计算的是分类器错认为正类的负实例占所有负实例的比例。还有一个真负类率（True Negative Rate，TNR），也称为specificity,计算公式为TNR=TN/ (FP&#43;&nbsp;TN) = 1-FPR。其中，两列True matches和True non-match分别代表应该匹配上和不应该匹配上的两行Pred matches和Pred non-match分别代表预测匹配上和预测不匹配上的 在一个二分类模型中，对于所得到的连续结果，假设已确定一个阀&#20540;，比如说 0.6，大于这个&#20540;的实例划归为正类，小于这个&#20540;则划到负类中。如果减小阀&#20540;，减到0.5，固然能识别出更多的正类，也就是提高了识别出的正例占所有正例 的比类，即TPR,但同时也将更多的负实例当作了正实例，即提高了FPR。为了形象化这一变化，在此引入ROC，ROC曲线可以用于评价一个分类器。 ROC曲线和它相关的比率 (a)理想情况下，TPR应该接近1，FPR应该接近0。 ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。 比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=0，对应于右上角的点(1,1) (b)P和N得分不作为特征间距离d的一个函数，随着阈&#20540;theta增加，TP和FP都增加 Receiver Operating Characteristic,翻译为&quot;接受者操作特性曲线&quot;，够拗口的。曲线由两个变量1-specificity 和 Sensitivity绘制. 1-specificity=FPR，即负正类率。Sensitivity即是真正类率，TPR(True positive rate),反映了正类覆盖程度。这个组合以1-specificity对sensitivity,即是以代价(costs)对收益(benefits)。 &nbsp; &nbsp; &nbsp; &nbsp;此外，ROC曲线还可以用来计算“均&#20540;平均精度”（mean average precision），这是当你通过改变阈&#20540;来选择最好的结果时所得到的平均精度（PPV）. 下表是一个逻辑回归得到的结果。将得到的实数&#20540;按大到小划分成10个个数 相同的部分。 Percentile 实例数 正例数 1-特异度(%) 敏感度(%) 10 6180 4879 2.73 34.64 20 6180 2804 9.80 54.55 30 6180 2165 18.22 69.92 40 6180 1506 28.01 80.62 50 6180 987 38.90 87.62 60 6180 529 50.74 91.38 70 6180 365 62.93 93.97 80 6180 294 75.26 96.06 90 6180 297 87.59 98.17 100 6177 258 100.00 100.00其正例数为此部分里实际的正类数。也就是说，将逻辑回归得到的结 果按从大到小排列，倘若以前10%的数&#20540;作为阀&#20540;，即将前10%的实例都划归为正类，6180个。其中，正确的个数为4879个，占所有正类的 4879/14084100%=34.64%，即敏感度；另外，有6180-4879=1301个负实例被错划为正类，占所有负类的1301 /47713100%=2.73%,即1-特异度。以这两组&#20540;分别作为x&#20540;和y&#20540;，在excel中作散点图。]]></content>
      <categories>
        <category>IT</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>ROC</tag>
        <tag>机器学习</tag>
        <tag>分类</tag>
      </tags>
  </entry>
</search>
